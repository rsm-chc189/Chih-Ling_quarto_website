[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Chih-Ling(Lynn) Chang",
    "section": "",
    "text": "Welcome to my website !"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let’s investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of -0.85.\n\n\nHere is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Preparing the Data for Estimatation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nChih-Ling Chang\n\n\nJun 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Cars\n\n\n\n\n\n\nYour Name\n\n\nJun 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBlueprinty Case Study\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Description\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK-Means & K Nearest Neighbors\n\n\n\n\n\n\nChih-Ling Chang\n\n\nJun 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logit Model\n\n\n\n\n\n\nChih-Ling Chang\n\n\nJun 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nChih-Ling Chang\n\n\nJun 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\nNo matching items\n\n:::\n:::"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "HW1/hw1_questions.html",
    "href": "HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "HW1/hw1_questions.html#introduction",
    "href": "HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "HW1/hw1_questions.html#data",
    "href": "HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "HW1/hw1_questions.html#experimental-results",
    "href": "HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "HW1/hw1_questions.html#simulation-experiment",
    "href": "HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "HW1/HW1.html",
    "href": "HW1/HW1.html",
    "title": "Data Description",
    "section": "",
    "text": "# pip install pandas pyreadstat\n\nRequirement already satisfied: pandas in /home/jovyan/.rsm-msba/lib/python3.11/site-packages (2.2.3)\nRequirement already satisfied: pyreadstat in /opt/conda/lib/python3.11/site-packages (1.2.8)\nRequirement already satisfied: numpy&gt;=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\nRequirement already satisfied: pytz&gt;=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six&gt;=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pyrsm as rsm\n\n\nkarlan_df = pd.read_stata('karlan_list_2007.dta')\nkarlan_df.to_csv('karlan_list_2007.csv', index=False)\n\n\nkarlan_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\nkarlan_df.isnull().sum()\n\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n\n\n\ngroup_cols = [\"treatment\", \"control\"]\nratio_cols = [\"ratio\", \"ratio2\", \"ratio3\"]\nsize_cols = [\"size25\", \"size50\", \"size100\", \"sizeno\"]\naskd_cols = [\"ask\", \"askd1\", \"askd2\", \"askd3\"]\nask_cols = [\"ask1\", \"ask2\", \"ask3\"]\nstate_cols = [\"red0\", \"blue0\"]\ncounty_cols = [\"redcty\", \"bluecty\"]\n\n\nkarlan_df[\"group\"] = karlan_df[group_cols].idxmax(axis=1)\nkarlan_df[\"county\"] = karlan_df[county_cols].idxmax(axis=1).map({\"redcty\": \"red\", \"bluecty\": \"blue\"})\nkarlan_df[\"state\"] = karlan_df[state_cols].idxmax(axis=1).map({\"red0\": \"red\", \"blue0\": \"blue\"})\nkarlan_df\n\n/tmp/ipykernel_7246/2551348540.py:2: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n  karlan_df[\"county\"] = karlan_df[county_cols].idxmax(axis=1).map({\"redcty\": \"red\", \"bluecty\": \"blue\"})\n/tmp/ipykernel_7246/2551348540.py:3: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n  karlan_df[\"state\"] = karlan_df[state_cols].idxmax(axis=1).map({\"red0\": \"red\", \"blue0\": \"blue\"})\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\ngroup\ncounty\nstate\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\ncontrol\nblue\nblue\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\ncontrol\nred\nblue\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\ntreatment\nblue\nblue\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\ntreatment\nred\nblue\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\ntreatment\nblue\nred\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\ntreatment\nblue\nred\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\ncontrol\nblue\nblue\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\ncontrol\nred\nblue\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\ntreatment\nred\nblue\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\ntreatment\nblue\nblue\n\n\n\n\n50083 rows × 54 columns\n\n\n\n\ngroup = karlan_df[\"group\"].value_counts(normalize=True)\ngroup.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Group Distribution\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nfor i in range(len(group)):\n    plt.text(i, group[i], f\"{round(group[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/2886523009.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, group[i], f\"{round(group[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nratios = karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}).value_counts(normalize=True)\nratios.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Match Ratios\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nfor i in range(len(ratios)):\n    plt.text(i, ratios[i], f\"{round(ratios[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/3747464993.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ratios[i], f\"{round(ratios[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nsizes = karlan_df[\"size\"].value_counts(normalize=True)\nsizes.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Match thresholds\")\nplt.xlabel(\"Size\")\nplt.ylabel(\"Proportion\")\nfor i in range(len(sizes)):\n    plt.text(i, sizes[i], f\"{round(sizes[i]*100, 2)}%\", ha='center', va='bottom')\nplt.xticks(rotation=0)\nplt.show()\n\n/tmp/ipykernel_7246/248569292.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, sizes[i], f\"{round(sizes[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nasks = karlan_df[\"ask\"].value_counts(normalize=True)\nasks.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Highest previous contribution (for suggestion)\")\nplt.xlabel(\"Ask\")\nplt.ylabel(\"Proportion\")\nfor i in range(len(asks)):\n    plt.text(i, asks[i], f\"{round(asks[i]*100, 2)}%\", ha='center', va='bottom')\nplt.xticks(rotation=0)\nplt.show()\n\n/tmp/ipykernel_7246/182013770.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, asks[i], f\"{round(asks[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngave = karlan_df[\"gave\"].value_counts(normalize=True)\nax = gave.plot(kind=\"pie\", autopct='%1.1f%%', startangle=90, colors=[\"lightblue\",\"lightpink\"])\nplt.title(\"Response rate of Donations\")\nplt.legend(title=\"Gave\", loc=\"upper right\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nax = karlan_df[karlan_df['gave'] == 1].groupby(\"group\")[\"amount\"].mean()\nax.plot(kind='bar', color='lightblue')\n\nplt.title(\"Average Dollar Given Amount by group\")\nplt.xlabel(\"group\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(ax)):\n    plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/1169144851.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngave1_ratio = karlan_df[karlan_df['gave'] == 1].groupby(karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}))['amount'].mean()\ngave1_ratio.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Average Amount Given by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Average Amount Given\")\nplt.xticks(rotation=0)\nfor i in range(len(gave1_ratio)):\n    plt.text(i, gave1_ratio[i], f\"{round(gave1_ratio[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/1509173456.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  gave1_ratio = karlan_df[karlan_df['gave'] == 1].groupby(karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}))['amount'].mean()\n/tmp/ipykernel_7246/1509173456.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, gave1_ratio[i], f\"{round(gave1_ratio[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nax = karlan_df[karlan_df[\"gave\"] == 1].groupby(\"size\")[\"amount\"].mean()\nax.plot(kind='bar', color='lightblue')\nplt.title(\"Average Dollar Given Amount by Match threshold\")\nplt.xlabel(\"size\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(ax)):\n    plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/1746374688.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  ax = karlan_df[karlan_df[\"gave\"] == 1].groupby(\"size\")[\"amount\"].mean()\n/tmp/ipykernel_7246/1746374688.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped_county = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"county\", \"group\"])[\"amount\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county,_ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors)\nplt.title(\"Average Dollar Given Amount by county\")\nplt.xlabel(\"county\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped_county)):\n    plt.text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/3334000609.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped_county = karlan_df.groupby([\"county\", \"group\"])[\"gave\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county,_ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors)\nplt.title(\"Response rate of Donation by county\")\nplt.xlabel(\"county\")\nplt.ylabel(\"Response rate\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped_county)):\n    plt.text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/683103117.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"state\", \"group\"])[\"amount\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors)\n\nplt.title(\"Average Dollar Given Amount by State\")\nplt.xlabel(\"State and Group\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped)):\n    plt.text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/4144588813.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped = karlan_df.groupby([\"state\", \"group\"])[\"gave\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors)\n\nplt.title(\"Response rate of Donation by State\")\nplt.xlabel(\"State and Group\")\nplt.ylabel(\"Response rate\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped)):\n    plt.text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/154559919.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nkarlan_df[['gave', 'median_hhincome', 'pwhite', 'page18_39']].describe()\n\n\n\n\n\n\n\n\ngave\nmedian_hhincome\npwhite\npage18_39\n\n\n\n\ncount\n50083.000000\n48209.000000\n48217.000000\n48217.000000\n\n\nmean\n0.020646\n54815.700533\n0.819599\n0.321694\n\n\nstd\n0.142197\n22027.316665\n0.168560\n0.103039\n\n\nmin\n0.000000\n5000.000000\n0.009418\n0.000000\n\n\n25%\n0.000000\n39181.000000\n0.755845\n0.258311\n\n\n50%\n0.000000\n50673.000000\n0.872797\n0.305534\n\n\n75%\n0.000000\n66005.000000\n0.938827\n0.369132\n\n\nmax\n1.000000\n200001.000000\n1.000000\n0.997544\n\n\n\n\n\n\n\n\nBalance Test\n\nnon-outcome variable: mrm2\n\nfrom scipy import stats\n\n# group by treatment and control\ntreated_mrm2 = karlan_df[karlan_df['group'] == \"treatment\"]['mrm2'].dropna()\ncontrol_mrm2 = karlan_df[karlan_df['group'] == \"control\"]['mrm2'].dropna()\n\n# t-test\nt_stat, p_val = stats.ttest_ind(treated_mrm2, control_mrm2, equal_var=True)\n\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 0.119, p-value: 0.905\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"mrm2\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: mrm2\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  215.360  &lt; .001  ***\nmrm2             0.000      0.000    0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.014 df(1, 50080), p.value 0.905\nNr obs: 50,082 (1 obs. dropped)\n\n\n\nimport statsmodels.api as sm\n\n# regression analysis\nX = sm.add_constant(karlan_df['treatment'])\ny = karlan_df['mrm2']\nmodel = sm.OLS(y, X, missing='drop').fit()\n\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.905\nTime:                        18:01:51   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nnon-outcome variable: median_hhincome\n\ntreated_mh = karlan_df[karlan_df['group'] == \"treatment\"]['median_hhincome'].dropna()\ncontrol_mh = karlan_df[karlan_df['group'] == \"control\"]['median_hhincome'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_mh, control_mh, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.742, p-value: 0.458\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"median_hhincome\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: median_hhincome\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n                 coefficient  std.error  t.value p.value     \nIntercept              0.671      0.006  116.647  &lt; .001  ***\nmedian_hhincome       -0.000      0.000   -0.742   0.458     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.55 df(1, 48207), p.value 0.458\nNr obs: 48,209 (1,874 obs. dropped)\n\n\n\n\nnon-outcome variable: freq\n\ntreated_freq = karlan_df[karlan_df['group'] == \"treatment\"]['freq'].dropna()\ncontrol_freq = karlan_df[karlan_df['group'] == \"control\"]['freq'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_freq, control_freq, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.111, p-value: 0.912\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"freq\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: freq\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  258.746  &lt; .001  ***\nfreq            -0.000      0.000   -0.111   0.912     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.012 df(1, 50081), p.value 0.912\nNr obs: 50,083\n\n\n\n\nnon-outcome variable: female\n\ntreated_female = karlan_df[karlan_df[\"group\"] == \"treatment\"][\"female\"].dropna()\ncontrol_female = karlan_df[karlan_df[\"group\"] == \"control\"][\"female\"].dropna()\n\nt_test, p_val = stats.ttest_ind(treated_female, control_female, equal_var=True)\nprint(f\"t-statistic: {t_test:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -1.758, p-value: 0.079\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"female\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: female\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.669      0.003  266.731  &lt; .001  ***\nfemale          -0.008      0.005   -1.758   0.079    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.092 df(1, 48970), p.value 0.079\nNr obs: 48,972 (1,111 obs. dropped)\n\n\n\n\n\nExperimental Results\n\nCharitable Contribution Made\n\ngave_by_group = karlan_df.groupby(\"group\")[\"gave\"].value_counts(normalize=True).unstack()\ngave_by_group\n\n\n\n\n\n\n\ngave\n0\n1\n\n\ngroup\n\n\n\n\n\n\ncontrol\n0.982142\n0.017858\n\n\ntreatment\n0.977961\n0.022039\n\n\n\n\n\n\n\n\ngave_by_group = karlan_df.groupby(\"group\")[\"gave\"].value_counts(normalize=True).unstack()\ngave_by_group.plot(kind=\"bar\", stacked=True, color=(\"lightblue\", \"lightpink\"))\nplt.title(\"Proportation of people who denoted by Group\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nplt.legend(title=\"Gave\", loc=\"upper right\")\n\nfor i, (gave_by_group, row) in enumerate(gave_by_group.iterrows()):\n    for j, value in enumerate(row):\n        if j == 1:\n            plt.text(i, value+1, f\"{value*100:.1f}%\", ha=\"center\", va=\"top\", fontsize=10)\n        else:\n            plt.text(i, value/2, f\"{value*100:.1f}%\", ha=\"center\", va=\"center\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\n\ntreated_gave = karlan_df[karlan_df['group'] == \"treatment\"]['gave'].dropna()\ncontrol_gave = karlan_df[karlan_df['group'] == \"control\"]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave, control_gave, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 3.101, p-value: 0.002\n\n\n\nfrom statsmodels.discrete.discrete_model import Probit\n\nX = sm.add_constant(karlan_df[\"treatment\"])\nprobit_model = Probit(karlan_df[\"gave\"], X).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        18:01:52   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\n\nratio_gave = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].dropna()\nratio2_gave = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].dropna()\nratio3_gave = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].dropna()\nratio_control_gave = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].dropna()\n\nt_stat, p_val = stats.ttest_ind(ratio_gave, ratio2_gave, equal_var=True)\nprint(f\"ratio1 & ratio2: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt_stat, p_val = stats.ttest_ind(ratio_gave, ratio3_gave, equal_var=True)\nprint(f\"ratio1 & ratio3: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt_stat, p_val = stats.ttest_ind(ratio_gave, ratio_control_gave, equal_var=True)\nprint(f\"ratio1 & control: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt_stat, p_val = stats.ttest_ind(ratio2_gave, ratio3_gave, equal_var=True)\nprint(f\"ratio2 & ratio3: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt_stat, p_val = stats.ttest_ind(ratio2_gave, ratio_control_gave, equal_var=True)\nprint(f\"ratio2 & control: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt_stat, p_val = stats.ttest_ind(ratio3_gave, ratio_control_gave, equal_var=True)\nprint(f\"ratio3 & control: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nratio1 & ratio2: t-statistic: -0.965, p-value: 0.335\nratio1 & ratio3: t-statistic: -1.015, p-value: 0.310\nratio1 & control: t-statistic: 1.730, p-value: 0.084\nratio2 & ratio3: t-statistic: -0.050, p-value: 0.960\nratio2 & control: t-statistic: 2.804, p-value: 0.005\nratio3 & control: t-statistic: 2.859, p-value: 0.004\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"gave\", evar=\"ratio\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : gave\nExplanatory variables: ratio\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\nratio[1]         0.003      0.002    1.661   0.097    .\nratio[2]         0.005      0.002    2.744   0.006   **\nratio[3]         0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.665 df(3, 50079), p.value 0.012\nNr obs: 50,083\n\n\n\nresponse_rate_ratio1 = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].mean().round(4)\nresponse_rate_ratio2 = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].mean().round(4)\nresponse_rate_ratio3 = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].mean().round(4)\nresponse_rate_control = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].mean().round(4)\nresponse_rate = pd.Series({\n    \"ratio1\": response_rate_ratio1,\n    \"ratio2\": response_rate_ratio2,\n    \"ratio3\": response_rate_ratio3,\n    \"control\": response_rate_control\n})\nresponse_rate\nresponse_rate.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Response Rate by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Response Rate\")\nplt.xticks(rotation=0)\n\nfor i, value in enumerate(response_rate):\n    plt.text(i, value, f\"{value*100:.2f}%\", ha=\"center\", va=\"bottom\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\n\ntreated_amount = karlan_df[karlan_df['group'] == \"treatment\"]['amount'].dropna()\ncontrol_amount = karlan_df[karlan_df['group'] == \"control\"]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_amount, control_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 1.861, p-value: 0.063\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"amount\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.666      0.002  314.669  &lt; .001  ***\namount           0.000      0.000    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.461 df(1, 50081), p.value 0.063\nNr obs: 50,083\n\n\n\ntreated_gave_amount = karlan_df[(karlan_df['group'] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\ncontrol_gave_amount = karlan_df[(karlan_df['group'] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave_amount, control_gave_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.581, p-value: 0.561\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df[karlan_df[\"gave\"] == 1]}, rvar=\"treatment\", evar=\"amount\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept         0.72      0.021   35.055  &lt; .001  ***\namount           -0.00      0.000   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.001\nF-statistic: 0.337 df(1, 1032), p.value 0.561\nNr obs: 1,034\n\n\n\ntreated_gave_amount = karlan_df[(karlan_df[\"group\"] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_treated_gave_amount = treated_gave_amount.mean()\n\ntreated_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7)\nplt.axvline(avg_treated_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_treated_gave_amount:.2f}\")\nplt.legend()\nplt.title(\"Distribution of Gave Amount for Treatment Group\")\nplt.xlabel(\"Amount\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\n\ncontrol_gave_amount = karlan_df[(karlan_df[\"group\"] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_control_gave_amount = control_gave_amount.mean()\ncontrol_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7)\nplt.axvline(avg_control_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_control_gave_amount:.2f}\")\nplt.legend()\nplt.title(\"Distribution of Gave Amount for Control Group\")\nplt.xlabel(\"Amount\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(0)\np_control = 0.018\np_treatment = 0.022\nn_control = 100_000\nn_treatment = 10_000\n\n# Simulate donatioin outcomes (Bernoulli distribution)\ncontrol = np.random.binomial(1, p_control, size=n_control)\ntreatment = np.random.binomial(1, p_treatment, size=n_treatment)\n\n# Sample the first 10,000 control observations to match treatment\ncontrol_sample = control[:n_treatment]\n\n# Difference = treatment - control\ndiffs = treatment - control_sample\n\n# Calculate the cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_treatment + 1)\n\n# Plot the cumulative average and the true difference line\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative average of difference\", color=\"lightblue\")\nplt.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True difference (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Law of Large Numbers Simulation\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(42)\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n\nfig, axes = plt.subplots(2, 2, figsize=(8, 8))\naxes = axes.flatten()\n\nfor idx, n in enumerate(sample_sizes):\n    diffs = []\n\n    # Simulate n_simulations times\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        diff = np.mean(treatment) - np.mean(control)\n        diffs.append(diff)\n\n    # Plot the histogram of differences\n    ax = axes[idx]\n    ax.hist(diffs, bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.75)\n    ax.axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Zero\")\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Mean Difference (Treatment - Control)\")\n    ax.set_ylabel(\"Frequency\")\n    ax.legend()\n\n# Add a title for the entire figure\nplt.suptitle(\"Central Limit Theorem Simulation\\nEffect of Sample Size on Distribution of Mean Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html",
    "href": "projects/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this large-scale natural field experiment, Karlan and List collaborated with a liberal nonprofit organization in the United States to examine how different price framing and incentives affect individual charitable giving behavior. The sample consisted of 50,083 individuals who had donated to the organization at least once since 1991. Participants were randomly assigned to either a control group or one of several treatment groups. The control group received a standard direct mail fundraising letter, while the treatment groups received letters that included an announcement of a matching grant or challenge grant offer.\nThe matching grant treatments varied systematically along three key dimensions: (1) the match ratio ($1:$1, $2:$1, and $3:$1), (2) the maximum size of the matching gift ($25,000, $50,000, $100,000, or unstated), and (3) the suggested donation amount (based on the recipient’s past donation, set at 1x, 1.25x, or 1.5x of their highest previous gift). This randomized design enabled the researchers to isolate the effect of each element on donation behavior.\nThe goal was to assess whether and how the “price” of giving, as framed by these match offers, influences both the likelihood of giving and the amount donated. The experiment provides a rare opportunity to observe actual behavior—rather than stated intentions—in a real-world charitable context, thereby generating high external validity. It also allows for an investigation of heterogeneous effects, such as differences in responsiveness across political geographies (“red” vs. “blue” states) and donor history.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#introduction",
    "href": "projects/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this large-scale natural field experiment, Karlan and List collaborated with a liberal nonprofit organization in the United States to examine how different price framing and incentives affect individual charitable giving behavior. The sample consisted of 50,083 individuals who had donated to the organization at least once since 1991. Participants were randomly assigned to either a control group or one of several treatment groups. The control group received a standard direct mail fundraising letter, while the treatment groups received letters that included an announcement of a matching grant or challenge grant offer.\nThe matching grant treatments varied systematically along three key dimensions: (1) the match ratio ($1:$1, $2:$1, and $3:$1), (2) the maximum size of the matching gift ($25,000, $50,000, $100,000, or unstated), and (3) the suggested donation amount (based on the recipient’s past donation, set at 1x, 1.25x, or 1.5x of their highest previous gift). This randomized design enabled the researchers to isolate the effect of each element on donation behavior.\nThe goal was to assess whether and how the “price” of giving, as framed by these match offers, influences both the likelihood of giving and the amount donated. The experiment provides a rare opportunity to observe actual behavior—rather than stated intentions—in a real-world charitable context, thereby generating high external validity. It also allows for an investigation of heterogeneous effects, such as differences in responsiveness across political geographies (“red” vs. “blue” states) and donor history.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#data",
    "href": "projects/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe bar chart indicates that approximately 66.7% of individuals belong to the “treatment” group, while 33.3% are in the “control” group.\n\n\n\n\n\n\n\n\n\nThe bar chart indicates that approximately 33.32% of individuals belonged to the “control” group, while the 1:1, 2:1, and 3:1 match ratios each accounted for about 22.23% of the sample.\n\n\n\n\n\n\n\n\n\nThe bar chart shows that approximately 33.32% of individuals belonged to the “control” group as well, while the unstated, $25,000, $50,000, and $100,00 match thresholds each accounted for about 16.66% of the sample.\n\n\n\n\n\n\n\n\n\nThe bar chart illustrates that roughly 33.32% of individuals were assigned to the control group, whereas each of the groups receiving suggested donation amounts of 1x, 1.25x, and 1.50x their previous highest contribution represented approximately 22.23% of the sample.\n\n\n\n\n\n\n\n\n\nThe pie chart shows that 2.1% of individuals made a donation of any amount.\n\n\n\n\n\n\n\n\n\nThe average donation amounts for the control and treatment groups are similar, at $46 and $44 respectively.\n\n\n\n\n\n\n\n\n\nBased on the match ratios, we can see that the control group has the highest average donation amount at $46. The 1:1 and 2:1 match groups follow closely, both averaging $45, while the 3:1 group has the lowest average, at only $41.\n\n\n\n\n\n\n\n\n\nThe bar chart illustrates the average donation amount across different match threshold conditions. Among all groups, the $25,000 match threshold yielded the highest average donation at $49. Both the control group and the group with an unstated match threshold followed, with an average donation of $46. In contrast, the $50,000 and $100,000 thresholds resulted in lower average donations, at $40 and $41 respectively. These findings suggest that a lower or unspecified match cap may be more effective at encouraging larger individual donations compared to higher threshold amounts.\n\n\n\n\n\n\n\n\n\nThe charts show the average donation amount and response rate across counties categorized by political affiliation (blue vs. red) and treatment type (control vs. matching grant).\nIn terms of average donation amount, the blue-control group gave the most ($46), while the treatment groups in both counties had slightly lower averages—$45 in blue counties and $43 in red counties. Notably, the red-treatment group had the lowest average donation.\nAs for the response rate, matching treatments increased participation in both regions. In blue counties, the response rose from 1.76% to 2.06%, while in red counties it increased more significantly from 1.82% to 2.33%.\nOverall, while matching grants improved the likelihood of donating, they did not necessarily increase the amount donated per person. The effect on response rate was particularly strong in red counties.\n\n\n\n\n\n\n\n\n\nThe charts provide insights into donation behavior across political states (blue vs. red) and treatment conditions (control vs. matching grant).\nIn terms of average donation amount, the highest contribution was observed in the red-control group at $47, followed by both the blue-control and red-treatment groups at $45. The blue-treatment group recorded the lowest average at $42, suggesting that matching treatments may slightly reduce the average donation amount in blue states.\nLooking at the response rate, matching grants had a positive effect in both political contexts, but the effect was particularly strong in red states. The red-treatment group showed the highest response rate at 2.34%, a significant increase from 1.46% in the red-control group. In blue states, the increase was more modest—from 2.0% to 2.11%.\nThese findings reinforce a key insight from Karlan and List (2007): matching grants boost participation (response rate), especially in red states, but do not necessarily lead to higher donation amounts per individual.\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nnon-outcome variable: mrm2\n\n\nfrom scipy import stats\n\n# group by treatment and control\ntreated_mrm2 = karlan_df[karlan_df['group'] == \"treatment\"]['mrm2'].dropna()\ncontrol_mrm2 = karlan_df[karlan_df['group'] == \"control\"]['mrm2'].dropna()\n\n# t-test\nt_stat, p_val = stats.ttest_ind(treated_mrm2, control_mrm2, equal_var=True)\n\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 0.119, p-value: 0.905\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"mrm2\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: mrm2\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  215.360  &lt; .001  ***\nmrm2             0.000      0.000    0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nnon-outcome variable: median_hhincome\n\n\ntreated_mh = karlan_df[karlan_df['group'] == \"treatment\"]['median_hhincome'].dropna()\ncontrol_mh = karlan_df[karlan_df['group'] == \"control\"]['median_hhincome'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_mh, control_mh, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.742, p-value: 0.458\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"median_hhincome\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: median_hhincome\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n                 coefficient  std.error  t.value p.value     \nIntercept              0.671      0.006  116.647  &lt; .001  ***\nmedian_hhincome       -0.000      0.000   -0.742   0.458     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nnon-outcome variable: freq\n\n\ntreated_freq = karlan_df[karlan_df['group'] == \"treatment\"]['freq'].dropna()\ncontrol_freq = karlan_df[karlan_df['group'] == \"control\"]['freq'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_freq, control_freq, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.111, p-value: 0.912\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"freq\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: freq\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  258.746  &lt; .001  ***\nfreq            -0.000      0.000   -0.111   0.912     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nnon-outcome variable: female\n\n\ntreated_female = karlan_df[karlan_df[\"group\"] == \"treatment\"][\"female\"].dropna()\ncontrol_female = karlan_df[karlan_df[\"group\"] == \"control\"][\"female\"].dropna()\n\nt_test, p_val = stats.ttest_ind(treated_female, control_female, equal_var=True)\nprint(f\"t-statistic: {t_test:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -1.758, p-value: 0.079\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"female\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: female\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.669      0.003  266.731  &lt; .001  ***\nfemale          -0.008      0.005   -1.758   0.079    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTo assess the validity of the random assignment, we tested several non-outcome variables—mrm2, median_hhincome, freq, and female—for balance between the treatment and control groups. Each variable was analyzed using both an independent-samples t-test and a linear regression, with the treatment assignment as the dependent variable. Across all tests, there were no statistically significant differences at the 95% confidence level (all p-values &gt; 0.05), suggesting that the two groups were comparable in terms of their baseline characteristics.\nOne exception worth noting is the variable female, which showed a p-value of 0.079—non-significant at the conventional 5% threshold but approaching marginal significance at the 10% level. This variable may be considered in further robustness checks as a potential confounder.\nThese findings mirror the results presented in Table 1 of Karlan and List (2007), which serves to confirm the success of the randomization. By establishing that the treatment and control groups are balanced on observable covariates, we strengthen the internal validity of the experimental design and provide a solid foundation for interpreting causal treatment effects in subsequent analyses."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#experimental-results",
    "href": "projects/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\ngave_by_group = karlan_df.groupby(\"group\")[\"gave\"].value_counts(normalize=True).unstack()\ngave_by_group.plot(kind=\"bar\", stacked=True, color=(\"lightblue\", \"lightpink\"))\nplt.title(\"Proportation of people who denoted by Group\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nplt.legend(title=\"Gave\", loc=\"upper right\")\n\nfor i, (gave_by_group, row) in enumerate(gave_by_group.iterrows()):\n    for j, value in enumerate(row):\n        if j == 1:\n            plt.text(i, value+1, f\"{value*100:.1f}%\", ha=\"center\", va=\"top\", fontsize=10)\n        else:\n            plt.text(i, value/2, f\"{value*100:.1f}%\", ha=\"center\", va=\"center\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\nThis bar chart shows the proportion of people who donated, broken down by group. We can see that 1.8% of individuals in the control group made a donation, compared to 2.2% in the treatment group.\n\ntreated_gave = karlan_df[karlan_df['group'] == \"treatment\"]['gave'].dropna()\ncontrol_gave = karlan_df[karlan_df['group'] == \"control\"]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave, control_gave, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 3.101, p-value: 0.002\n\n\n\nStatistical Results & Interpretation\nThe t-test comparing donation rates between the treatment and control groups produced a statistically significant result (p-value = 0.002), indicating a meaningful difference in the likelihood of making a donation. Specifically, individuals who received the matching grant treatment were significantly more likely to donate than those who received the standard fundraising letter.\nTogether, these results align with Table 2A, Panel A in Karlan and List (2007), which shows that the matching grant treatment increases the donation response rate from approximately 1.8% in the control group to 2.2% in the treatment group. Although this change may appear small in absolute terms, it is statistically reliable and meaningful in large-scale fundraising.\n\n\nWhat We Learn About Human Behavior\nThese findings suggest that even simple changes in how charitable giving opportunities are framed—such as the use of a matching grant—can significantly influence behavior. People appear to be more willing to give when they perceive that their contribution will be amplified or matched by another donor. This reflects the importance of social cues and perceived impact in motivating altruistic behavior, and highlights how thoughtfully designed messages can boost participation in public good provision.\n\n\nProbit Regression Summary\n\nimport statsmodels.api as sm\nfrom statsmodels.discrete.discrete_model import Probit\n\nX = sm.add_constant(karlan_df[\"treatment\"])\nprobit_model = Probit(karlan_df[\"gave\"], X).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 28 May 2025   Pseudo R-squ.:               0.0009783\nTime:                        15:51:03   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nTo replicate the results presented in Table 3, Column 1 of Karlan and List (2007), I conducted a probit regression where the outcome variable was whether an individual made any charitable donation, and the explanatory variable was assignment to the treatment or control group. The regression results indicate that assignment to the treatment group significantly increased the likelihood of donating.\nThe estimated coefficient on the treatment variable was 0.0868, with a p-value of 0.002, indicating strong statistical significance at the 1% level. This positive and significant result aligns closely with the original paper’s findings, where the authors report a similar treatment effect of approximately 0.087.\nThese findings confirm that the treatment intervention—providing a matching grant—has a statistically meaningful impact on charitable behavior, increasing the probability that individuals choose to give. The successful replication supports the robustness of the original study’s conclusion: that subtle framing strategies in fundraising can effectively encourage higher participation in charitable giving.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nratio_gave = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].dropna()\nratio2_gave = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].dropna()\nratio3_gave = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].dropna()\nratio_control_gave = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].dropna()\n\npairs = [\n    (\"ratio1 & ratio2\", ratio_gave, ratio2_gave),\n    (\"ratio1 & ratio3\", ratio_gave, ratio3_gave),\n    (\"ratio1 & control\", ratio_gave, ratio_control_gave),\n    (\"ratio2 & ratio3\", ratio2_gave, ratio3_gave),\n    (\"ratio2 & control\", ratio2_gave, ratio_control_gave),\n    (\"ratio3 & control\", ratio3_gave, ratio_control_gave),\n]\n\nfor label, group1, group2 in pairs:\n    t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=True)\n    print(f\"{label}: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nratio1 & ratio2: t-statistic: -0.965, p-value: 0.335\nratio1 & ratio3: t-statistic: -1.015, p-value: 0.310\nratio1 & control: t-statistic: 1.730, p-value: 0.084\nratio2 & ratio3: t-statistic: -0.050, p-value: 0.960\nratio2 & control: t-statistic: 2.804, p-value: 0.005\nratio3 & control: t-statistic: 2.859, p-value: 0.004\n\n\n\nMatch Ratio T-Test Summary\nTo evaluate whether the size of the match ratio influences charitable behavior, a series of t-tests were conducted comparing donation rates across different match treatments (1:1, 2:1, 3:1) and a control group. This analysis was designed to test the authors’ suggestion in the paper that larger match ratios do not necessarily lead to higher donation rates.\nThe results show no statistically significant differences in donation likelihood between the 1:1, 2:1, and 3:1 match groups (all p-values &gt; 0.3). This suggests that increasing the match ratio does not significantly increase the probability that someone will donate, relative to the baseline 1:1 offer.\nHowever, when comparing each match ratio group to the control group, both the 2:1 and 3:1 ratios led to statistically significant increases in donation rates (p = 0.005 and p = 0.004, respectively), whereas the 1:1 vs. control difference was not significant (p = 0.084).\nThese findings support the authors’ claim on page 8 of the paper that, although offering a match increases the probability of donation, increasing the match ratio beyond 1:1 does not further enhance donation behavior. In other words, it is the presence of a match, rather than its generosity, that seems to matter most.\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"gave\", evar=\"ratio\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : gave\nExplanatory variables: ratio\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\nratio[1]         0.003      0.002    1.661   0.097    .\nratio[2]         0.005      0.002    2.744   0.006   **\nratio[3]         0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nRegression Summary: Match Ratio and Donation Behavior\nTo further assess whether the size of the match ratio affects donation behavior, I ran a linear regression using indicator variables for each match ratio group (ratio1, ratio2, and ratio3) to predict the probability of making a donation (gave). The regression results reveal that the match ratio does have a measurable impact on donation rates.\nThe intercept of 0.018 represents the baseline donation rate for the control group (1.8%). Compared to this baseline: • The 1:1 match (ratio1) increased donation rates by 0.3 percentage points, but this effect is not statistically significant (p = 0.097). • The 2:1 and 3:1 match groups (ratio2 and ratio3) both show statistically significant increases of 0.5 percentage points (p = 0.006 and p = 0.005, respectively).\nThese findings align with the earlier t-test results, reinforcing the conclusion that larger match ratios (2:1 and 3:1) lead to significantly higher response rates compared to the control group, whereas the 1:1 match has a smaller and statistically weaker effect.\nTaken together, the regression analysis supports the interpretation in the original paper that while offering a match increases donations, increasing the generosity of the match beyond 1:1 may yield modest but statistically significant gains. However, the differences between match ratios themselves remain relatively small.\n\nresponse_rate_ratio1 = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].mean().round(4)\nresponse_rate_ratio2 = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].mean().round(4)\nresponse_rate_ratio3 = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].mean().round(4)\nresponse_rate_control = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].mean().round(4)\nresponse_rate = pd.Series({\n    \"ratio1\": response_rate_ratio1,\n    \"ratio2\": response_rate_ratio2,\n    \"ratio3\": response_rate_ratio3,\n    \"control\": response_rate_control\n})\nresponse_rate\nresponse_rate.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Response Rate by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Response Rate\")\nplt.xticks(rotation=0)\n\nfor i, value in enumerate(response_rate):\n    plt.text(i, value, f\"{value*100:.2f}%\", ha=\"center\", va=\"bottom\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSummary of Response Rate by Match Ratio:\nTo evaluate the effectiveness of different match ratios on donation behavior, I calculated the donation response rates for the control group and each treatment group (1:1, 2:1, and 3:1 match ratios). The results reveal a clear pattern: any match treatment increases the likelihood of donation compared to no match, but increasing the match ratio does not substantially improve the response rate beyond the baseline 1:1 match. • Control group response rate: 1.79% • 1:1 match (ratio1): 2.07% • 2:1 match (ratio2): 2.26% • 3:1 match (ratio3): 2.27%\nThe increase from the control group to any treatment group is notable—about 0.3% to 0.5 percentage points—confirming that offering a matching grant increases participation. However, the differences among the 1:1, 2:1, and 3:1 ratios themselves are minimal, with a maximum difference of just 0.2 percentage points, suggesting diminishing returns to increasing the generosity of the match.\nThese findings align with the authors’ conclusion in the paper that the presence of a match matters more than the size of the match. From a practical perspective, this implies that organizations may not need to offer high match ratios to achieve significant gains in donor participation.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\ntreated_amount = karlan_df[karlan_df['group'] == \"treatment\"]['amount'].dropna()\ncontrol_amount = karlan_df[karlan_df['group'] == \"control\"]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_amount, control_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 1.861, p-value: 0.063\n\n\n\nDoes treatment affect the average donation amount?\nIn the first part of the analysis, a t-test was used to compare the donation amounts between the treatment and control groups. The results show that the treatment group donated slightly more on average than the control group, with a t-statistic of 1.861 and a p-value of 0.063. This value is close to, but does not reach, the conventional 5% threshold for statistical significance.\nThis suggests that the matching grant treatment may have some effect on the amount donated, but the evidence is not strong enough to confirm a clear impact. In other words, we find weak evidence that the treatment could increase the average donation amount, but it does not support a strong causal conclusion.\n\nreg = rsm.model.regress({\"karlan\": karlan_df[karlan_df[\"gave\"] == 1]}, rvar=\"treatment\", evar=\"amount\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept         0.72      0.021   35.055  &lt; .001  ***\namount           -0.00      0.000   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nAmong donors only, does treatment affect the donation amount?\nIn the second part of the analysis, a linear regression was conducted using only those individuals who made a donation, in order to assess whether the treatment influenced the amount donated among actual donors. The result shows that the coefficient on treatment is essentially zero (p = 0.561), indicating no significant relationship between treatment status and donation amount among those who gave.\nThis implies that while the matching grant treatment may encourage more people to donate, it does not significantly affect how much they donate once they’ve decided to give. The primary effect of the treatment appears to lie in influencing the decision to donate, not the size of the donation.\nAdditionally, because this analysis is limited to donors only and treatment is not randomly assigned within this subset (it’s conditioned on gave = 1), the result cannot be interpreted causally, and should be treated as descriptive.\n\ntreated_gave_amount = karlan_df[(karlan_df[\"group\"] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_treated_gave_amount = treated_gave_amount.mean()\n\ncontrol_gave_amount = karlan_df[(karlan_df[\"group\"] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_control_gave_amount = control_gave_amount.mean()\nfig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n\n# Plot for Control Group\ncontrol_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7, ax=axes[0])\naxes[0].axvline(avg_control_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_control_gave_amount:.2f}\")\naxes[0].legend()\naxes[0].set_title(\"Distribution of Gave Amount for Control Group\", fontsize=10)\naxes[0].set_xlabel(\"Amount\")\naxes[0].set_ylabel(\"Frequency\")\n\n# Plot for Treatment Group\ntreated_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7, ax=axes[1])\naxes[1].axvline(avg_treated_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_treated_gave_amount:.2f}\")\naxes[1].legend()\naxes[1].set_title(\"Distribution of Gave Amount for Treatment Group\", fontsize=10)\naxes[1].set_xlabel(\"Amount\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#simulation-experiment",
    "href": "projects/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers Simulation\nThe plot below visualizes the Law of Large Numbers using a simulation of donation behavior. Specifically, I simulated 100,000 random draws from the control group distribution and 10,000 random draws from the treatment group distribution, then calculated a vector of 10,000 differences between a randomly drawn treatment value and a randomly drawn control value. The chart plots the cumulative average of those differences as the number of simulations increases.\nThe red dashed line represents the true average difference in means, which is 0.004. As shown in the graph, the cumulative average fluctuates more heavily at the beginning when the number of simulations is small, but gradually stabilizes and converges toward the true value as the number of simulations increases. This behavior is a direct demonstration of the Law of Large Numbers, which states that the average of a large number of independent observations will converge to the expected value.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(0)\np_control = 0.018\np_treatment = 0.022\nn_control = 100_000\nn_treatment = 10_000\n\n# Simulate donatioin outcomes (Bernoulli distribution)\ncontrol = np.random.binomial(1, p_control, size=n_control)\ntreatment = np.random.binomial(1, p_treatment, size=n_treatment)\n\n# Sample the first 10,000 control observations to match treatment\ncontrol_sample = control[:n_treatment]\n\n# Difference = treatment - control\ndiffs = treatment - control_sample\n\n# Calculate the cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_treatment + 1)\n\n# Plot the cumulative average and the true difference line\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative average of difference\", color=\"lightblue\")\nplt.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True difference (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Law of Large Numbers Simulation\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nConclusion\nThis simulation confirms that the cumulative average difference between treatment and control groups indeed approaches the true difference in means as the number of samples grows. It visually reinforces a key statistical principle: with enough data, we can reliably estimate underlying population parameters, even when working with noisy or variable outcomes.\n\n\nCentral Limit Theorem Simulation\nThe set of histograms above illustrates the Central Limit Theorem (CLT) in action by showing how the distribution of sample mean differences (treatment minus control) changes with increasing sample sizes. For each sample size (50, 200, 500, and 1000), I repeatedly drew random samples from the treatment and control distributions, computed their mean difference, and repeated this process 1000 times to generate a distribution of average differences.\n\nSample size = 50: The distribution is wide and irregular, showing high variability. The zero line lies close to the center but not perfectly symmetric, and the distribution appears somewhat dispersed.\nSample size = 200: The histogram begins to resemble a normal distribution. The peak becomes more centered around zero, and the variance shrinks.\nSample size = 500: The distribution is tighter and more symmetric. Zero is clearly in the center, showing reduced sampling variability.\nSample size = 1000: The distribution becomes even more narrow and bell-shaped, strongly centered around zero. The noise has largely averaged out.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(42)\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n\nfig, axes = plt.subplots(2, 2, figsize=(8, 8))\naxes = axes.flatten()\n\nfor idx, n in enumerate(sample_sizes):\n    diffs = []\n\n    # Simulate n_simulations times\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        diff = np.mean(treatment) - np.mean(control)\n        diffs.append(diff)\n\n    # Plot the histogram of differences\n    ax = axes[idx]\n    ax.hist(diffs, bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.75)\n    ax.axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Zero\")\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Mean Difference (Treatment - Control)\")\n    ax.set_ylabel(\"Frequency\")\n    ax.legend()\n\n# Add a title for the entire figure\nplt.suptitle(\"Central Limit Theorem Simulation\\nEffect of Sample Size on Distribution of Mean Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\n\nConclusion\nThese plots clearly demonstrate the Central Limit Theorem: as the sample size increases, the distribution of the sample mean differences becomes more normal and converges toward the true mean (which is close to zero in this case). Importantly, zero is consistently near the center of the distribution, indicating that under random sampling, there is no systematic difference between the treatment and control means—exactly what we expect under the null hypothesis.\nThis reinforces a key statistical principle: larger sample sizes lead to more stable and reliable estimates, and support valid inference based on the sampling distribution of the mean."
  },
  {
    "objectID": "projects/HW1/index.html",
    "href": "projects/HW1/index.html",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects/HW1/HW1.html",
    "href": "projects/HW1/HW1.html",
    "title": "Data Description",
    "section": "",
    "text": "# pip install pandas pyreadstat\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pyrsm as rsm\n\n\nkarlan_df = pd.read_stata('karlan_list_2007.dta')\nkarlan_df.to_csv('karlan_list_2007.csv', index=False)\n\n\nkarlan_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\nkarlan_df.isnull().sum()\n\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n\n\n\ngroup_cols = [\"treatment\", \"control\"]\nratio_cols = [\"ratio\", \"ratio2\", \"ratio3\"]\nsize_cols = [\"size25\", \"size50\", \"size100\", \"sizeno\"]\naskd_cols = [\"ask\", \"askd1\", \"askd2\", \"askd3\"]\nask_cols = [\"ask1\", \"ask2\", \"ask3\"]\nstate_cols = [\"red0\", \"blue0\"]\ncounty_cols = [\"redcty\", \"bluecty\"]\n\n\nkarlan_df[\"group\"] = karlan_df[group_cols].idxmax(axis=1)\nkarlan_df[\"county\"] = karlan_df[county_cols].idxmax(axis=1).map({\"redcty\": \"red\", \"bluecty\": \"blue\"})\nkarlan_df[\"state\"] = karlan_df[state_cols].idxmax(axis=1).map({\"red0\": \"red\", \"blue0\": \"blue\"})\nkarlan_df\n\n/tmp/ipykernel_38392/2551348540.py:2: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n  karlan_df[\"county\"] = karlan_df[county_cols].idxmax(axis=1).map({\"redcty\": \"red\", \"bluecty\": \"blue\"})\n/tmp/ipykernel_38392/2551348540.py:3: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n  karlan_df[\"state\"] = karlan_df[state_cols].idxmax(axis=1).map({\"red0\": \"red\", \"blue0\": \"blue\"})\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\ngroup\ncounty\nstate\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\ncontrol\nblue\nblue\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\ncontrol\nred\nblue\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\ntreatment\nblue\nblue\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\ntreatment\nred\nblue\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\ntreatment\nblue\nred\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\ntreatment\nblue\nred\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\ncontrol\nblue\nblue\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\ncontrol\nred\nblue\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\ntreatment\nred\nblue\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\ntreatment\nblue\nblue\n\n\n\n\n50083 rows × 54 columns\n\n\n\n\ngroup = karlan_df[\"group\"].value_counts(normalize=True)\ngroup.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Group Distribution\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nfor i in range(len(group)):\n    plt.text(i, group[i], f\"{round(group[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n\ngroup = karlan_df[\"group\"].value_counts(normalize=True)\ngroup.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Group Distribution\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nfor i in range(len(group)):\n    plt.text(i, group[i], f\"{round(group[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/2886523009.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, group[i], f\"{round(group[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nratios = karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}).value_counts(normalize=True)\nratios.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Match Ratios\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nfor i in range(len(ratios)):\n    plt.text(i, ratios[i], f\"{round(ratios[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/3747464993.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ratios[i], f\"{round(ratios[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nsizes = karlan_df[\"size\"].value_counts(normalize=True)\nsizes.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Match thresholds\")\nplt.xlabel(\"Size\")\nplt.ylabel(\"Proportion\")\nfor i in range(len(sizes)):\n    plt.text(i, sizes[i], f\"{round(sizes[i]*100, 2)}%\", ha='center', va='bottom')\nplt.xticks(rotation=0)\nplt.show()\n\n/tmp/ipykernel_38392/248569292.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, sizes[i], f\"{round(sizes[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nasks = karlan_df[\"ask\"].value_counts(normalize=True)\nasks.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Highest previous contribution (for suggestion)\")\nplt.xlabel(\"Ask\")\nplt.ylabel(\"Proportion\")\nfor i in range(len(asks)):\n    plt.text(i, asks[i], f\"{round(asks[i]*100, 2)}%\", ha='center', va='bottom')\nplt.xticks(rotation=0)\nplt.show()\n\n/tmp/ipykernel_38392/182013770.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, asks[i], f\"{round(asks[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngave = karlan_df[\"gave\"].value_counts(normalize=True)\nax = gave.plot(kind=\"pie\", autopct='%1.1f%%', startangle=90, colors=[\"lightblue\",\"lightpink\"])\nplt.title(\"Response rate of Donations\")\nplt.legend(title=\"Gave\", loc=\"upper right\")\nplt.show()\n\n\n\n\n\n\n\n\n\nax = karlan_df[karlan_df['gave'] == 1].groupby(\"group\")[\"amount\"].mean()\nax.plot(kind='bar', color='lightblue')\n\nplt.title(\"Average Dollar Given Amount by group\")\nplt.xlabel(\"group\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(ax)):\n    plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/1169144851.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngave1_ratio = karlan_df[karlan_df['gave'] == 1].groupby(karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}))['amount'].mean()\ngave1_ratio.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Average Amount Given by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Average Amount Given\")\nplt.xticks(rotation=0)\nfor i in range(len(gave1_ratio)):\n    plt.text(i, gave1_ratio[i], f\"{round(gave1_ratio[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/1509173456.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  gave1_ratio = karlan_df[karlan_df['gave'] == 1].groupby(karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}))['amount'].mean()\n/tmp/ipykernel_38392/1509173456.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, gave1_ratio[i], f\"{round(gave1_ratio[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nax = karlan_df[karlan_df[\"gave\"] == 1].groupby(\"size\")[\"amount\"].mean()\nax.plot(kind='bar', color='lightblue')\nplt.title(\"Average Dollar Given Amount by Match threshold\")\nplt.xlabel(\"size\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(ax)):\n    plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/1746374688.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  ax = karlan_df[karlan_df[\"gave\"] == 1].groupby(\"size\")[\"amount\"].mean()\n/tmp/ipykernel_38392/1746374688.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=False)\n\n# Plot 1: Average Dollar Given Amount by county\ngrouped_county = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"county\", \"group\"])[\"amount\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county, _ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors, ax=axes[0])\naxes[0].set_title(\"Average Dollar Given Amount by county\")\naxes[0].set_xlabel(\"County\")\naxes[0].set_ylabel(\"Average Amount\")\naxes[0].tick_params(axis='x', rotation=0, labelsize=9)  # Adjust the fontsize here\nfor i in range(len(grouped_county)):\n    axes[0].text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\n\n# Plot 2: Response rate of Donation by county\ngrouped_county = karlan_df.groupby([\"county\", \"group\"])[\"gave\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county, _ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors, ax=axes[1])\naxes[1].set_title(\"Response rate of Donation by county\")\naxes[1].set_xlabel(\"County\")\naxes[1].set_ylabel(\"Response rate\")\naxes[1].tick_params(axis='x', rotation=0, labelsize=9)  # Adjust the fontsize here\nfor i in range(len(grouped_county)):\n    axes[1].text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_38392/2640907076.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  axes[0].text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\n/tmp/ipykernel_38392/2640907076.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  axes[1].text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped_county = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"county\", \"group\"])[\"amount\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county,_ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors)\nplt.title(\"Average Dollar Given Amount by county\")\nplt.xlabel(\"county\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped_county)):\n    plt.text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/3334000609.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped_county = karlan_df.groupby([\"county\", \"group\"])[\"gave\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county,_ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors)\nplt.title(\"Response rate of Donation by county\")\nplt.xlabel(\"county\")\nplt.ylabel(\"Response rate\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped_county)):\n    plt.text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/683103117.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=False)\n\n# Plot 1: Average Dollar Given Amount by State\ngrouped = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"state\", \"group\"])[\"amount\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors, ax=axes[0])\naxes[0].set_title(\"Average Dollar Given Amount by State\")\naxes[0].set_xlabel(\"State and Group\")\naxes[0].set_ylabel(\"Average Amount\")\naxes[0].tick_params(axis='x', rotation=0)\nfor i in range(len(grouped)):\n    axes[0].text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\n\n# Plot 2: Response Rate of Donation by State\ngrouped = karlan_df.groupby([\"state\", \"group\"])[\"gave\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors, ax=axes[1])\naxes[1].set_title(\"Response Rate of Donation by State\")\naxes[1].set_xlabel(\"State and Group\")\naxes[1].set_ylabel(\"Response Rate\")\naxes[1].tick_params(axis='x', rotation=0)\nfor i in range(len(grouped)):\n    axes[1].text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_38392/3635852891.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  axes[0].text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\n/tmp/ipykernel_38392/3635852891.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  axes[1].text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"state\", \"group\"])[\"amount\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors)\n\nplt.title(\"Average Dollar Given Amount by State\")\nplt.xlabel(\"State and Group\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped)):\n    plt.text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/4144588813.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped = karlan_df.groupby([\"state\", \"group\"])[\"gave\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors)\n\nplt.title(\"Response rate of Donation by State\")\nplt.xlabel(\"State and Group\")\nplt.ylabel(\"Response rate\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped)):\n    plt.text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/154559919.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nkarlan_df[['gave', 'median_hhincome', 'pwhite', 'page18_39']].describe()\n\n\n\n\n\n\n\n\ngave\nmedian_hhincome\npwhite\npage18_39\n\n\n\n\ncount\n50083.000000\n48209.000000\n48217.000000\n48217.000000\n\n\nmean\n0.020646\n54815.700533\n0.819599\n0.321694\n\n\nstd\n0.142197\n22027.316665\n0.168560\n0.103039\n\n\nmin\n0.000000\n5000.000000\n0.009418\n0.000000\n\n\n25%\n0.000000\n39181.000000\n0.755845\n0.258311\n\n\n50%\n0.000000\n50673.000000\n0.872797\n0.305534\n\n\n75%\n0.000000\n66005.000000\n0.938827\n0.369132\n\n\nmax\n1.000000\n200001.000000\n1.000000\n0.997544\n\n\n\n\n\n\n\n\nBalance Test\n\nnon-outcome variable: mrm2\n\nfrom scipy import stats\n\n# group by treatment and control\ntreated_mrm2 = karlan_df[karlan_df['group'] == \"treatment\"]['mrm2'].dropna()\ncontrol_mrm2 = karlan_df[karlan_df['group'] == \"control\"]['mrm2'].dropna()\n\n# t-test\nt_stat, p_val = stats.ttest_ind(treated_mrm2, control_mrm2, equal_var=True)\n\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 0.119, p-value: 0.905\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"mrm2\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: mrm2\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  215.360  &lt; .001  ***\nmrm2             0.000      0.000    0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nimport statsmodels.api as sm\n\n# regression analysis\nX = sm.add_constant(karlan_df['treatment'])\ny = karlan_df['mrm2']\nmodel = sm.OLS(y, X, missing='drop').fit()\n\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.905\nTime:                        20:34:15   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nnon-outcome variable: median_hhincome\n\ntreated_mh = karlan_df[karlan_df['group'] == \"treatment\"]['median_hhincome'].dropna()\ncontrol_mh = karlan_df[karlan_df['group'] == \"control\"]['median_hhincome'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_mh, control_mh, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.742, p-value: 0.458\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"median_hhincome\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: median_hhincome\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n                 coefficient  std.error  t.value p.value     \nIntercept              0.671      0.006  116.647  &lt; .001  ***\nmedian_hhincome       -0.000      0.000   -0.742   0.458     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nnon-outcome variable: freq\n\ntreated_freq = karlan_df[karlan_df['group'] == \"treatment\"]['freq'].dropna()\ncontrol_freq = karlan_df[karlan_df['group'] == \"control\"]['freq'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_freq, control_freq, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.111, p-value: 0.912\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"freq\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: freq\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  258.746  &lt; .001  ***\nfreq            -0.000      0.000   -0.111   0.912     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nnon-outcome variable: female\n\ntreated_female = karlan_df[karlan_df[\"group\"] == \"treatment\"][\"female\"].dropna()\ncontrol_female = karlan_df[karlan_df[\"group\"] == \"control\"][\"female\"].dropna()\n\nt_test, p_val = stats.ttest_ind(treated_female, control_female, equal_var=True)\nprint(f\"t-statistic: {t_test:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -1.758, p-value: 0.079\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"female\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: female\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.669      0.003  266.731  &lt; .001  ***\nfemale          -0.008      0.005   -1.758   0.079    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nExperimental Results\n\nCharitable Contribution Made\n\ngave_by_group = karlan_df.groupby(\"group\")[\"gave\"].value_counts(normalize=True).unstack()\ngave_by_group.plot(kind=\"bar\", stacked=True, color=(\"lightblue\", \"lightpink\"))\nplt.title(\"Proportation of people who denoted by Group\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nplt.legend(title=\"Gave\", loc=\"upper right\")\n\nfor i, (gave_by_group, row) in enumerate(gave_by_group.iterrows()):\n    for j, value in enumerate(row):\n        if j == 1:\n            plt.text(i, value+1, f\"{value*100:.1f}%\", ha=\"center\", va=\"top\", fontsize=10)\n        else:\n            plt.text(i, value/2, f\"{value*100:.1f}%\", ha=\"center\", va=\"center\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\n\ntreated_gave = karlan_df[karlan_df['group'] == \"treatment\"]['gave'].dropna()\ncontrol_gave = karlan_df[karlan_df['group'] == \"control\"]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave, control_gave, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 3.101, p-value: 0.002\n\n\n\nfrom statsmodels.discrete.discrete_model import Probit\n\nX = sm.add_constant(karlan_df[\"treatment\"])\nprobit_model = Probit(karlan_df[\"gave\"], X).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        20:16:14   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\n\nratio_gave = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].dropna()\nratio2_gave = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].dropna()\nratio3_gave = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].dropna()\nratio_control_gave = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].dropna()\n\npairs = [\n    (\"ratio1 & ratio2\", ratio_gave, ratio2_gave),\n    (\"ratio1 & ratio3\", ratio_gave, ratio3_gave),\n    (\"ratio1 & control\", ratio_gave, ratio_control_gave),\n    (\"ratio2 & ratio3\", ratio2_gave, ratio3_gave),\n    (\"ratio2 & control\", ratio2_gave, ratio_control_gave),\n    (\"ratio3 & control\", ratio3_gave, ratio_control_gave),\n]\n\nfor label, group1, group2 in pairs:\n    t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=True)\n    print(f\"{label}: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nratio1 & ratio2: t-statistic: -0.965, p-value: 0.335\nratio1 & ratio3: t-statistic: -1.015, p-value: 0.310\nratio1 & control: t-statistic: 1.730, p-value: 0.084\nratio2 & ratio3: t-statistic: -0.050, p-value: 0.960\nratio2 & control: t-statistic: 2.804, p-value: 0.005\nratio3 & control: t-statistic: 2.859, p-value: 0.004\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"gave\", evar=\"ratio\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : gave\nExplanatory variables: ratio\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\nratio[1]         0.003      0.002    1.661   0.097    .\nratio[2]         0.005      0.002    2.744   0.006   **\nratio[3]         0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nresponse_rate_ratio1 = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].mean().round(4)\nresponse_rate_ratio2 = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].mean().round(4)\nresponse_rate_ratio3 = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].mean().round(4)\nresponse_rate_control = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].mean().round(4)\nresponse_rate = pd.Series({\n    \"ratio1\": response_rate_ratio1,\n    \"ratio2\": response_rate_ratio2,\n    \"ratio3\": response_rate_ratio3,\n    \"control\": response_rate_control\n})\nresponse_rate\nresponse_rate.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Response Rate by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Response Rate\")\nplt.xticks(rotation=0)\n\nfor i, value in enumerate(response_rate):\n    plt.text(i, value, f\"{value*100:.2f}%\", ha=\"center\", va=\"bottom\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\n\ntreated_amount = karlan_df[karlan_df['group'] == \"treatment\"]['amount'].dropna()\ncontrol_amount = karlan_df[karlan_df['group'] == \"control\"]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_amount, control_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 1.861, p-value: 0.063\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"amount\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.666      0.002  314.669  &lt; .001  ***\namount           0.000      0.000    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ntreated_gave_amount = karlan_df[(karlan_df['group'] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\ncontrol_gave_amount = karlan_df[(karlan_df['group'] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave_amount, control_gave_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.581, p-value: 0.561\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df[karlan_df[\"gave\"] == 1]}, rvar=\"treatment\", evar=\"amount\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept         0.72      0.021   35.055  &lt; .001  ***\namount           -0.00      0.000   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ntreated_gave_amount = karlan_df[(karlan_df[\"group\"] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_treated_gave_amount = treated_gave_amount.mean()\n\ncontrol_gave_amount = karlan_df[(karlan_df[\"group\"] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_control_gave_amount = control_gave_amount.mean()\nfig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n\n# Plot for Control Group\ncontrol_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7, ax=axes[0])\naxes[0].axvline(avg_control_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_control_gave_amount:.2f}\")\naxes[0].legend()\naxes[0].set_title(\"Distribution of Gave Amount for Control Group\", fontsize=10)\naxes[0].set_xlabel(\"Amount\")\naxes[0].set_ylabel(\"Frequency\")\n\n# Plot for Treatment Group\ntreated_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7, ax=axes[1])\naxes[1].axvline(avg_treated_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_treated_gave_amount:.2f}\")\naxes[1].legend()\naxes[1].set_title(\"Distribution of Gave Amount for Treatment Group\", fontsize=10)\naxes[1].set_xlabel(\"Amount\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ntreated_gave_amount = karlan_df[(karlan_df[\"group\"] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_treated_gave_amount = treated_gave_amount.mean()\n\ntreated_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7)\nplt.axvline(avg_treated_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_treated_gave_amount:.2f}\")\nplt.legend()\nplt.title(\"Distribution of Gave Amount for Treatment Group\")\nplt.xlabel(\"Amount\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\n\ncontrol_gave_amount = karlan_df[(karlan_df[\"group\"] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_control_gave_amount = control_gave_amount.mean()\n\ncontrol_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7)\nplt.axvline(avg_control_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_control_gave_amount:.2f}\")\nplt.legend()\nplt.title(\"Distribution of Gave Amount for Control Group\")\nplt.xlabel(\"Amount\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(0)\np_control = 0.018\np_treatment = 0.022\nn_control = 100_000\nn_treatment = 10_000\n\n# Simulate donatioin outcomes (Bernoulli distribution)\ncontrol = np.random.binomial(1, p_control, size=n_control)\ntreatment = np.random.binomial(1, p_treatment, size=n_treatment)\n\n# Sample the first 10,000 control observations to match treatment\ncontrol_sample = control[:n_treatment]\n\n# Difference = treatment - control\ndiffs = treatment - control_sample\n\n# Calculate the cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_treatment + 1)\n\n# Plot the cumulative average and the true difference line\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative average of difference\", color=\"lightblue\")\nplt.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True difference (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Law of Large Numbers Simulation\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(42)\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n\nfig, axes = plt.subplots(2, 2, figsize=(8, 8))\naxes = axes.flatten()\n\nfor idx, n in enumerate(sample_sizes):\n    diffs = []\n\n    # Simulate n_simulations times\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        diff = np.mean(treatment) - np.mean(control)\n        diffs.append(diff)\n\n    # Plot the histogram of differences\n    ax = axes[idx]\n    ax.hist(diffs, bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.75)\n    ax.axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Zero\")\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Mean Difference (Treatment - Control)\")\n    ax.set_ylabel(\"Frequency\")\n    ax.legend()\n\n# Add a title for the entire figure\nplt.suptitle(\"Central Limit Theorem Simulation\\nEffect of Sample Size on Distribution of Mean Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()"
  },
  {
    "objectID": "projects/HW2/hw2_questions.html",
    "href": "projects/HW2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nComparison of histograms and means of number of patents by customer status\n\n\n\n\n\n\n\n\n\n\nCustomers of Blueprinty have fewer firms overall but a higher average number of patents.\nOn average, customers have 4.13 patents compared to 3.47 for non-customers.\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nComparison of regions and ages by customer status\n\n\n\n\n\n\n\n\n\n\nMost customers come from the Northeast region, while non-customers are more evenly distributed across all regions.\nThe Midwest, South, and Southwest regions are underrepresented among Blueprinty customers compared to non-customers.\n\n\n\n\n\n\n\n\n\n\n\nBoth customers and non-customers are concentrated in the 20–39 age range, but non-customers tend to be slightly younger overall.\nThe youngest group (ages 0–9) is almost exclusively non-customers, while customers have a relatively higher proportion in the 30–49 range.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe mathematical likelihood for_ \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log(\\lambda) - \\log(Y_i!) \\right)\n\\]\nCode the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import gammaln\n\n# target variable\nY_data = blueprinty['patents'].values  \n\n# define the Poisson log-likelihood function\ndef poisson_loglikelihood(lmbda, Y):\n    Y = np.array(Y)\n    return np.sum(Y * np.log(lmbda) - lmbda - gammaln(Y + 1))\n\n# test example\nprint(\"log-likelihood at λ=3.0:\", poisson_loglikelihood(3.0, Y_data))\n\nlog-likelihood at λ=3.0: -3476.8568706008004\n\n\nUse my function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y)._\n\nimport matplotlib.pyplot as plt\n\n# Create a range of lambda values\nlambda_range = np.linspace(0.1, 10, 300)\n\n# Compute log-likelihood for each lambda\nloglik_values = [poisson_loglikelihood(lmb, Y_data) for lmb in lambda_range]\n\n# Find the lambda that gives the maximum log-likelihood\nlambda_mle_empirical = lambda_range[np.argmax(loglik_values)]\n\n# Plot the curve\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_range, loglik_values, label=\"Log-Likelihood Curve\")\nplt.axvline(lambda_mle_empirical, color=\"red\", linestyle=\"--\", label=f\"Empirical Max λ ≈ {lambda_mle_empirical:.2f}\")\nplt.xlabel(\"Lambda (λ)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Poisson Log-Likelihood Curve\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTake the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. We find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\n\n# Compute theoretical MLE as the sample mean\nlambda_mle_theory = np.mean(Y_data)\nprint(f\"Theoretical MLE λ = mean(Y) = {lambda_mle_theory:.4f}\")\n\nTheoretical MLE λ = mean(Y) = 3.6847\n\n\nFind the MLE by optimizing my likelihood function with sp.optimize() in Python.\n\nfrom scipy.optimize import minimize_scalar\n\n# Find λ that maximizes the log-likelihood using numerical optimization\nresult = minimize_scalar(\n    lambda lmb: -poisson_loglikelihood(lmb, Y_data),  # we minimize the negative log-likelihood\n    bounds=(0.01, 20),\n    method=\"bounded\"\n)\n\nlambda_mle_optimized = result.x\nprint(f\"Optimized MLE λ = {lambda_mle_optimized:.4f}\")\n\nOptimized MLE λ = 3.6847\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nUpdate my likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that_ \\(\\lambda_i = e^{X_i'\\beta}\\). _For example:\n\n# Define Poisson log-likelihood function with stable exp()\ndef poisson_regression_loglik(beta, Y, X):\n    lin_pred = X @ beta\n    lin_pred = np.clip(lin_pred, -20, 20)  # numerical stability\n    lambda_i = np.exp(lin_pred)\n    return -np.sum(Y * lin_pred - lambda_i - gammaln(Y + 1))\n\nUse my function along with Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\n# Initial guess (zeros)\nbeta_init = np.zeros(X.shape[1])\n\n# Minimize negative log-likelihood\nresult = minimize(\n    poisson_regression_loglik,\n    beta_init,\n    args=(Y, X),\n    method='BFGS',\n    options={'disp': True}\n)\n\n# Extract coefficients\nbeta_mle = result.x\n\n# Compute standard errors from inverse Hessian\nhessian_inv = result.hess_inv\nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\n# Format output as DataFrame\nregression_result = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Std. Error': standard_errors\n}, index=param_names)\n\nprint(regression_result)\n\n         Current function value: 3258.072164\n         Iterations: 14\n         Function evaluations: 804\n         Gradient evaluations: 88\n                        Coefficient  Std. Error\nIntercept                 -0.509955    0.193037\nC(region)[T.Northeast]     0.029159    0.046759\nC(region)[T.Northwest]    -0.017578    0.057235\nC(region)[T.South]         0.056567    0.056242\nC(region)[T.Southwest]     0.050589    0.049609\nage                        0.148702    0.014460\nage_squared               -0.002972    0.000266\niscustomer                 0.207600    0.032939\n\n\n/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py:708: OptimizeWarning:\n\nDesired error not necessarily achieved due to precision loss.\n\n\n\nCheck my results using Python sm.GLM() function.\n\nimport statsmodels.api as sm\n\n# Fit Poisson regression using statsmodels GLM\nglm_poisson = sm.GLM(Y, X, family=sm.families.Poisson())\nglm_results = glm_poisson.fit()\n\n# Display regression summary (coefficients, standard errors, z-scores)\nprint(glm_results.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 28 May 2025   Deviance:                       2143.3\nTime:                        15:50:02   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nx1             0.0292      0.044      0.669      0.504      -0.056       0.115\nx2            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx3             0.0566      0.053      1.074      0.283      -0.047       0.160\nx4             0.0506      0.047      1.072      0.284      -0.042       0.143\nx5             0.1486      0.014     10.716      0.000       0.121       0.176\nx6            -0.0030      0.000    -11.513      0.000      -0.003      -0.002\nx7             0.2076      0.031      6.719      0.000       0.147       0.268\n==============================================================================\n\n\n\n\n\n\niscustomer (whether the firm uses Blueprinty software):\n\n\nCoefficient: +0.208\nP-value &lt; 0.001 → statistically significant\nIn a Poisson regression, this means the expected patent count for users is: \\(e^{0.208} \\approx 1.23\\)\nThis implies that firms using Blueprinty software have, on average, 23% more patents than those who do not.\n\n\nage and age_squared:\n\n\nage: +0.149 → older firms tend to have more patents\nage_squared: -0.003 → diminishing returns, the effect of age decreases as firms get older\nThis suggests that patent counts increase with firm age, but at a decreasing rate.\n\n\nregion:\n\n\nRegion dummy variables show only minor differences compared to the baseline (Midwest)\nMost region effects are not statistically significant, acting as control variables\n\n\n\n\n\nThere is a significant positive association between using Blueprinty software and higher patent counts.\nAge is a meaningful predictor with diminishing marginal effects.\nRegional differences are minor and do not substantially influence model predictions.\n\nBecause the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and my fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences.\n\n# Copy design matrix\nX_0 = X.copy()\nX_1 = X.copy()\n\n# Find column index of \"iscustomer\"\niscust_idx = X_design.design_info.column_names.index(\"iscustomer\")\n\n# Simulate everyone as non-customer (0)\nX_0[:, iscust_idx] = 0\n\n# Simulate everyone as customer (1)\nX_1[:, iscust_idx] = 1\n\n# Predict expected patent counts for both cases\ny_pred_0 = glm_results.predict(X_0)\ny_pred_1 = glm_results.predict(X_1)\n\n# Compute average treatment effect\naverage_treatment_effect = np.mean(y_pred_1 - y_pred_0)\nprint(f\"Average treatment effect of Blueprinty software: {average_treatment_effect:.4f}\")\n\nAverage treatment effect of Blueprinty software: 0.7928"
  },
  {
    "objectID": "projects/HW2/hw2_questions.html#blueprinty-case-study",
    "href": "projects/HW2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nComparison of histograms and means of number of patents by customer status\n\n\n\n\n\n\n\n\n\n\nCustomers of Blueprinty have fewer firms overall but a higher average number of patents.\nOn average, customers have 4.13 patents compared to 3.47 for non-customers.\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nComparison of regions and ages by customer status\n\n\n\n\n\n\n\n\n\n\nMost customers come from the Northeast region, while non-customers are more evenly distributed across all regions.\nThe Midwest, South, and Southwest regions are underrepresented among Blueprinty customers compared to non-customers.\n\n\n\n\n\n\n\n\n\n\n\nBoth customers and non-customers are concentrated in the 20–39 age range, but non-customers tend to be slightly younger overall.\nThe youngest group (ages 0–9) is almost exclusively non-customers, while customers have a relatively higher proportion in the 30–49 range.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe mathematical likelihood for_ \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log(\\lambda) - \\log(Y_i!) \\right)\n\\]\nCode the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import gammaln\n\n# target variable\nY_data = blueprinty['patents'].values  \n\n# define the Poisson log-likelihood function\ndef poisson_loglikelihood(lmbda, Y):\n    Y = np.array(Y)\n    return np.sum(Y * np.log(lmbda) - lmbda - gammaln(Y + 1))\n\n# test example\nprint(\"log-likelihood at λ=3.0:\", poisson_loglikelihood(3.0, Y_data))\n\nlog-likelihood at λ=3.0: -3476.8568706008004\n\n\nUse my function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y)._\n\nimport matplotlib.pyplot as plt\n\n# Create a range of lambda values\nlambda_range = np.linspace(0.1, 10, 300)\n\n# Compute log-likelihood for each lambda\nloglik_values = [poisson_loglikelihood(lmb, Y_data) for lmb in lambda_range]\n\n# Find the lambda that gives the maximum log-likelihood\nlambda_mle_empirical = lambda_range[np.argmax(loglik_values)]\n\n# Plot the curve\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_range, loglik_values, label=\"Log-Likelihood Curve\")\nplt.axvline(lambda_mle_empirical, color=\"red\", linestyle=\"--\", label=f\"Empirical Max λ ≈ {lambda_mle_empirical:.2f}\")\nplt.xlabel(\"Lambda (λ)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Poisson Log-Likelihood Curve\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTake the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. We find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\n\n# Compute theoretical MLE as the sample mean\nlambda_mle_theory = np.mean(Y_data)\nprint(f\"Theoretical MLE λ = mean(Y) = {lambda_mle_theory:.4f}\")\n\nTheoretical MLE λ = mean(Y) = 3.6847\n\n\nFind the MLE by optimizing my likelihood function with sp.optimize() in Python.\n\nfrom scipy.optimize import minimize_scalar\n\n# Find λ that maximizes the log-likelihood using numerical optimization\nresult = minimize_scalar(\n    lambda lmb: -poisson_loglikelihood(lmb, Y_data),  # we minimize the negative log-likelihood\n    bounds=(0.01, 20),\n    method=\"bounded\"\n)\n\nlambda_mle_optimized = result.x\nprint(f\"Optimized MLE λ = {lambda_mle_optimized:.4f}\")\n\nOptimized MLE λ = 3.6847\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nUpdate my likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that_ \\(\\lambda_i = e^{X_i'\\beta}\\). _For example:\n\n# Define Poisson log-likelihood function with stable exp()\ndef poisson_regression_loglik(beta, Y, X):\n    lin_pred = X @ beta\n    lin_pred = np.clip(lin_pred, -20, 20)  # numerical stability\n    lambda_i = np.exp(lin_pred)\n    return -np.sum(Y * lin_pred - lambda_i - gammaln(Y + 1))\n\nUse my function along with Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\n# Initial guess (zeros)\nbeta_init = np.zeros(X.shape[1])\n\n# Minimize negative log-likelihood\nresult = minimize(\n    poisson_regression_loglik,\n    beta_init,\n    args=(Y, X),\n    method='BFGS',\n    options={'disp': True}\n)\n\n# Extract coefficients\nbeta_mle = result.x\n\n# Compute standard errors from inverse Hessian\nhessian_inv = result.hess_inv\nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\n# Format output as DataFrame\nregression_result = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Std. Error': standard_errors\n}, index=param_names)\n\nprint(regression_result)\n\n         Current function value: 3258.072164\n         Iterations: 14\n         Function evaluations: 804\n         Gradient evaluations: 88\n                        Coefficient  Std. Error\nIntercept                 -0.509955    0.193037\nC(region)[T.Northeast]     0.029159    0.046759\nC(region)[T.Northwest]    -0.017578    0.057235\nC(region)[T.South]         0.056567    0.056242\nC(region)[T.Southwest]     0.050589    0.049609\nage                        0.148702    0.014460\nage_squared               -0.002972    0.000266\niscustomer                 0.207600    0.032939\n\n\n/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py:708: OptimizeWarning:\n\nDesired error not necessarily achieved due to precision loss.\n\n\n\nCheck my results using Python sm.GLM() function.\n\nimport statsmodels.api as sm\n\n# Fit Poisson regression using statsmodels GLM\nglm_poisson = sm.GLM(Y, X, family=sm.families.Poisson())\nglm_results = glm_poisson.fit()\n\n# Display regression summary (coefficients, standard errors, z-scores)\nprint(glm_results.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 28 May 2025   Deviance:                       2143.3\nTime:                        15:50:02   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nx1             0.0292      0.044      0.669      0.504      -0.056       0.115\nx2            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx3             0.0566      0.053      1.074      0.283      -0.047       0.160\nx4             0.0506      0.047      1.072      0.284      -0.042       0.143\nx5             0.1486      0.014     10.716      0.000       0.121       0.176\nx6            -0.0030      0.000    -11.513      0.000      -0.003      -0.002\nx7             0.2076      0.031      6.719      0.000       0.147       0.268\n==============================================================================\n\n\n\n\n\n\niscustomer (whether the firm uses Blueprinty software):\n\n\nCoefficient: +0.208\nP-value &lt; 0.001 → statistically significant\nIn a Poisson regression, this means the expected patent count for users is: \\(e^{0.208} \\approx 1.23\\)\nThis implies that firms using Blueprinty software have, on average, 23% more patents than those who do not.\n\n\nage and age_squared:\n\n\nage: +0.149 → older firms tend to have more patents\nage_squared: -0.003 → diminishing returns, the effect of age decreases as firms get older\nThis suggests that patent counts increase with firm age, but at a decreasing rate.\n\n\nregion:\n\n\nRegion dummy variables show only minor differences compared to the baseline (Midwest)\nMost region effects are not statistically significant, acting as control variables\n\n\n\n\n\nThere is a significant positive association between using Blueprinty software and higher patent counts.\nAge is a meaningful predictor with diminishing marginal effects.\nRegional differences are minor and do not substantially influence model predictions.\n\nBecause the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and my fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences.\n\n# Copy design matrix\nX_0 = X.copy()\nX_1 = X.copy()\n\n# Find column index of \"iscustomer\"\niscust_idx = X_design.design_info.column_names.index(\"iscustomer\")\n\n# Simulate everyone as non-customer (0)\nX_0[:, iscust_idx] = 0\n\n# Simulate everyone as customer (1)\nX_1[:, iscust_idx] = 1\n\n# Predict expected patent counts for both cases\ny_pred_0 = glm_results.predict(X_0)\ny_pred_1 = glm_results.predict(X_1)\n\n# Compute average treatment effect\naverage_treatment_effect = np.mean(y_pred_1 - y_pred_0)\nprint(f\"Average treatment effect of Blueprinty software: {average_treatment_effect:.4f}\")\n\nAverage treatment effect of Blueprinty software: 0.7928"
  },
  {
    "objectID": "projects/HW2/hw2_questions.html#airbnb-case-study",
    "href": "projects/HW2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\nExplorary Data Analysis\n\nairbnb.info()\nairbnb.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 40628 entries, 0 to 40627\nData columns (total 14 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Unnamed: 0                 40628 non-null  int64  \n 1   id                         40628 non-null  int64  \n 2   days                       40628 non-null  int64  \n 3   last_scraped               40628 non-null  object \n 4   host_since                 40593 non-null  object \n 5   room_type                  40628 non-null  object \n 6   bathrooms                  40468 non-null  float64\n 7   bedrooms                   40552 non-null  float64\n 8   price                      40628 non-null  int64  \n 9   number_of_reviews          40628 non-null  int64  \n 10  review_scores_cleanliness  30433 non-null  float64\n 11  review_scores_location     30374 non-null  float64\n 12  review_scores_value        30372 non-null  float64\n 13  instant_bookable           40628 non-null  object \ndtypes: float64(5), int64(5), object(4)\nmemory usage: 4.3+ MB\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\n\n\n\n\ncount\n40628.000000\n4.062800e+04\n40628.000000\n40468.000000\n40552.000000\n40628.000000\n40628.000000\n30433.000000\n30374.000000\n30372.000000\n\n\nmean\n20314.500000\n9.698889e+06\n1102.368219\n1.124592\n1.147046\n144.760732\n15.904426\n9.198370\n9.413544\n9.331522\n\n\nstd\n11728.437705\n5.460166e+06\n1383.269358\n0.385884\n0.691746\n210.657597\n29.246009\n1.119935\n0.844949\n0.902966\n\n\nmin\n1.000000\n2.515000e+03\n1.000000\n0.000000\n0.000000\n10.000000\n0.000000\n2.000000\n2.000000\n2.000000\n\n\n25%\n10157.750000\n4.889868e+06\n542.000000\n1.000000\n1.000000\n70.000000\n1.000000\n9.000000\n9.000000\n9.000000\n\n\n50%\n20314.500000\n9.862878e+06\n996.000000\n1.000000\n1.000000\n100.000000\n4.000000\n10.000000\n10.000000\n10.000000\n\n\n75%\n30471.250000\n1.466789e+07\n1535.000000\n1.000000\n1.000000\n170.000000\n17.000000\n10.000000\n10.000000\n10.000000\n\n\nmax\n40628.000000\n1.800967e+07\n42828.000000\n8.000000\n10.000000\n10000.000000\n421.000000\n10.000000\n10.000000\n10.000000\n\n\n\n\n\n\n\n\nVariables Distribution\n\n\n\n\n\n\n\n\n\n\nThe majority of listings are either entire homes/apartments or private rooms, with nearly equal counts.\nShared rooms are much less common, accounting for only a small fraction of the total listings.\n\n\n\n\n\n\n\n\n\n\n\nThe vast majority of listings have exactly one bathroom, with over 34,000 such cases.\nListings with more than two bathrooms are rare, and those with zero or fractional bathrooms also occur infrequently.\n\n\n\n\n\n\n\n\n\n\n\nThe majority of listings have exactly one bedroom, with over 30,000 such entries.\nListings with three or more bedrooms are relatively rare, and those with zero bedrooms likely represent studio or shared space accommodations.\n\n\n\n\n\n\n\n\n\n\n\nMost listings have high cleanliness scores, with the majority rated 9 or 10.\nVery few listings fall below a cleanliness score of 6, indicating generally high standards across the dataset.\n\n\n\n\n\n\n\n\n\n\n\nLocaion share similar trend with cleanliness. The vast majority of listings have high location ratings, with most scoring 9 or 10.\nListings rated below 7 are very rare, indicating that location is generally perceived positively across the dataset.\n\n\n\n\n\n\n\n\n\n\n\nValue also share similar trend with location and cleanliness. Most of the listings have high value score, with the majority scoring 9 or 10.\nListings rated below 7 are very rare, indicating that value is generally perceived positively across the dataset.\n\n\n\n\n\n\n\n\n\n\n\nThe price distribution is highly right-skewed, with most listings priced under $1,000.\nA small number of listings have extremely high prices, creating a long tail on the higher end of the distribution.\n\n\n\nPrice Distribution by Different Variables\n\n\n\n\n\n\n\n\n\n\nEntire home/apartment listings have the highest average price at around $205.\nPrivate rooms and shared rooms are significantly more affordable, with average prices of approximately $87 and $78 respectively.\n\n\n\n\n\n\n\n\n\n\n\nAverage price tends to increase with the number of bathrooms, showing a clear upward trend.\nListings with 6 or more bathrooms are priced significantly higher, with some reaching over $5,000 on average.\n\n\n\n\n\n\n\n\n\n\n\nAverage price generally increases with the number of bedrooms, peaking at 8 bedrooms with an average price around $1,200.\nAfter 8 bedrooms, the average price fluctuates and slightly declines, possibly due to fewer listings or outliers in those categories.\n\n\n\n\n\n\n\n\n\n\n\nAverage price does not follow a clear linear trend with cleanliness score.\nInterestingly, listings with very low cleanliness scores (e.g., 2 or 5) show higher average prices than those with mid-range scores, suggesting possible outliers or low sample size effects.\n\n\n\n\n\n\n\n\n\n\n\nAverage price generally increases with higher location scores, especially for listings rated 10, which have the highest average price.\nListings with lower location scores (such as 3 or below) tend to have significantly lower prices.\n\n\n\n\n\n\n\n\n\n\n\nThe average price is relatively stable across most value scores, typically ranging between $110 and $140.\nHowever, listings with a value score of 3 show an unusually high average price, which may indicate the presence of outliers or data anomalies.\n\n\n\n\nModel Building\n\nimport pandas as pd\nimport numpy as np\nimport patsy\nimport statsmodels.api as sm\n\n# Load dataset\n\n# Step 1: Select relevant variables\nrelevant_vars = ['number_of_reviews', 'bedrooms', 'bathrooms', 'room_type', 'price']\n\n# Step 2: Drop rows with missing values in relevant variables\nairbnb_clean = airbnb.dropna(subset=relevant_vars).copy()\n\n# Step 3: Feature engineering\n# Apply log-transform to skewed variable `price`\nairbnb_clean['price_log'] = np.log1p(airbnb_clean['price'])  # log(1 + price) to handle zeros/skewness\n\n# Convert categorical variable to category type (for dummy encoding)\nairbnb_clean['room_type'] = airbnb_clean['room_type'].astype('category')\n\n# Step 4: Create design matrices using patsy\n# This builds the regression formula for Poisson regression\ny, X = patsy.dmatrices(\n    'number_of_reviews ~ bedrooms + bathrooms + price_log + C(room_type)',\n    data=airbnb_clean,\n    return_type='dataframe'\n)\n\n# Step 5: Fit Poisson regression model using statsmodels\nmodel = sm.GLM(y, X, family=sm.families.Poisson())\nresults = model.fit()\n\n# Step 6: Output model summary\nprint(results.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                40395\nModel:                            GLM   Df Residuals:                    40389\nModel Family:                 Poisson   Df Model:                            5\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -7.2270e+05\nDate:                Wed, 28 May 2025   Deviance:                   1.3222e+06\nTime:                        15:50:04   Pearson chi2:                 2.16e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):             0.1308\nCovariance Type:            nonrobust                                         \n================================================================================================\n                                   coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------------------\nIntercept                        3.0093      0.013    230.701      0.000       2.984       3.035\nC(room_type)[T.Private room]    -0.1105      0.003    -33.717      0.000      -0.117      -0.104\nC(room_type)[T.Shared room]     -0.3607      0.009    -40.154      0.000      -0.378      -0.343\nbedrooms                         0.0871      0.002     43.538      0.000       0.083       0.091\nbathrooms                       -0.1409      0.004    -37.006      0.000      -0.148      -0.133\nprice_log                       -0.0273      0.003    -10.354      0.000      -0.033      -0.022\n================================================================================================\n\n\n\n\nCoefficient Interpretation (Exponentiate to interpret effect size):\nIn Poisson regression, coefficients represent the log change in the expected count per one-unit increase in the predictor. To interpret in terms of percent change, use: \\[\n\\text{Percent Change} = (e^{\\beta} - 1) \\times 100\n\\] Where \\(\\beta\\) is the coefficient from the model.\n\n\nPoisson Regression Coefficients\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nP-value\nInterpretation\n\n\n\n\nIntercept\n3.0093\n&lt; 0.001\nBaseline: Entire home/apartment with 0 bedrooms and 0 bathrooms at price_log=0Expected: \\((e^{3.0093} \\approx 20.26)\\)\n\n\nPrivate room (vs Entire home)\n-0.1105\n&lt; 0.001\nPrivate rooms have ~10.5% fewer reviews than entire homes/apartment \\((e^{-0.1105} \\approx 0.895)\\)\n\n\nShared room (vs Entire home)\n-0.3607\n&lt; 0.001\nShared rooms have ~30.3% fewer reviews than entire homes/apartment \\((e^{-0.3607} \\approx 0.697)\\)\n\n\nBedrooms\n+0.0871\n&lt; 0.001\nEach additional bedroom increases reviews by ~9.1% \\((e^{0.0871} \\approx 1.091)\\)\n\n\nBathrooms\n-0.1409\n&lt; 0.001\nEach additional bathroom decreases reviews by ~13.1% \\((e^{-0.1409} \\approx 0.869)\\)\n\n\nPrice (log)\n-0.0273\n&lt; 0.001\nA 1% increase in price slightly reduces reviews by ~2.7% \\((e^{-0.0273} \\approx 0.973)\\)\n\n\n\n\n\nSummary:\n\nRoom type: Private and shared rooms tend to receive fewer reviews than entire apartments (statistically significant).\nBedrooms: More bedrooms → more reviews (positive relationship).\nBathrooms: More bathrooms → surprisingly associated with fewer reviews (possibly due to multicollinearity or price confounding).\nPrice (log): Listings with higher prices (after log transformation) tend to receive slightly fewer reviews."
  },
  {
    "objectID": "HW2/hw2_questions.html",
    "href": "HW2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "HW2/hw2_questions.html#blueprinty-case-study",
    "href": "HW2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "HW2/hw2_questions.html#airbnb-case-study",
    "href": "HW2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided."
  },
  {
    "objectID": "projects/HW2/HW2.html",
    "href": "projects/HW2/HW2.html",
    "title": "Blueprinty Case Study",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nData\nRead in data\n\nblueprinty = pd.read_csv('blueprinty.csv')\nblueprinty\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n...\n...\n...\n...\n...\n\n\n1495\n2\nNortheast\n18.5\n1\n\n\n1496\n3\nSouthwest\n22.5\n0\n\n\n1497\n4\nSouthwest\n17.0\n0\n\n\n1498\n3\nSouth\n29.0\n0\n\n\n1499\n1\nSouth\n39.0\n0\n\n\n\n\n1500 rows × 4 columns\n\n\n\nCompare histograms and means of number of patents by customer status. What do you observe?\n\n# Calculate the mean of patents by customer status\nmean_patents_iscus = blueprinty.groupby('iscustomer')['patents'].mean()\npatents_iscus = blueprinty.groupby('iscustomer')['patents'].sum()\n\n# Plot the bar chart for the count of patents\nfig, ax1 = plt.subplots()\n\npatents_iscus.plot(kind='bar', color='lightblue', ax=ax1, label='Number of Patents')\nax1.set_title('Patents by Customer Status')\nax1.set_xlabel('Customer Status')\nax1.set_ylabel('Number of Patents')\nax1.set_xticks([0, 1])\nax1.set_xticklabels(['Non-Customer', 'Customer'], rotation=0)\nax1.legend(loc='upper right', bbox_to_anchor=(1, 1))\n\n# Plot the line chart for the mean of patents\nax2 = ax1.twinx()\nmean_patents_iscus.plot(kind='line', color='orange', marker='o', ax=ax2, label='Mean of Patents')\nax2.set_ylim(0, 6)\nax2.set_ylabel('Mean of Patents')\nax2.legend(loc='upper right', bbox_to_anchor=(1, 0.9))\n\n# Add data labels to the bars\nfor i in range(len(patents_iscus)):\n    plt.text(i, patents_iscus[i]*0.0016, f\"{patents_iscus[i]}\", ha='center', va='bottom')\nfor j in range(len(mean_patents_iscus)):\n    plt.text(j, mean_patents_iscus[j]+0.1, f\"{round(mean_patents_iscus[j],2)}\", ha='center', va='bottom')\nplt.show()\n\n\n\n\n\n\n\n\nCompare regions and ages by customer status. What do you observe?\n\npastel_colors = ['#A6CEE3', '#FDBF6F', '#B2DF8A', '#FB9A99', '#CAB2D6']\nregion_iscus = blueprinty.groupby('iscustomer')['region'].value_counts().unstack()\nregion_iscus.plot(kind='bar', stacked=True, color=pastel_colors)\nplt.title('Region Distribution by Customer Status')\nplt.xlabel('Customer Status')\nplt.ylabel('Count by Regions')\nplt.xticks([0, 1], ['Non-Customer', 'Customer'], rotation=0)\nplt.legend(title='Region', bbox_to_anchor=(1, 1))\n\n# Add data labels to the middle of the bars\nfor i in range(len(region_iscus)):\n    cumulative_height = 0\n    for j in range(len(region_iscus.columns)):\n        height = region_iscus.iloc[i, j]\n        if height &gt; 0:\n            plt.text(i, cumulative_height + height / 2, f\"{height}\", ha='center', va='center')\n        cumulative_height += height\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Create bins for ten-year age intervals\nbins = range(0, int(blueprinty['age'].max()) + 10, 10)\nlabels = [f\"{i}-{i+9}\" for i in bins[:-1]]\n\n# Add a new column for age groups\nblueprinty['age_group'] = pd.cut(blueprinty['age'], bins=bins, labels=labels, right=False)\n\n# Regroup the data by age groups and customer status\npastel_colors = ['#A6CEE3', '#FDBF6F', '#B2DF8A', '#FB9A99', '#CAB2D6']\nage_group_iscus = blueprinty.groupby(['iscustomer', 'age_group'])['age'].count().unstack()\nage_group_iscus.plot(kind='bar', stacked=True, color=pastel_colors)\nplt.title('Age Distribution by Customer Status')\nplt.xlabel('Customer Status')\nplt.ylabel('Count by Age Groups')\nplt.xticks([0, 1], ['Non-Customer', 'Customer'], rotation=0)\nplt.legend(title='Age Group', bbox_to_anchor=(1, 1))\n# Add data labels to the middle of the bars \nfor i in range(len(age_group_iscus)):\n    cumulative_height = 0\n    for j in range(len(age_group_iscus.columns)):\n        height = age_group_iscus.iloc[i, j]\n        if height &gt; 0:\n            plt.text(i, cumulative_height + height / 2, f\"{height}\", ha='center', va='center')\n        cumulative_height += height\nplt.tight_layout()\n\n/tmp/ipykernel_44952/2703104569.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  age_group_iscus = blueprinty.groupby(['iscustomer', 'age_group'])['age'].count().unstack()\n\n\n\n\n\n\n\n\n\n\n\nEstimation of Simple Poisson Model\nWrite down mathematically the likelihood for_ \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log(\\lambda) - \\log(Y_i!) \\right)\n\\]\nCode the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import gammaln\n\n# target variable\nY_data = blueprinty['patents'].values  \n\n# define the Poisson log-likelihood function\ndef poisson_loglikelihood(lmbda, Y):\n    Y = np.array(Y)\n    return np.sum(Y * np.log(lmbda) - lmbda - gammaln(Y + 1))\n\n# test example\nprint(\"log-likelihood at λ=3.0:\", poisson_loglikelihood(3.0, Y_data))\n\nlog-likelihood at λ=3.0: -3476.8568706008004\n\n\nUse your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\n\nimport matplotlib.pyplot as plt\n\n# Create a range of lambda values\nlambda_range = np.linspace(0.1, 10, 300)\n\n# Compute log-likelihood for each lambda\nloglik_values = [poisson_loglikelihood(lmb, Y_data) for lmb in lambda_range]\n\n# Find the lambda that gives the maximum log-likelihood\nlambda_mle_empirical = lambda_range[np.argmax(loglik_values)]\n\n# Plot the curve\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_range, loglik_values, label=\"Log-Likelihood Curve\")\nplt.axvline(lambda_mle_empirical, color=\"red\", linestyle=\"--\", label=f\"Empirical Max λ ≈ {lambda_mle_empirical:.2f}\")\nplt.xlabel(\"Lambda (λ)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Poisson Log-Likelihood Curve\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIf you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\n\n# Compute theoretical MLE as the sample mean\nlambda_mle_theory = np.mean(Y_data)\nprint(f\"Theoretical MLE λ = mean(Y) = {lambda_mle_theory:.4f}\")\n\nTheoretical MLE λ = mean(Y) = 3.6847\n\n\nFind the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\nfrom scipy.optimize import minimize_scalar\n\n# Find λ that maximizes the log-likelihood using numerical optimization\nresult = minimize_scalar(\n    lambda lmb: -poisson_loglikelihood(lmb, Y_data),  # we minimize the negative log-likelihood\n    bounds=(0.01, 20),\n    method=\"bounded\"\n)\n\nlambda_mle_optimized = result.x\nprint(f\"Optimized MLE λ = {lambda_mle_optimized:.4f}\")\n\nOptimized MLE λ = 3.6847\n\n\n\n\nEstimation of Poisson Regression Model\nUpdate your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that_ \\(\\lambda_i = e^{X_i'\\beta}\\). _For example:\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import gammaln\nfrom scipy.optimize import minimize\nimport patsy\n\n\n# Add age_squared feature\n\nblueprinty[\"age_squared\"] = blueprinty[\"age\"] ** 2\n\n# Construct model matrix X using patsy (includes intercept automatically)\ny_data, X_design = patsy.dmatrices(\n    'patents ~ age + age_squared + C(region) + iscustomer',\n    data=blueprinty,\n    return_type='dataframe'\n)\n\n# Extract matrix and response\nX = np.asarray(X_design)\nY = blueprinty[\"patents\"].values\nparam_names = X_design.design_info.column_names\n\n# Define Poisson log-likelihood function with stable exp()\ndef poisson_regression_loglik(beta, Y, X):\n    lin_pred = X @ beta\n    lin_pred = np.clip(lin_pred, -20, 20)  # numerical stability\n    lambda_i = np.exp(lin_pred)\n    return -np.sum(Y * lin_pred - lambda_i - gammaln(Y + 1))\n\nUse your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\n# Initial guess (zeros)\nbeta_init = np.zeros(X.shape[1])\n\n# Minimize negative log-likelihood\nresult = minimize(\n    poisson_regression_loglik,\n    beta_init,\n    args=(Y, X),\n    method='BFGS',\n    options={'disp': True}\n)\n\n# Extract coefficients\nbeta_mle = result.x\n\n# Compute standard errors from inverse Hessian\nhessian_inv = result.hess_inv\nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\n# Format output as DataFrame\nregression_result = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Std. Error': standard_errors\n}, index=param_names)\n\nprint(regression_result)\n\n         Current function value: 3258.072164\n         Iterations: 14\n         Function evaluations: 804\n         Gradient evaluations: 88\n                        Coefficient  Std. Error\nIntercept                 -0.509955    0.193037\nC(region)[T.Northeast]     0.029159    0.046759\nC(region)[T.Northwest]    -0.017578    0.057235\nC(region)[T.South]         0.056567    0.056242\nC(region)[T.Southwest]     0.050589    0.049609\nage                        0.148702    0.014460\nage_squared               -0.002972    0.000266\niscustomer                 0.207600    0.032939\n\n\n/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py:708: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n  res = _minimize_bfgs(fun, x0, args, jac, callback, **options)\n\n\nCheck your results using R’s glm() function or Python sm.GLM() function.\n\nimport statsmodels.api as sm\n\n# Fit Poisson regression using statsmodels GLM\nglm_poisson = sm.GLM(Y, X, family=sm.families.Poisson())\nglm_results = glm_poisson.fit()\n\n# Display regression summary (coefficients, standard errors, z-scores)\nprint(glm_results.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        00:40:42   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nx1             0.0292      0.044      0.669      0.504      -0.056       0.115\nx2            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx3             0.0566      0.053      1.074      0.283      -0.047       0.160\nx4             0.0506      0.047      1.072      0.284      -0.042       0.143\nx5             0.1486      0.014     10.716      0.000       0.121       0.176\nx6            -0.0030      0.000    -11.513      0.000      -0.003      -0.002\nx7             0.2076      0.031      6.719      0.000       0.147       0.268\n==============================================================================\n\n\nInterpret the results.\n\n# Extract coefficients and confidence intervals\ncoef_table = glm_results.summary2().tables[1]\n\n# Display key statistics\nprint(coef_table[['Coef.', 'Std.Err.', 'P&gt;|z|']])\n\n          Coef.  Std.Err.         P&gt;|z|\nconst -0.508920  0.183179  5.464935e-03\nx1     0.029170  0.043625  5.037205e-01\nx2    -0.017575  0.053781  7.438327e-01\nx3     0.056561  0.052662  2.828066e-01\nx4     0.050576  0.047198  2.839141e-01\nx5     0.148619  0.013869  8.539597e-27\nx6    -0.002970  0.000258  1.131496e-30\nx7     0.207591  0.030895  1.827509e-11\n\n\n\n\nKey Variable Interpretations:\n\niscustomer (whether the firm uses Blueprinty software):\n\n\nCoefficient: +0.208\nP-value &lt; 0.001 → statistically significant\nIn a Poisson regression, this means the expected patent count for users is: \\(e^{0.208} \\approx 1.23\\)\nThis implies that firms using Blueprinty software have, on average, 23% more patents than those who do not.\n\n\nage and age_squared:\n\n\nage: +0.149 → older firms tend to have more patents\nage_squared: -0.003 → diminishing returns, the effect of age decreases as firms get older\nThis suggests that patent counts increase with firm age, but at a decreasing rate.\n\n\nregion:\n\n\nRegion dummy variables show only minor differences compared to the baseline (Midwest)\nMost region effects are not statistically significant, acting as control variables\n\n\n\nSummary:\n\nThere is a significant positive association between using Blueprinty software and higher patent counts.\nAge is a meaningful predictor with diminishing marginal effects.\nRegional differences are minor and do not substantially influence model predictions.\n\nWhat do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences.\n\n# Copy design matrix\nX_0 = X.copy()\nX_1 = X.copy()\n\n# Find column index of \"iscustomer\"\niscust_idx = X_design.design_info.column_names.index(\"iscustomer\")\n\n# Simulate everyone as non-customer (0)\nX_0[:, iscust_idx] = 0\n\n# Simulate everyone as customer (1)\nX_1[:, iscust_idx] = 1\n\n# Predict expected patent counts for both cases\ny_pred_0 = glm_results.predict(X_0)\ny_pred_1 = glm_results.predict(X_1)\n\n# Compute average treatment effect\naverage_treatment_effect = np.mean(y_pred_1 - y_pred_0)\nprint(f\"Average treatment effect of Blueprinty software: {average_treatment_effect:.4f}\")\n\nAverage treatment effect of Blueprinty software: 0.7928\n\n\n\n# Optional: summary table\nimport pandas as pd\n\npd.DataFrame({\n    'Pred (iscustomer=0)': y_pred_0,\n    'Pred (iscustomer=1)': y_pred_1,\n    'Difference': y_pred_1 - y_pred_0\n}).describe()\n\n\n\n\n\n\n\n\nPred (iscustomer=0)\nPred (iscustomer=1)\nDifference\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n\n\nmean\n3.436219\n4.228987\n0.792768\n\n\nstd\n0.586140\n0.721368\n0.135228\n\n\nmin\n0.698603\n0.859777\n0.161174\n\n\n25%\n3.187149\n3.922454\n0.735305\n\n\n50%\n3.633079\n4.471265\n0.838186\n\n\n75%\n3.867802\n4.760140\n0.892338\n\n\nmax\n4.081981\n5.023732\n0.941751\n\n\n\n\n\n\n\n\n\nAirBnB Case Study\nAssume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided.\n\nairbnb = pd.read_csv('airbnb.csv')\nairbnb\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n40623\n40624\n18008937\n266\n4/2/2017\n7/10/2016\nEntire home/apt\n1.5\n2.0\n150\n0\nNaN\nNaN\nNaN\nt\n\n\n40624\n40625\n18009045\n366\n4/2/2017\n4/1/2016\nPrivate room\n1.0\n1.0\n125\n0\nNaN\nNaN\nNaN\nf\n\n\n40625\n40626\n18009065\n587\n4/2/2017\n8/24/2015\nPrivate room\n1.0\n1.0\n80\n0\nNaN\nNaN\nNaN\nt\n\n\n40626\n40627\n18009650\n335\n4/2/2017\n5/2/2016\nPrivate room\n1.0\n1.0\n69\n0\nNaN\nNaN\nNaN\nt\n\n\n40627\n40628\n18009669\n1\n4/2/2017\n4/1/2017\nEntire home/apt\n1.0\n1.0\n115\n0\nNaN\nNaN\nNaN\nt\n\n\n\n\n40628 rows × 14 columns\n\n\n\n\nExplorary data analysis\n\nairbnb.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 40628 entries, 0 to 40627\nData columns (total 14 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Unnamed: 0                 40628 non-null  int64  \n 1   id                         40628 non-null  int64  \n 2   days                       40628 non-null  int64  \n 3   last_scraped               40628 non-null  object \n 4   host_since                 40593 non-null  object \n 5   room_type                  40628 non-null  object \n 6   bathrooms                  40468 non-null  float64\n 7   bedrooms                   40552 non-null  float64\n 8   price                      40628 non-null  int64  \n 9   number_of_reviews          40628 non-null  int64  \n 10  review_scores_cleanliness  30433 non-null  float64\n 11  review_scores_location     30374 non-null  float64\n 12  review_scores_value        30372 non-null  float64\n 13  instant_bookable           40628 non-null  object \ndtypes: float64(5), int64(5), object(4)\nmemory usage: 4.3+ MB\n\n\n\nairbnb.describe()\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\n\n\n\n\ncount\n40628.000000\n4.062800e+04\n40628.000000\n40468.000000\n40552.000000\n40628.000000\n40628.000000\n30433.000000\n30374.000000\n30372.000000\n\n\nmean\n20314.500000\n9.698889e+06\n1102.368219\n1.124592\n1.147046\n144.760732\n15.904426\n9.198370\n9.413544\n9.331522\n\n\nstd\n11728.437705\n5.460166e+06\n1383.269358\n0.385884\n0.691746\n210.657597\n29.246009\n1.119935\n0.844949\n0.902966\n\n\nmin\n1.000000\n2.515000e+03\n1.000000\n0.000000\n0.000000\n10.000000\n0.000000\n2.000000\n2.000000\n2.000000\n\n\n25%\n10157.750000\n4.889868e+06\n542.000000\n1.000000\n1.000000\n70.000000\n1.000000\n9.000000\n9.000000\n9.000000\n\n\n50%\n20314.500000\n9.862878e+06\n996.000000\n1.000000\n1.000000\n100.000000\n4.000000\n10.000000\n10.000000\n10.000000\n\n\n75%\n30471.250000\n1.466789e+07\n1535.000000\n1.000000\n1.000000\n170.000000\n17.000000\n10.000000\n10.000000\n10.000000\n\n\nmax\n40628.000000\n1.800967e+07\n42828.000000\n8.000000\n10.000000\n10000.000000\n421.000000\n10.000000\n10.000000\n10.000000\n\n\n\n\n\n\n\n\nroom_type = airbnb[\"room_type\"].value_counts()\nroom_type.plot(kind='bar', color='#B2DF8A')\nplt.title('Room Type Distribution')\nplt.xlabel('Room Type')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nfor i in range(len(room_type)):\n    plt.text(i, room_type[i], f\"{room_type[i]}\", ha='center', va='bottom')\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_44952/1378945223.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, room_type[i], f\"{room_type[i]}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ndbathroom = airbnb[\"bathrooms\"].value_counts().sort_index()\ndbathroom.plot(kind='bar', color='#B2DF8A')\nplt.title('Bathroom Distribution')\nplt.xlabel('Bathroom')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nfor i, (x, y) in enumerate(zip(dbathroom.index, dbathroom.values)):\n    plt.text(i, y, f\"{y}\", ha='center', va='bottom', fontsize=8)\nplt.show()\n\n\n\n\n\n\n\n\n\ndbedroom = airbnb[\"bedrooms\"].value_counts().sort_index()\ndbedroom.plot(kind='bar', color='#B2DF8A')\nplt.title('Bedroom Distribution')\nplt.xlabel('Bedroom')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\n\n# Add data labels aligned with the top of the bars\nfor i, (x, y) in enumerate(zip(dbedroom.index, dbedroom.values)):\n    plt.text(i, y, f\"{y}\", ha='center', va='bottom', fontsize=8)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nd_cleanliness = airbnb[\"review_scores_cleanliness\"].value_counts().sort_index()\nd_cleanliness.plot(kind='bar', color='#B2DF8A')\nplt.title('Cleanliness Distribution')\nplt.xlabel('Cleanliness')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nfor i, (x, y) in enumerate(zip(d_cleanliness.index, d_cleanliness.values)):\n    plt.text(i, y, f\"{y}\", ha='center', va='bottom', fontsize=8)\nplt.show()\n\n\n\n\n\n\n\n\n\nd_location = airbnb[\"review_scores_location\"].value_counts().sort_index()\nd_location.plot(kind='bar', color='#B2DF8A')\nplt.title('Location Distribution')\nplt.xlabel('Location')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nfor i, (x, y) in enumerate(zip(d_location.index, d_location.values)):\n    plt.text(i, y, f\"{y}\", ha='center', va='bottom', fontsize=8)   \nplt.show()\n\n\n\n\n\n\n\n\n\nd_value = airbnb[\"review_scores_value\"].value_counts().sort_index()\nd_value.plot(kind='bar', color='#B2DF8A')\nplt.title('Value Distribution')\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\n# Add data labels aligned with the top of the bars\nfor i, (x, y) in enumerate(zip(d_value.index, d_value.values)):\n    plt.text(i, y, f\"{y}\", ha='center', va='bottom', fontsize=8)\nplt.show()\n\n\n\n\n\n\n\n\n\nprice = airbnb[\"price\"].value_counts().sort_index()\nprice.plot(kind='line', color='#B2DF8A')\nplt.title('Price Distribution')\nplt.xlabel('Price')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nplt.show()\n\n\n\n\n\n\n\n\n\nrtype_price = airbnb.groupby('room_type')['price'].mean()\nrtype_price.plot(kind='bar', color='lightblue')\nplt.title('Average Price by Room Type')\nplt.xlabel('Room Type')\nplt.ylabel('Average Price')\nplt.xticks(rotation=0)\nfor i in range(len(rtype_price)):\n    plt.text(i, rtype_price[i] , f\"{round(rtype_price[i], 2)}\", ha='center', va='bottom')\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_44952/2344399035.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, rtype_price[i] , f\"{round(rtype_price[i], 2)}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nbathrooms_price = airbnb.groupby('bathrooms')['price'].mean()\nbathrooms_price.plot(kind='bar', color='lightblue')\nplt.title('Average Price by Number of Bathrooms')\nplt.xlabel('Number of Bathrooms')\nplt.ylabel('Average Price')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nbedrooms_price = airbnb.groupby('bedrooms')['price'].mean()\nbedrooms_price.plot(kind='bar', color='lightblue')\nplt.title('Average Price by Number of Bedrooms')\nplt.xlabel('Number of Bedrooms')\nplt.ylabel('Average Price')\nplt.xticks(rotation=0)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nscleanliness_price = airbnb.groupby('review_scores_cleanliness')['price'].mean()\nscleanliness_price.plot(kind='bar', color='lightblue')\nplt.title('Average Price by Cleanliness Score')\nplt.xlabel('Cleanliness Score')\nplt.ylabel('Average Price')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nslocation_price = airbnb.groupby('review_scores_location')['price'].mean()\nslocation_price.plot(kind='bar', color='lightblue')\nplt.title('Average Price by Location')\nplt.xlabel('Location')\nplt.ylabel('Average Price')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nsvalue_price = airbnb.groupby('review_scores_value')['price'].mean()\nsvalue_price.plot(kind='bar', color='lightblue')\nplt.title('Average Price by Value Score')\nplt.xlabel('Value Score')\nplt.ylabel('Average Price')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nModel building\n\nimport pandas as pd\nimport numpy as np\nimport patsy\nimport statsmodels.api as sm\n\n# Load dataset\n\n# Step 1: Select relevant variables\nrelevant_vars = ['number_of_reviews', 'bedrooms', 'bathrooms', 'room_type', 'price']\n\n# Step 2: Drop rows with missing values in relevant variables\nairbnb_clean = airbnb.dropna(subset=relevant_vars).copy()\n\n# Step 3: Feature engineering\n# Apply log-transform to skewed variable `price`\nairbnb_clean['price_log'] = np.log1p(airbnb_clean['price'])  # log(1 + price) to handle zeros/skewness\n\n# Convert categorical variable to category type (for dummy encoding)\nairbnb_clean['room_type'] = airbnb_clean['room_type'].astype('category')\n\n# Step 4: Create design matrices using patsy\n# This builds the regression formula for Poisson regression\ny, X = patsy.dmatrices(\n    'number_of_reviews ~ bedrooms + bathrooms + price_log + C(room_type)',\n    data=airbnb_clean,\n    return_type='dataframe'\n)\n\n# Step 5: Fit Poisson regression model using statsmodels\nmodel = sm.GLM(y, X, family=sm.families.Poisson())\nresults = model.fit()\n\n# Step 6: Output model summary\nprint(results.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                40395\nModel:                            GLM   Df Residuals:                    40389\nModel Family:                 Poisson   Df Model:                            5\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -7.2270e+05\nDate:                Wed, 07 May 2025   Deviance:                   1.3222e+06\nTime:                        12:30:55   Pearson chi2:                 2.16e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):             0.1308\nCovariance Type:            nonrobust                                         \n================================================================================================\n                                   coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------------------\nIntercept                        3.0093      0.013    230.701      0.000       2.984       3.035\nC(room_type)[T.Private room]    -0.1105      0.003    -33.717      0.000      -0.117      -0.104\nC(room_type)[T.Shared room]     -0.3607      0.009    -40.154      0.000      -0.378      -0.343\nbedrooms                         0.0871      0.002     43.538      0.000       0.083       0.091\nbathrooms                       -0.1409      0.004    -37.006      0.000      -0.148      -0.133\nprice_log                       -0.0273      0.003    -10.354      0.000      -0.033      -0.022\n================================================================================================\n\n\n\n\nCoefficient Interpretation (Exponentiate to interpret effect size):\nIn Poisson regression, coefficients represent the log change in the expected count per one-unit increase in the predictor. To interpret in terms of percent change, use: \\[\n\\text{Percent Change} = (e^{\\beta} - 1) \\times 100\n\\] Where \\(\\beta\\) is the coefficient from the model.\n\n\nPoisson Regression Coefficients\n[\n\\[\\begin{array}{|l|r|r|l|}\n\\hline\n\\textbf{Variable} & \\textbf{Coefficient} & \\textbf{P-value} & \\textbf{Interpretation} \\\\\n\\hline\n\\text{Intercept} & 3.0093 & &lt; 0.001 & \\text{Baseline: Entire home/apartment with 0 bedrooms and 0 bathrooms at price\\_log=0 is expected to have about 20.26 reviews } (e^{3.0093} \\approx 20.26)\\\\\n\\text{Private room (vs Entire home)} & -0.1105 & &lt; 0.001 & \\text{Private rooms have $\\sim$10.5\\% fewer reviews than entire homes/apartments } (e^{-0.1105} \\approx 0.895)\n\\\\\n\\text{Shared room (vs Entire home)} & -0.3607 & &lt; 0.001 & \\text{Shared rooms have $\\sim$30.3\\% fewer reviews than entire homes/apartments } (e^{-0.3607} \\approx 0.697)\n\\\\\n\\text{Bedrooms} & +0.0871 & &lt; 0.001 & \\text{Each extra bedroom increases reviews by $\\sim$9.1\\% } (e^{0.0871} \\approx 1.091) \\\\\n\\text{Bathrooms} & -0.1409 & &lt; 0.001 & \\text{Each bathroom decreases reviews by $\\sim$13.1\\% } (e^{-0.1409} \\approx 0.869) \\\\\n\\text{Price (log)} & -0.0273 & &lt; 0.001 & \\text{A 1\\% increase in price (log scale) slightly reduces reviews by $\\sim$2.7\\% } (e^{-0.0273} \\approx 0.973)\\\\\n\\hline\n\\end{array}\\]\n]\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nP-value\nInterpretation\n\n\n\n\nIntercept\n3.0093\n&lt; 0.001\nBaseline: Entire home/apartment with 0 bedrooms and 0 bathrooms at price_log=0Expected: \\((e^{3.0093} \\approx 20.26)\\)\n\n\nPrivate room (vs Entire home)\n-0.1105\n&lt; 0.001\nPrivate rooms have ~10.5% fewer reviews than entire homes/apartment \\((e^{-0.1105} \\approx 0.895)\\)\n\n\nShared room (vs Entire home)\n-0.3607\n&lt; 0.001\nShared rooms have ~30.3% fewer reviews than entire homes/apartment \\((e^{-0.3607} \\approx 0.697)\\)\n\n\nBedrooms\n+0.0871\n&lt; 0.001\nEach additional bedroom increases reviews by ~9.1% \\((e^{0.0871} \\approx 1.091)\\)\n\n\nBathrooms\n-0.1409\n&lt; 0.001\nEach additional bathroom decreases reviews by ~13.1% \\((e^{-0.1409} \\approx 0.869)\\)\n\n\nPrice (log)\n-0.0273\n&lt; 0.001\nA 1% increase in price slightly reduces reviews by ~2.7% \\((e^{-0.0273} \\approx 0.973)\\)\n\n\n\nSummary: - Room type: Private and shared rooms tend to receive fewer reviews than entire apartments (statistically significant). - Bedrooms: More bedrooms → more reviews (positive relationship). - Bathrooms: More bathrooms → surprisingly associated with fewer reviews (possibly due to multicollinearity or price confounding). - Price (log): Listings with higher prices (after log transformation) tend to receive slightly fewer reviews."
  },
  {
    "objectID": "HW3/hw3_questions.html",
    "href": "HW3/hw3_questions.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm."
  },
  {
    "objectID": "HW3/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "href": "HW3/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multi-nomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 3 products, then either \\(y=3\\) or \\(y=(0,0,1)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, brand, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 3 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^3e^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]"
  },
  {
    "objectID": "HW3/hw3_questions.html#simulate-conjoint-data",
    "href": "HW3/hw3_questions.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.\nEach alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.\nThe part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer \\(i\\) for hypothethical streaming service \\(j\\) is\n\\[\nu_{ij} = (1 \\times Netflix_j) + (0.5 \\times Prime_j) + (-0.8*Ads_j) - 0.1\\times Price_j + \\varepsilon_{ij}\n\\]\nwhere the variables are binary indicators and \\(\\varepsilon\\) is Type 1 Extreme Value (ie, Gumble) distributed.\nThe following code provides the simulation of the conjoint data.\n\n\n\n\n\n\nNote\n\n\n\n\n\n# set seed for reproducibility\nset.seed(123)\n\n# define attributes\nbrand &lt;- c(\"N\", \"P\", \"H\") # Netflix, Prime, Hulu\nad &lt;- c(\"Yes\", \"No\")\nprice &lt;- seq(8, 32, by=4)\n\n# generate all possible profiles\nprofiles &lt;- expand.grid(\n    brand = brand,\n    ad = ad,\n    price = price\n)\nm &lt;- nrow(profiles)\n\n# assign part-worth utilities (true parameters)\nb_util &lt;- c(N = 1.0, P = 0.5, H = 0)\na_util &lt;- c(Yes = -0.8, No = 0.0)\np_util &lt;- function(p) -0.1 * p\n\n# number of respondents, choice tasks, and alternatives per task\nn_peeps &lt;- 100\nn_tasks &lt;- 10\nn_alts &lt;- 3\n\n# function to simulate one respondent’s data\nsim_one &lt;- function(id) {\n  \n    datlist &lt;- list()\n    \n    # loop over choice tasks\n    for (t in 1:n_tasks) {\n        \n        # randomly sample 3 alts (better practice would be to use a design)\n        dat &lt;- cbind(resp=id, task=t, profiles[sample(m, size=n_alts), ])\n        \n        # compute deterministic portion of utility\n        dat$v &lt;- b_util[dat$brand] + a_util[dat$ad] + p_util(dat$price) |&gt; round(10)\n        \n        # add Gumbel noise (Type I extreme value)\n        dat$e &lt;- -log(-log(runif(n_alts)))\n        dat$u &lt;- dat$v + dat$e\n        \n        # identify chosen alternative\n        dat$choice &lt;- as.integer(dat$u == max(dat$u))\n        \n        # store task\n        datlist[[t]] &lt;- dat\n    }\n    \n    # combine all tasks for one respondent\n    do.call(rbind, datlist)\n}\n\n# simulate data for all respondents\nconjoint_data &lt;- do.call(rbind, lapply(1:n_peeps, sim_one))\n\n# remove values unobservable to the researcher\nconjoint_data &lt;- conjoint_data[ , c(\"resp\", \"task\", \"brand\", \"ad\", \"price\", \"choice\")]\n\n# clean up\nrm(list=setdiff(ls(), \"conjoint_data\"))"
  },
  {
    "objectID": "HW3/hw3_questions.html#preparing-the-data-for-estimation",
    "href": "HW3/hw3_questions.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\ntodo: reshape and prep the data"
  },
  {
    "objectID": "HW3/hw3_questions.html#estimation-via-maximum-likelihood",
    "href": "HW3/hw3_questions.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\ntodo: Code up the log-likelihood function.\ntodo: Use optim() in R or scipy.optimize() in Python to find the MLEs for the 4 parameters (\\(\\beta_\\text{netflix}\\), \\(\\beta_\\text{prime}\\), \\(\\beta_\\text{ads}\\), \\(\\beta_\\text{price}\\)), as well as their standard errors (from the Hessian). For each parameter construct a 95% confidence interval."
  },
  {
    "objectID": "HW3/hw3_questions.html#estimation-via-bayesian-methods",
    "href": "HW3/hw3_questions.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\ntodo: code up a metropolis-hasting MCMC sampler of the posterior distribution. Take 11,000 steps and throw away the first 1,000, retaining the subsequent 10,000.\nhint: Use N(0,5) priors for the betas on the binary variables, and a N(0,1) prior for the price beta.\n_hint: instead of calculating post=lik*prior, you can work in the log-space and calculate log-post = log-lik + log-prior (this should enable you to re-use your log-likelihood function from the MLE section just above)_\nhint: King Markov (in the video) use a candidate distribution of a coin flip to decide whether to move left or right among his islands. Unlike King Markov, we have 4 dimensions (because we have 4 betas) and our dimensions are continuous. So, use a multivariate normal distribution to pospose the next location for the algorithm to move to. I recommend a MNV(mu, Sigma) where mu=c(0,0,0,0) and sigma has diagonal values c(0.05, 0.05, 0.05, 0.005) and zeros on the off-diagonal. Since this MVN has no covariances, you can sample each dimension independently (so 4 univariate normals instead of 1 multivariate normal), where the first 3 univariate normals are N(0,0.05) and the last one if N(0,0.005).\ntodo: for at least one of the 4 parameters, show the trace plot of the algorithm, as well as the histogram of the posterior distribution.\ntodo: report the 4 posterior means, standard deviations, and 95% credible intervals and compare them to your results from the Maximum Likelihood approach."
  },
  {
    "objectID": "HW3/hw3_questions.html#discussion",
    "href": "HW3/hw3_questions.html#discussion",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\ntodo: Suppose you did not simulate the data. What do you observe about the parameter estimates? What does \\(\\beta_\\text{Netflix} &gt; \\beta_\\text{Prime}\\) mean? Does it make sense that \\(\\beta_\\text{price}\\) is negative?\ntodo: At a high level, discuss what change you would need to make in order to simulate data from — and estimate the parameters of — a multi-level (aka random-parameter or hierarchical) model. This is the model we use to analyze “real world” conjoint data."
  },
  {
    "objectID": "projects/HW3/hw3_questions.html",
    "href": "projects/HW3/hw3_questions.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm."
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "href": "projects/HW3/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multi-nomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 3 products, then either \\(y=3\\) or \\(y=(0,0,1)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, brand, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 3 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^3e^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#simulate-conjoint-data",
    "href": "projects/HW3/hw3_questions.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.\nEach alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.\nThe part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer \\(i\\) for hypothethical streaming service \\(j\\) is\n\\[\nu_{ij} = (1 \\times Netflix_j) + (0.5 \\times Prime_j) + (-0.8*Ads_j) - 0.1\\times Price_j + \\varepsilon_{ij}\n\\]\nwhere the variables are binary indicators and \\(\\varepsilon\\) is Type 1 Extreme Value (ie, Gumble) distributed.\nThe following code provides the simulation of the conjoint data.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n# set seed for reproducibility\nset.seed(123)\n\n# define attributes\nbrand &lt;- c(\"N\", \"P\", \"H\") # Netflix, Prime, Hulu\nad &lt;- c(\"Yes\", \"No\")\nprice &lt;- seq(8, 32, by=4)\n\n# generate all possible profiles\nprofiles &lt;- expand.grid(\n    brand = brand,\n    ad = ad,\n    price = price\n)\nm &lt;- nrow(profiles)\n\n# assign part-worth utilities (true parameters)\nb_util &lt;- c(N = 1.0, P = 0.5, H = 0)\na_util &lt;- c(Yes = -0.8, No = 0.0)\np_util &lt;- function(p) -0.1 * p\n\n# number of respondents, choice tasks, and alternatives per task\nn_peeps &lt;- 100\nn_tasks &lt;- 10\nn_alts &lt;- 3\n\n# function to simulate one respondent’s data\nsim_one &lt;- function(id) {\n  \n    datlist &lt;- list()\n    \n    # loop over choice tasks\n    for (t in 1:n_tasks) {\n        \n        # randomly sample 3 alts (better practice would be to use a design)\n        dat &lt;- cbind(resp=id, task=t, profiles[sample(m, size=n_alts), ])\n        \n        # compute deterministic portion of utility\n        dat$v &lt;- b_util[dat$brand] + a_util[dat$ad] + p_util(dat$price) |&gt; round(10)\n        \n        # add Gumbel noise (Type I extreme value)\n        dat$e &lt;- -log(-log(runif(n_alts)))\n        dat$u &lt;- dat$v + dat$e\n        \n        # identify chosen alternative\n        dat$choice &lt;- as.integer(dat$u == max(dat$u))\n        \n        # store task\n        datlist[[t]] &lt;- dat\n    }\n    \n    # combine all tasks for one respondent\n    do.call(rbind, datlist)\n}\n\n# simulate data for all respondents\nconjoint_data &lt;- do.call(rbind, lapply(1:n_peeps, sim_one))\n\n# remove values unobservable to the researcher\nconjoint_data &lt;- conjoint_data[ , c(\"resp\", \"task\", \"brand\", \"ad\", \"price\", \"choice\")]\n\n# clean up\nrm(list=setdiff(ls(), \"conjoint_data\"))"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#preparing-the-data-for-estimation",
    "href": "projects/HW3/hw3_questions.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\nThis section focuses on transforming the raw dataset into a format suitable for estimating a multinomial logit (MNL) model. The key steps include:\n\nConverting categorical variables to binary dummy variables: For example, the brand variable, which has three levels (e.g., N, P, H), is converted into two binary indicators: brand_N and brand_P. The base level brand_H is omitted to avoid multicollinearity (the dummy variable trap). This is done using pandas.get_dummies() with drop_first=True.\nMaintaining the choice-task-alternative structure: The data is structured at the respondent-task-alternative level, meaning each respondent completes multiple choice tasks, each involving three alternatives. This structure is necessary for computing utility and choice probabilities for each option within a task.\n\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom numpy.linalg import inv\nimport matplotlib.pyplot as plt\n\n\nconjoint = pd.read_csv('conjoint_data.csv')\nconjoint\n\nconjoint['ad_yes'] = conjoint['ad'].apply(lambda x: 1 if x == 'Yes' else 0)\ndf_dummies = pd.get_dummies(conjoint, columns=['brand'], drop_first=True)\ndf_dummies.drop(columns=['ad'], inplace=True)\ndf_dummies = df_dummies.astype(int)\ndf_dummies\n\n\n\n\n\n\n\n\nresp\ntask\nchoice\nprice\nad_yes\nbrand_N\nbrand_P\n\n\n\n\n0\n1\n1\n1\n28\n1\n1\n0\n\n\n1\n1\n1\n0\n16\n1\n0\n0\n\n\n2\n1\n1\n0\n16\n1\n0\n1\n\n\n3\n1\n2\n0\n32\n1\n1\n0\n\n\n4\n1\n2\n1\n16\n1\n0\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2995\n100\n9\n1\n12\n0\n0\n0\n\n\n2996\n100\n9\n0\n8\n1\n0\n1\n\n\n2997\n100\n10\n0\n28\n1\n1\n0\n\n\n2998\n100\n10\n0\n24\n0\n0\n0\n\n\n2999\n100\n10\n1\n16\n0\n0\n0\n\n\n\n\n3000 rows × 7 columns"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#estimation-via-maximum-likelihood",
    "href": "projects/HW3/hw3_questions.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\nIn this section, we implement the log-likelihood function for the MNL model and estimate the model parameters using maximum likelihood via scipy.optimize.minimize(). The estimated parameters include:\n\nβ_brand_N: preference for brand N relative to the baseline (brand H)\nβ_brand_P: preference for brand P relative to brand H\nβ_ad_Yes: the effect of advertising on utility\nβ_price: the effect of price on choice\n\nThe utility for each alternative is modeled as a linear combination of its features. We compute the softmax probability for each alternative and use these probabilities to construct the log-likelihood. The optimizer returns parameter estimates along with standard errors, from which we compute 95% confidence intervals for inference.\n\ndef log_likelihood(beta, data, negate=False):\n    beta_n, beta_p, beta_ad, beta_price = beta\n    utility = (\n        beta_n * data[\"brand_N\"] +\n        beta_p * data[\"brand_P\"] +\n        beta_ad * data[\"ad_yes\"] +\n        beta_price * data[\"price\"]\n    )\n    data = data.copy()\n    data[\"exp_utility\"] = np.exp(utility)\n    data[\"denom\"] = data.groupby([\"resp\", \"task\"])[\"exp_utility\"].transform(\"sum\")\n    data[\"prob\"] = data[\"exp_utility\"] / data[\"denom\"]\n    data[\"log_likelihood\"] = data[\"choice\"] * np.log(data[\"prob\"])\n    result = data[\"log_likelihood\"].sum()\n    return -result if negate else result \n\n\ninitial_beta = np.zeros(4)\nresult = minimize(log_likelihood, initial_beta, args=(df_dummies, True), method=\"BFGS\")\n\n# Extract estimates, standard errors, and 95% confidence intervals\nbeta_hat = result.x\nhessian_inv = result.hess_inv\nstd_errors = np.sqrt(np.diag(hessian_inv))\nconf_int = np.vstack([beta_hat - 1.96 * std_errors, beta_hat + 1.96 * std_errors]).T\n\n# Print results\nparams = [\"brand_N\", \"brand_P\", \"ad_Yes\", \"price\"]\nfor i in range(4):\n    print(f\"{params[i]}: Estimate = {beta_hat[i]:.4f}, StdErr = {std_errors[i]:.4f}, \"\n          f\"95% CI = [{conf_int[i, 0]:.4f}, {conf_int[i, 1]:.4f}]\")\n\nbrand_N: Estimate = 0.9412, StdErr = 0.1148, 95% CI = [0.7161, 1.1663]\nbrand_P: Estimate = 0.5016, StdErr = 0.1207, 95% CI = [0.2650, 0.7382]\nad_Yes: Estimate = -0.7320, StdErr = 0.0886, 95% CI = [-0.9057, -0.5583]\nprice: Estimate = -0.0995, StdErr = 0.0064, 95% CI = [-0.1119, -0.0870]"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#estimation-via-bayesian-methods",
    "href": "projects/HW3/hw3_questions.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\nThis section implements Bayesian estimation using the Metropolis-Hastings MCMC algorithm. We assign prior distributions as follows:\n\nN(0, 5) for the binary features (brands and ad)\nN(0, 1) for the price coefficient\n\nThe MCMC algorithm runs for 11,000 iterations, discarding the first 1,000 as burn-in. Each iteration proposes a new set of coefficients by adding random noise (independently for each parameter) from a normal distribution with small variance. The posterior is evaluated in log space as the sum of the log-likelihood and log-prior.\nWe report the posterior means, standard deviations, and 95% credible intervals for each parameter. These are then compared to the MLE results to assess consistency and understand uncertainty from a Bayesian perspective.\n\n# Define log-prior\ndef log_prior(beta):\n    # N(0,5) for first 3; N(0,1) for price\n    log_p = -0.5 * ((beta[0:3]**2) / 5 + (beta[3]**2) / 1)\n    return np.sum(log_p)\n\n# Define log-posterior\ndef log_posterior(beta, data, negate=False):\n    return log_likelihood(beta, data, negate=False) + log_prior(beta)\n\n\n# Run MCMC using Metropolis-Hastings\nnp.random.seed(0)\nn_iter = 11000\nburn_in = 1000\nbeta_samples = np.zeros((n_iter, 4))\nbeta_current = np.zeros(4)\nlog_post_current = log_posterior(beta_current, df_dummies, negate=True)\nproposal_std = np.array([0.05, 0.05, 0.05, 0.005])\n\nfor i in range(n_iter):\n    proposal = beta_current + np.random.normal(0, proposal_std)\n    log_post_proposal = log_posterior(proposal, df_dummies, negate=True)\n    log_accept_ratio = log_post_proposal - log_post_current\n    if np.log(np.random.rand()) &lt; log_accept_ratio:\n        beta_current = proposal\n        log_post_current = log_post_proposal\n    beta_samples[i] = beta_current\n\n\n# Discard burn-in\nposterior_samples = beta_samples[burn_in:]\n\n# Compute summary statistics\nposterior_means = posterior_samples.mean(axis=0)\nposterior_sds = posterior_samples.std(axis=0)\nposterior_cis = np.percentile(posterior_samples, [2.5, 97.5], axis=0).T\n\nparams = [\"brand_N\", \"brand_P\", \"ad_Yes\", \"price\"]\nprint(\"Posterior Summary:\")\nfor i in range(4):\n    print(f\"{params[i]}: Mean = {posterior_means[i]:.4f}, SD = {posterior_sds[i]:.4f}, \"\n          f\"95% CI = [{posterior_cis[i, 0]:.4f}, {posterior_cis[i, 1]:.4f}]\")\n\nPosterior Summary:\nbrand_N: Mean = 0.9348, SD = 0.1124, 95% CI = [0.7189, 1.1746]\nbrand_P: Mean = 0.4915, SD = 0.1104, 95% CI = [0.2791, 0.7109]\nad_Yes: Mean = -0.7298, SD = 0.0859, 95% CI = [-0.8946, -0.5611]\nprice: Mean = -0.0995, SD = 0.0063, 95% CI = [-0.1123, -0.0873]\n\n\n\n# Optional Trace and Histogram Plot (example for price)\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(posterior_samples[:, 3], color='green', alpha=0.5)\nplt.title(\"Trace plot for β_price\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"β_price\")\n\nplt.subplot(1, 2, 2)\nplt.hist(posterior_samples[:, 3], bins=30, density=True, color='green', alpha=0.5)\nplt.title(\"Posterior Distribution for β_price\")\nplt.xlabel(\"β_price\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/HW3/hw3_questions.html#discussion",
    "href": "projects/HW3/hw3_questions.html#discussion",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\nThe parameter estimates from both the maximum likelihood and Bayesian approaches align well with intuition about consumer behavior. The positive coefficients for brand_N and brand_P indicate that, on average, consumers prefer these brands over the baseline brand H, with a stronger preference for brand_N (Netflix) over brand_P (Prime Video). This suggests a clear brand hierarchy in perceived utility.\nThe negative coefficient on price is both expected and meaningful. It implies that, holding other factors constant, an increase in price decreases the probability that a product is chosen. This is consistent with standard economic theory: consumers are price-sensitive and prefer cheaper options, all else being equal. The fact that _{} &lt; 0 supports the validity of the model.\nInterestingly, the ad_Yes coefficient is also negative, suggesting that the presence of advertising reduces utility. In this context, it may be that ads are perceived as intrusive or associated with lower-value offerings, leading to a lower probability of choice for advertised options.\nTo extend the model and better reflect real-world variation in consumer preferences, one could use a multilevel (hierarchical) model. In such models, individual-level parameters _i are assumed to vary across respondents and are drawn from a population distribution (e.g., _i (, )). This captures heterogeneity by allowing each respondent to weigh attributes differently. Estimation involves recovering both individual preferences and the population-level parameters, typically via hierarchical Bayes or simulated maximum likelihood. This approach is widely used in practical conjoint analysis for more accurate prediction and segmentation."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html",
    "href": "projects/HW4/hw4_questions.html",
    "title": "K-Means & K Nearest Neighbors",
    "section": "",
    "text": "First, we display the distribution of the variables bill_length_mm and flipper_length_mm from the Palmer Penguins dataset using a scatter plot.\n\n\n\n\n\n\n\n\n\nThen, we write a function to manually implement a simple K-means algorithm, using K=3 as an example. Each plot demonstrates how the algorithm works by gradually adjusting the centroids for each cluster until it finds the optimal solution.\n\ndef kmeans_custom(X, k=3, max_iters=10, random_state=42):\n    np.random.seed(random_state)\n    # Randomly initialize centroids\n    centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n    for iteration in range(max_iters):\n        # Assign clusters\n        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n        labels = np.argmin(distances, axis=1)\n\n        # Plot clusters and centroids\n        plt.figure()\n        for i in range(k):\n            cluster_points = X[labels == i]\n            plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f\"Cluster {i}\")\n        plt.scatter(centroids[:, 0], centroids[:, 1], color='black', marker='x', s=100, label='Centroids')\n        plt.xlabel(\"Bill Length (mm)\")\n        plt.ylabel(\"Flipper Length (mm)\")\n        plt.title(f\"K-Means Iteration {iteration+1}\")\n        plt.legend()\n        plt.show()\n\n        # Recalculate centroids\n        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n        if np.allclose(centroids, new_centroids):\n            break\n        centroids = new_centroids\n    return labels, centroids\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, we use the buit-in KMeans from scikit-learn to validate and compare the outcome.\n\nkmeans_sklearn = KMeans(n_clusters=3, n_init=10, random_state=42)\nlabels_sklearn = kmeans_sklearn.fit_predict(X)\n\nplt.scatter(X[:, 0], X[:, 1], c=labels_sklearn, cmap='viridis')\nplt.xlabel(\"Bill Length (mm)\")\nplt.ylabel(\"Flipper Length (mm)\")\nplt.title(\"Sklearn KMeans Clustering (K=3)\")\nplt.show()\n\n\n\n\n\n\n\n\nFinally, we evaluate for K=2 to 7 using WCSS and Silhouette Score\n\nwcss = []\nsilhouette = []\nk_values = range(2, 8)\n\nfor k in k_values:\n    model = KMeans(n_clusters=k, n_init=10, random_state=42)\n    y_k = model.fit_predict(X)\n    wcss.append(model.inertia_)\n    silhouette.append(silhouette_score(X, y_k))\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(k_values, wcss, marker='o')\nplt.title(\"Within-Cluster Sum of Squares\")\nplt.xlabel(\"k\")\nplt.ylabel(\"WCSS\")\n\nplt.subplot(1, 2, 2)\nplt.plot(k_values, silhouette, marker='o')\nplt.title(\"Silhouette Score\")\nplt.xlabel(\"k\")\nplt.ylabel(\"Score\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe plots show how Within-Cluster Sum of Squares (WCSS) decreases as k increases (as expected), while the Silhouette Score peaks around k = 2 or 3, suggesting one of those is likely the “best” number of clusters.\nThis analysis helps determine an appropriate cluster count without ground truth labels."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#a.-k-means",
    "href": "projects/HW4/hw4_questions.html#a.-k-means",
    "title": "K-Means & K Nearest Neighbors",
    "section": "",
    "text": "First, we display the distribution of the variables bill_length_mm and flipper_length_mm from the Palmer Penguins dataset using a scatter plot.\n\n\n\n\n\n\n\n\n\nThen, we write a function to manually implement a simple K-means algorithm, using K=3 as an example. Each plot demonstrates how the algorithm works by gradually adjusting the centroids for each cluster until it finds the optimal solution.\n\ndef kmeans_custom(X, k=3, max_iters=10, random_state=42):\n    np.random.seed(random_state)\n    # Randomly initialize centroids\n    centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n    for iteration in range(max_iters):\n        # Assign clusters\n        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n        labels = np.argmin(distances, axis=1)\n\n        # Plot clusters and centroids\n        plt.figure()\n        for i in range(k):\n            cluster_points = X[labels == i]\n            plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f\"Cluster {i}\")\n        plt.scatter(centroids[:, 0], centroids[:, 1], color='black', marker='x', s=100, label='Centroids')\n        plt.xlabel(\"Bill Length (mm)\")\n        plt.ylabel(\"Flipper Length (mm)\")\n        plt.title(f\"K-Means Iteration {iteration+1}\")\n        plt.legend()\n        plt.show()\n\n        # Recalculate centroids\n        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n        if np.allclose(centroids, new_centroids):\n            break\n        centroids = new_centroids\n    return labels, centroids\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, we use the buit-in KMeans from scikit-learn to validate and compare the outcome.\n\nkmeans_sklearn = KMeans(n_clusters=3, n_init=10, random_state=42)\nlabels_sklearn = kmeans_sklearn.fit_predict(X)\n\nplt.scatter(X[:, 0], X[:, 1], c=labels_sklearn, cmap='viridis')\nplt.xlabel(\"Bill Length (mm)\")\nplt.ylabel(\"Flipper Length (mm)\")\nplt.title(\"Sklearn KMeans Clustering (K=3)\")\nplt.show()\n\n\n\n\n\n\n\n\nFinally, we evaluate for K=2 to 7 using WCSS and Silhouette Score\n\nwcss = []\nsilhouette = []\nk_values = range(2, 8)\n\nfor k in k_values:\n    model = KMeans(n_clusters=k, n_init=10, random_state=42)\n    y_k = model.fit_predict(X)\n    wcss.append(model.inertia_)\n    silhouette.append(silhouette_score(X, y_k))\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(k_values, wcss, marker='o')\nplt.title(\"Within-Cluster Sum of Squares\")\nplt.xlabel(\"k\")\nplt.ylabel(\"WCSS\")\n\nplt.subplot(1, 2, 2)\nplt.plot(k_values, silhouette, marker='o')\nplt.title(\"Silhouette Score\")\nplt.xlabel(\"k\")\nplt.ylabel(\"Score\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe plots show how Within-Cluster Sum of Squares (WCSS) decreases as k increases (as expected), while the Silhouette Score peaks around k = 2 or 3, suggesting one of those is likely the “best” number of clusters.\nThis analysis helps determine an appropriate cluster count without ground truth labels."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#b.-latent-class-mnl",
    "href": "projects/HW4/hw4_questions.html#b.-latent-class-mnl",
    "title": "Add Title",
    "section": "1b. Latent-Class MNL",
    "text": "1b. Latent-Class MNL\ntodo: Use the Yogurt dataset to estimate a latent-class MNL model. This model was formally introduced in the paper by Kamakura & Russell (1989); you may want to read or reference page 2 of the pdf, which is described in the class slides, session 4, slides 56-57.\nThe data provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were “featured” in the store as a form of advertising (f1:f4), and the products’ prices in price-per-ounce (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1’s purchase. Consumers 2 through 7 each bought yogurt 2, etc. You may want to reshape the data from its current “wide” format into a “long” format.\ntodo: Fit the standard MNL model on these data. Then fit the latent-class MNL on these data separately for 2, 3, 4, and 5 latent classes.\ntodo: How many classes are suggested by the \\(BIC = -2*\\ell_n  + k*log(n)\\)? (where \\(\\ell_n\\) is the log-likelihood, \\(n\\) is the sample size, and \\(k\\) is the number of parameters.) The Bayesian-Schwarz Information Criterion link is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate – akin to the adjusted R-squared for the linear regression model. Note, that a lower BIC indicates a better model fit, accounting for the number of parameters in the model.\ntodo: compare the parameter estimates between (1) the aggregate MNL, and (2) the latent-class MNL with the number of classes suggested by the BIC."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#a.-k-nearest-neighbors",
    "href": "projects/HW4/hw4_questions.html#a.-k-nearest-neighbors",
    "title": "K-Means & K Nearest Neighbors",
    "section": "2a. K Nearest Neighbors",
    "text": "2a. K Nearest Neighbors\ntodo: use the following code (or the python equivalent) to generate a synthetic dataset for the k-nearest neighbors algorithm. The code generates a dataset with two features, x1 and x2, and a binary outcome variable y that is determined by whether x2 is above or below a wiggly boundary defined by a sin function.\ntodo: plot the data where the horizontal axis is x1, the vertical axis is x2, and the points are colored by the value of y. You may optionally draw the wiggly boundary.\ntodo: generate a test dataset with 100 points, using the same code as above but with a different seed.\ntodo: implement KNN by hand. Check you work with a built-in function – eg, class::knn() or caret::train(method=\"knn\") in R, or scikit-learn’s KNeighborsClassifier in Python.\ntodo: run your function for k=1,…,k=30, each time noting the percentage of correctly-classified points from the test dataset. Plot the results, where the horizontal axis is 1-30 and the vertical axis is the percentage of correctly-classified points. What is the optimal value of k as suggested by your plot?\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\n\n# Step 1: Generate training data\nnp.random.seed(42)\nn = 100\nx1_train = np.random.uniform(-3, 3, n)\nx2_train = np.random.uniform(-3, 3, n)\nboundary_train = np.sin(4 * x1_train) + x1_train\ny_train = (x2_train &gt; boundary_train).astype(int)\n\n\n# Visualize training data\nplt.figure()\nplt.scatter(x1_train, x2_train, c=y_train, cmap='bwr', edgecolor='k')\nplt.title(\"Training Data with Wiggly Boundary\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Step 2: Generate test data\nnp.random.seed(2025)\nx1_test = np.random.uniform(-3, 3, n)\nx2_test = np.random.uniform(-3, 3, n)\nboundary_test = np.sin(4 * x1_test) + x1_test\ny_test = (x2_test &gt; boundary_test).astype(int)\n\nX_train = np.column_stack((x1_train, x2_train))\nX_test = np.column_stack((x1_test, x2_test))\n\n\n# Step 3: Implement and evaluate KNN from k=1 to 30\naccuracy_scores = []\n\nfor k in range(1, 31):\n    model = KNeighborsClassifier(n_neighbors=k)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    accuracy_scores.append(acc)\n\n\n# Step 4: Plot accuracy vs. k\nplt.figure(figsize=(8, 5))\nplt.plot(range(1, 31), accuracy_scores, marker='o')\nplt.title(\"KNN Accuracy on Test Data\")\nplt.xlabel(\"k (Number of Neighbors)\")\nplt.ylabel(\"Accuracy\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#b.-key-drivers-analysis",
    "href": "projects/HW4/hw4_questions.html#b.-key-drivers-analysis",
    "title": "K-Means & K Nearest Neighbors",
    "section": "2b. Key Drivers Analysis",
    "text": "2b. Key Drivers Analysis\ntodo: replicate the table on slide 75 of the session 5 slides. Specifically, using the dataset provided in the file data_for_drivers_analysis.csv, calculate: pearson correlations, standardized regression coefficients, “usefulness”, Shapley values for a linear regression, Johnson’s relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python; you do not need to perform these calculations “by hand.”\nIf you want a challenge, add additional measures to the table such as the importance scores from XGBoost, from a Neural Network, or from any additional method that measures the importance of variables."
  },
  {
    "objectID": "HW4/hw4_questions.html",
    "href": "HW4/hw4_questions.html",
    "title": "Add Title",
    "section": "",
    "text": "todo: do two analyses. Do one of either 1a or 1b, AND one of either 2a or 2b."
  },
  {
    "objectID": "HW4/hw4_questions.html#a.-k-means",
    "href": "HW4/hw4_questions.html#a.-k-means",
    "title": "Add Title",
    "section": "1a. K-Means",
    "text": "1a. K-Means\ntodo: write your own code to implement the k-means algorithm. Make plots of the various steps the algorithm takes so you can “see” the algorithm working. Test your algorithm on the Palmer Penguins dataset, specifically using the bill length and flipper length variables. Compare your results to the built-in kmeans function in R or Python.\ntodo: Calculate both the within-cluster-sum-of-squares and silhouette scores (you can use built-in functions to do so) and plot the results for various numbers of clusters (ie, K=2,3,…,7). What is the “right” number of clusters as suggested by these two metrics?\nIf you want a challenge, add your plots as an animated gif on your website so that the result looks something like this."
  },
  {
    "objectID": "HW4/hw4_questions.html#b.-latent-class-mnl",
    "href": "HW4/hw4_questions.html#b.-latent-class-mnl",
    "title": "Add Title",
    "section": "1b. Latent-Class MNL",
    "text": "1b. Latent-Class MNL\ntodo: Use the Yogurt dataset to estimate a latent-class MNL model. This model was formally introduced in the paper by Kamakura & Russell (1989); you may want to read or reference page 2 of the pdf, which is described in the class slides, session 4, slides 56-57.\nThe data provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were “featured” in the store as a form of advertising (f1:f4), and the products’ prices in price-per-ounce (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1’s purchase. Consumers 2 through 7 each bought yogurt 2, etc. You may want to reshape the data from its current “wide” format into a “long” format.\ntodo: Fit the standard MNL model on these data. Then fit the latent-class MNL on these data separately for 2, 3, 4, and 5 latent classes.\ntodo: How many classes are suggested by the \\(BIC = -2*\\ell_n  + k*log(n)\\)? (where \\(\\ell_n\\) is the log-likelihood, \\(n\\) is the sample size, and \\(k\\) is the number of parameters.) The Bayesian-Schwarz Information Criterion link is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate – akin to the adjusted R-squared for the linear regression model. Note, that a lower BIC indicates a better model fit, accounting for the number of parameters in the model.\ntodo: compare the parameter estimates between (1) the aggregate MNL, and (2) the latent-class MNL with the number of classes suggested by the BIC."
  },
  {
    "objectID": "HW4/hw4_questions.html#a.-k-nearest-neighbors",
    "href": "HW4/hw4_questions.html#a.-k-nearest-neighbors",
    "title": "Add Title",
    "section": "2a. K Nearest Neighbors",
    "text": "2a. K Nearest Neighbors\ntodo: use the following code (or the python equivalent) to generate a synthetic dataset for the k-nearest neighbors algorithm. The code generates a dataset with two features, x1 and x2, and a binary outcome variable y that is determined by whether x2 is above or below a wiggly boundary defined by a sin function.\n\n# gen data -----\nset.seed(42)\nn &lt;- 100\nx1 &lt;- runif(n, -3, 3)\nx2 &lt;- runif(n, -3, 3)\nx &lt;- cbind(x1, x2)\n\n# define a wiggly boundary\nboundary &lt;- sin(4*x1) + x1\ny &lt;- ifelse(x2 &gt; boundary, 1, 0) |&gt; as.factor()\ndat &lt;- data.frame(x1 = x1, x2 = x2, y = y)\n\ntodo: plot the data where the horizontal axis is x1, the vertical axis is x2, and the points are colored by the value of y. You may optionally draw the wiggly boundary.\ntodo: generate a test dataset with 100 points, using the same code as above but with a different seed.\ntodo: implement KNN by hand. Check you work with a built-in function – eg, class::knn() or caret::train(method=\"knn\") in R, or scikit-learn’s KNeighborsClassifier in Python.\ntodo: run your function for k=1,…,k=30, each time noting the percentage of correctly-classified points from the test dataset. Plot the results, where the horizontal axis is 1-30 and the vertical axis is the percentage of correctly-classified points. What is the optimal value of k as suggested by your plot?"
  },
  {
    "objectID": "HW4/hw4_questions.html#b.-key-drivers-analysis",
    "href": "HW4/hw4_questions.html#b.-key-drivers-analysis",
    "title": "Add Title",
    "section": "2b. Key Drivers Analysis",
    "text": "2b. Key Drivers Analysis\ntodo: replicate the table on slide 75 of the session 5 slides. Specifically, using the dataset provided in the file data_for_drivers_analysis.csv, calculate: pearson correlations, standardized regression coefficients, “usefulness”, Shapley values for a linear regression, Johnson’s relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python; you do not need to perform these calculations “by hand.”\nIf you want a challenge, add additional measures to the table such as the importance scores from XGBoost, from a Neural Network, or from any additional method that measures the importance of variables."
  },
  {
    "objectID": "projects/HW4/HW4.html",
    "href": "projects/HW4/HW4.html",
    "title": "Lynn's Quarto Website",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom matplotlib import cm\n\n\n# Step 1: Load data and clean it\npenguins_df = pd.read_csv(\"palmer_penguins.csv\")\npenguins_df = penguins_df[['bill_length_mm', 'flipper_length_mm']].dropna()\nX = penguins_df.values\n\n# Step 2: Visualize raw data\nplt.scatter(X[:, 0], X[:, 1], c='skyblue')\nplt.xlabel(\"Bill Length (mm)\")\nplt.ylabel(\"Flipper Length (mm)\")\nplt.title(\"Raw Data: Palmer Penguins\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# Step 3: Manually implement simple K-means (for K=3 as example)\ndef kmeans_custom(X, k=3, max_iters=10, random_state=42):\n    np.random.seed(random_state)\n    # Randomly initialize centroids\n    centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n    for iteration in range(max_iters):\n        # Assign clusters\n        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n        labels = np.argmin(distances, axis=1)\n\n        # Plot clusters and centroids\n        plt.figure()\n        for i in range(k):\n            cluster_points = X[labels == i]\n            plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f\"Cluster {i}\")\n        plt.scatter(centroids[:, 0], centroids[:, 1], color='black', marker='x', s=100, label='Centroids')\n        plt.xlabel(\"Bill Length (mm)\")\n        plt.ylabel(\"Flipper Length (mm)\")\n        plt.title(f\"K-Means Iteration {iteration+1}\")\n        plt.legend()\n        plt.show()\n\n        # Recalculate centroids\n        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n        if np.allclose(centroids, new_centroids):\n            break\n        centroids = new_centroids\n    return labels, centroids\n\n\nlabels_custom, centroids_custom = kmeans_custom(X, k=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Step 4: Use sklearn's KMeans and compare\nkmeans_sklearn = KMeans(n_clusters=3, n_init=10, random_state=42)\nlabels_sklearn = kmeans_sklearn.fit_predict(X)\n\nplt.scatter(X[:, 0], X[:, 1], c=labels_sklearn, cmap='viridis')\nplt.xlabel(\"Bill Length (mm)\")\nplt.ylabel(\"Flipper Length (mm)\")\nplt.title(\"Sklearn KMeans Clustering (K=3)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# Step 5: Evaluate for K=2 to 7 using WCSS and Silhouette Score\nwcss = []\nsilhouette = []\nk_values = range(2, 8)\n\nfor k in k_values:\n    model = KMeans(n_clusters=k, n_init=10, random_state=42)\n    y_k = model.fit_predict(X)\n    wcss.append(model.inertia_)\n    silhouette.append(silhouette_score(X, y_k))\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(k_values, wcss, marker='o')\nplt.title(\"Within-Cluster Sum of Squares\")\nplt.xlabel(\"k\")\nplt.ylabel(\"WCSS\")\n\nplt.subplot(1, 2, 2)\nplt.plot(k_values, silhouette, marker='o')\nplt.title(\"Silhouette Score\")\nplt.xlabel(\"k\")\nplt.ylabel(\"Score\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#k-means",
    "href": "projects/HW4/hw4_questions.html#k-means",
    "title": "K-Means & K Nearest Neighbors",
    "section": "",
    "text": "First, we display the distribution of the variables bill_length_mm and flipper_length_mm from the Palmer Penguins dataset using a scatter plot.\n\n\n\n\n\n\n\n\n\nThen, we write a function to manually implement a simple K-means algorithm, using K=3 as an example. Each plot demonstrates how the algorithm works by gradually adjusting the centroids for each cluster until it finds the optimal solution.\n\ndef kmeans_custom(X, k=3, max_iters=10, random_state=42):\n    np.random.seed(random_state)\n    # Randomly initialize centroids\n    centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n    for iteration in range(max_iters):\n        # Assign clusters\n        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n        labels = np.argmin(distances, axis=1)\n\n        # Plot clusters and centroids\n        plt.figure()\n        for i in range(k):\n            cluster_points = X[labels == i]\n            plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f\"Cluster {i}\")\n        plt.scatter(centroids[:, 0], centroids[:, 1], color='black', marker='x', s=100, label='Centroids')\n        plt.xlabel(\"Bill Length (mm)\")\n        plt.ylabel(\"Flipper Length (mm)\")\n        plt.title(f\"K-Means Iteration {iteration+1}\")\n        plt.legend()\n        plt.show()\n\n        # Recalculate centroids\n        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n        if np.allclose(centroids, new_centroids):\n            break\n        centroids = new_centroids\n    return labels, centroids\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, we use the buit-in KMeans from scikit-learn to validate and compare the outcome.\n\nkmeans_sklearn = KMeans(n_clusters=3, n_init=10, random_state=42)\nlabels_sklearn = kmeans_sklearn.fit_predict(X)\n\nplt.scatter(X[:, 0], X[:, 1], c=labels_sklearn, cmap='viridis')\nplt.xlabel(\"Bill Length (mm)\")\nplt.ylabel(\"Flipper Length (mm)\")\nplt.title(\"Sklearn KMeans Clustering (K=3)\")\nplt.show()\n\n\n\n\n\n\n\n\nFinally, we evaluate for K=2 to 7 using WCSS and Silhouette Score\n\nwcss = []\nsilhouette = []\nk_values = range(2, 8)\n\nfor k in k_values:\n    model = KMeans(n_clusters=k, n_init=10, random_state=42)\n    y_k = model.fit_predict(X)\n    wcss.append(model.inertia_)\n    silhouette.append(silhouette_score(X, y_k))\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(k_values, wcss, marker='o')\nplt.title(\"Within-Cluster Sum of Squares\")\nplt.xlabel(\"k\")\nplt.ylabel(\"WCSS\")\n\nplt.subplot(1, 2, 2)\nplt.plot(k_values, silhouette, marker='o')\nplt.title(\"Silhouette Score\")\nplt.xlabel(\"k\")\nplt.ylabel(\"Score\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe plots show how Within-Cluster Sum of Squares (WCSS) decreases as k increases (as expected), while the Silhouette Score peaks around k = 2 or 3, suggesting one of those is likely the “best” number of clusters.\nThis analysis helps determine an appropriate cluster count without ground truth labels."
  },
  {
    "objectID": "projects/HW4/hw4_questions.html#k-nearest-neighbors",
    "href": "projects/HW4/hw4_questions.html#k-nearest-neighbors",
    "title": "K-Means & K Nearest Neighbors",
    "section": "2. K Nearest Neighbors",
    "text": "2. K Nearest Neighbors\nFirst, we generate a synthetic dataset for the k-nearest neighbors algorithm and do visualization. The code generates a dataset with two features, x1 and x2, and a binary outcome variable y that is determined by whether x2 is above or below a wiggly boundary defined by a sin function.\n\n# Step 1: Generate training data\nnp.random.seed(42)\nn = 100\nx1_train = np.random.uniform(-3, 3, n)\nx2_train = np.random.uniform(-3, 3, n)\nboundary_train = np.sin(4 * x1_train) + x1_train\ny_train = (x2_train &gt; boundary_train).astype(int)\n\n\n# Visualize training data\nplt.figure()\nplt.scatter(x1_train, x2_train, c=y_train, cmap='bwr', edgecolor='k')\nplt.title(\"Training Data with Wiggly Boundary\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Step 2: Generate test data\nnp.random.seed(2025)\nx1_test = np.random.uniform(-3, 3, n)\nx2_test = np.random.uniform(-3, 3, n)\nboundary_test = np.sin(4 * x1_test) + x1_test\ny_test = (x2_test &gt; boundary_test).astype(int)\n\nX_train = np.column_stack((x1_train, x2_train))\nX_test = np.column_stack((x1_test, x2_test))\n\nAfter generating the training and testing data, we implement and evaluate KNN from k=1 to 30.\n\n# Step 3: Implement and evaluate KNN from k=1 to 30\naccuracy_scores = []\n\nfor k in range(1, 31):\n    model = KNeighborsClassifier(n_neighbors=k)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    accuracy_scores.append(acc)\n\nThen, we plot the results, where the horizontal axis is 1-30 and the vertical axis is the percentage of correctly-classified points.\n\n# Step 4: Plot accuracy vs. k\nplt.figure(figsize=(8, 5))\nplt.plot(range(1, 31), accuracy_scores, marker='o')\nplt.title(\"KNN Accuracy on Test Data\")\nplt.xlabel(\"k (Number of Neighbors)\")\nplt.ylabel(\"Accuracy\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nSummary\nFrom the plot of KNN accuracy vs. k, we observe:\n\nAccuracy starts relatively high at low values of k (especially k = 1 to k = 5).\nPeak performance occurs around k = 5 to k = 10, indicating this is a good range for balancing bias and variance.\nAs k increases beyond 15–20, accuracy plateaus or slightly drops, reflecting that large k may oversmooth the decision boundary.\n\nOverall, this result shows the importance of tuning k and that moderate values (5–10) yield the best generalization for this dataset."
  }
]