[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Chih-Ling(Lynn) Chang",
    "section": "",
    "text": "Welcome to my website !"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let’s investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of -0.85.\n\n\nHere is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nChih-Ling Chang\n\n\nApr 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Cars\n\n\n\n\n\n\nYour Name\n\n\nApr 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nData Description\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "HW1/hw1_questions.html",
    "href": "HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "HW1/hw1_questions.html#introduction",
    "href": "HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "HW1/hw1_questions.html#data",
    "href": "HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "HW1/hw1_questions.html#experimental-results",
    "href": "HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "HW1/hw1_questions.html#simulation-experiment",
    "href": "HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "HW1/HW1.html",
    "href": "HW1/HW1.html",
    "title": "Data Description",
    "section": "",
    "text": "# pip install pandas pyreadstat\n\nRequirement already satisfied: pandas in /home/jovyan/.rsm-msba/lib/python3.11/site-packages (2.2.3)\nRequirement already satisfied: pyreadstat in /opt/conda/lib/python3.11/site-packages (1.2.8)\nRequirement already satisfied: numpy&gt;=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\nRequirement already satisfied: pytz&gt;=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six&gt;=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pyrsm as rsm\n\n\nkarlan_df = pd.read_stata('karlan_list_2007.dta')\nkarlan_df.to_csv('karlan_list_2007.csv', index=False)\n\n\nkarlan_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\nkarlan_df.isnull().sum()\n\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n\n\n\ngroup_cols = [\"treatment\", \"control\"]\nratio_cols = [\"ratio\", \"ratio2\", \"ratio3\"]\nsize_cols = [\"size25\", \"size50\", \"size100\", \"sizeno\"]\naskd_cols = [\"ask\", \"askd1\", \"askd2\", \"askd3\"]\nask_cols = [\"ask1\", \"ask2\", \"ask3\"]\nstate_cols = [\"red0\", \"blue0\"]\ncounty_cols = [\"redcty\", \"bluecty\"]\n\n\nkarlan_df[\"group\"] = karlan_df[group_cols].idxmax(axis=1)\nkarlan_df[\"county\"] = karlan_df[county_cols].idxmax(axis=1).map({\"redcty\": \"red\", \"bluecty\": \"blue\"})\nkarlan_df[\"state\"] = karlan_df[state_cols].idxmax(axis=1).map({\"red0\": \"red\", \"blue0\": \"blue\"})\nkarlan_df\n\n/tmp/ipykernel_7246/2551348540.py:2: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n  karlan_df[\"county\"] = karlan_df[county_cols].idxmax(axis=1).map({\"redcty\": \"red\", \"bluecty\": \"blue\"})\n/tmp/ipykernel_7246/2551348540.py:3: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n  karlan_df[\"state\"] = karlan_df[state_cols].idxmax(axis=1).map({\"red0\": \"red\", \"blue0\": \"blue\"})\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\ngroup\ncounty\nstate\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\ncontrol\nblue\nblue\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\ncontrol\nred\nblue\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\ntreatment\nblue\nblue\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\ntreatment\nred\nblue\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\ntreatment\nblue\nred\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\ntreatment\nblue\nred\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\ncontrol\nblue\nblue\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\ncontrol\nred\nblue\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\ntreatment\nred\nblue\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\ntreatment\nblue\nblue\n\n\n\n\n50083 rows × 54 columns\n\n\n\n\ngroup = karlan_df[\"group\"].value_counts(normalize=True)\ngroup.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Group Distribution\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nfor i in range(len(group)):\n    plt.text(i, group[i], f\"{round(group[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/2886523009.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, group[i], f\"{round(group[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nratios = karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}).value_counts(normalize=True)\nratios.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Match Ratios\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nfor i in range(len(ratios)):\n    plt.text(i, ratios[i], f\"{round(ratios[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/3747464993.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ratios[i], f\"{round(ratios[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nsizes = karlan_df[\"size\"].value_counts(normalize=True)\nsizes.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Match thresholds\")\nplt.xlabel(\"Size\")\nplt.ylabel(\"Proportion\")\nfor i in range(len(sizes)):\n    plt.text(i, sizes[i], f\"{round(sizes[i]*100, 2)}%\", ha='center', va='bottom')\nplt.xticks(rotation=0)\nplt.show()\n\n/tmp/ipykernel_7246/248569292.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, sizes[i], f\"{round(sizes[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nasks = karlan_df[\"ask\"].value_counts(normalize=True)\nasks.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Highest previous contribution (for suggestion)\")\nplt.xlabel(\"Ask\")\nplt.ylabel(\"Proportion\")\nfor i in range(len(asks)):\n    plt.text(i, asks[i], f\"{round(asks[i]*100, 2)}%\", ha='center', va='bottom')\nplt.xticks(rotation=0)\nplt.show()\n\n/tmp/ipykernel_7246/182013770.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, asks[i], f\"{round(asks[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngave = karlan_df[\"gave\"].value_counts(normalize=True)\nax = gave.plot(kind=\"pie\", autopct='%1.1f%%', startangle=90, colors=[\"lightblue\",\"lightpink\"])\nplt.title(\"Response rate of Donations\")\nplt.legend(title=\"Gave\", loc=\"upper right\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nax = karlan_df[karlan_df['gave'] == 1].groupby(\"group\")[\"amount\"].mean()\nax.plot(kind='bar', color='lightblue')\n\nplt.title(\"Average Dollar Given Amount by group\")\nplt.xlabel(\"group\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(ax)):\n    plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/1169144851.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngave1_ratio = karlan_df[karlan_df['gave'] == 1].groupby(karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}))['amount'].mean()\ngave1_ratio.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Average Amount Given by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Average Amount Given\")\nplt.xticks(rotation=0)\nfor i in range(len(gave1_ratio)):\n    plt.text(i, gave1_ratio[i], f\"{round(gave1_ratio[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/1509173456.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  gave1_ratio = karlan_df[karlan_df['gave'] == 1].groupby(karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}))['amount'].mean()\n/tmp/ipykernel_7246/1509173456.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, gave1_ratio[i], f\"{round(gave1_ratio[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nax = karlan_df[karlan_df[\"gave\"] == 1].groupby(\"size\")[\"amount\"].mean()\nax.plot(kind='bar', color='lightblue')\nplt.title(\"Average Dollar Given Amount by Match threshold\")\nplt.xlabel(\"size\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(ax)):\n    plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/1746374688.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  ax = karlan_df[karlan_df[\"gave\"] == 1].groupby(\"size\")[\"amount\"].mean()\n/tmp/ipykernel_7246/1746374688.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped_county = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"county\", \"group\"])[\"amount\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county,_ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors)\nplt.title(\"Average Dollar Given Amount by county\")\nplt.xlabel(\"county\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped_county)):\n    plt.text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/3334000609.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped_county = karlan_df.groupby([\"county\", \"group\"])[\"gave\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county,_ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors)\nplt.title(\"Response rate of Donation by county\")\nplt.xlabel(\"county\")\nplt.ylabel(\"Response rate\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped_county)):\n    plt.text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/683103117.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"state\", \"group\"])[\"amount\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors)\n\nplt.title(\"Average Dollar Given Amount by State\")\nplt.xlabel(\"State and Group\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped)):\n    plt.text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/4144588813.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped = karlan_df.groupby([\"state\", \"group\"])[\"gave\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors)\n\nplt.title(\"Response rate of Donation by State\")\nplt.xlabel(\"State and Group\")\nplt.ylabel(\"Response rate\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped)):\n    plt.text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_7246/154559919.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nkarlan_df[['gave', 'median_hhincome', 'pwhite', 'page18_39']].describe()\n\n\n\n\n\n\n\n\ngave\nmedian_hhincome\npwhite\npage18_39\n\n\n\n\ncount\n50083.000000\n48209.000000\n48217.000000\n48217.000000\n\n\nmean\n0.020646\n54815.700533\n0.819599\n0.321694\n\n\nstd\n0.142197\n22027.316665\n0.168560\n0.103039\n\n\nmin\n0.000000\n5000.000000\n0.009418\n0.000000\n\n\n25%\n0.000000\n39181.000000\n0.755845\n0.258311\n\n\n50%\n0.000000\n50673.000000\n0.872797\n0.305534\n\n\n75%\n0.000000\n66005.000000\n0.938827\n0.369132\n\n\nmax\n1.000000\n200001.000000\n1.000000\n0.997544\n\n\n\n\n\n\n\n\nBalance Test\n\nnon-outcome variable: mrm2\n\nfrom scipy import stats\n\n# group by treatment and control\ntreated_mrm2 = karlan_df[karlan_df['group'] == \"treatment\"]['mrm2'].dropna()\ncontrol_mrm2 = karlan_df[karlan_df['group'] == \"control\"]['mrm2'].dropna()\n\n# t-test\nt_stat, p_val = stats.ttest_ind(treated_mrm2, control_mrm2, equal_var=True)\n\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 0.119, p-value: 0.905\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"mrm2\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: mrm2\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  215.360  &lt; .001  ***\nmrm2             0.000      0.000    0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.014 df(1, 50080), p.value 0.905\nNr obs: 50,082 (1 obs. dropped)\n\n\n\nimport statsmodels.api as sm\n\n# regression analysis\nX = sm.add_constant(karlan_df['treatment'])\ny = karlan_df['mrm2']\nmodel = sm.OLS(y, X, missing='drop').fit()\n\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.905\nTime:                        18:01:51   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nnon-outcome variable: median_hhincome\n\ntreated_mh = karlan_df[karlan_df['group'] == \"treatment\"]['median_hhincome'].dropna()\ncontrol_mh = karlan_df[karlan_df['group'] == \"control\"]['median_hhincome'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_mh, control_mh, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.742, p-value: 0.458\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"median_hhincome\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: median_hhincome\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n                 coefficient  std.error  t.value p.value     \nIntercept              0.671      0.006  116.647  &lt; .001  ***\nmedian_hhincome       -0.000      0.000   -0.742   0.458     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.55 df(1, 48207), p.value 0.458\nNr obs: 48,209 (1,874 obs. dropped)\n\n\n\n\nnon-outcome variable: freq\n\ntreated_freq = karlan_df[karlan_df['group'] == \"treatment\"]['freq'].dropna()\ncontrol_freq = karlan_df[karlan_df['group'] == \"control\"]['freq'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_freq, control_freq, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.111, p-value: 0.912\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"freq\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: freq\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  258.746  &lt; .001  ***\nfreq            -0.000      0.000   -0.111   0.912     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.012 df(1, 50081), p.value 0.912\nNr obs: 50,083\n\n\n\n\nnon-outcome variable: female\n\ntreated_female = karlan_df[karlan_df[\"group\"] == \"treatment\"][\"female\"].dropna()\ncontrol_female = karlan_df[karlan_df[\"group\"] == \"control\"][\"female\"].dropna()\n\nt_test, p_val = stats.ttest_ind(treated_female, control_female, equal_var=True)\nprint(f\"t-statistic: {t_test:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -1.758, p-value: 0.079\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"female\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: female\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.669      0.003  266.731  &lt; .001  ***\nfemale          -0.008      0.005   -1.758   0.079    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.092 df(1, 48970), p.value 0.079\nNr obs: 48,972 (1,111 obs. dropped)\n\n\n\n\n\nExperimental Results\n\nCharitable Contribution Made\n\ngave_by_group = karlan_df.groupby(\"group\")[\"gave\"].value_counts(normalize=True).unstack()\ngave_by_group\n\n\n\n\n\n\n\ngave\n0\n1\n\n\ngroup\n\n\n\n\n\n\ncontrol\n0.982142\n0.017858\n\n\ntreatment\n0.977961\n0.022039\n\n\n\n\n\n\n\n\ngave_by_group = karlan_df.groupby(\"group\")[\"gave\"].value_counts(normalize=True).unstack()\ngave_by_group.plot(kind=\"bar\", stacked=True, color=(\"lightblue\", \"lightpink\"))\nplt.title(\"Proportation of people who denoted by Group\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nplt.legend(title=\"Gave\", loc=\"upper right\")\n\nfor i, (gave_by_group, row) in enumerate(gave_by_group.iterrows()):\n    for j, value in enumerate(row):\n        if j == 1:\n            plt.text(i, value+1, f\"{value*100:.1f}%\", ha=\"center\", va=\"top\", fontsize=10)\n        else:\n            plt.text(i, value/2, f\"{value*100:.1f}%\", ha=\"center\", va=\"center\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\n\ntreated_gave = karlan_df[karlan_df['group'] == \"treatment\"]['gave'].dropna()\ncontrol_gave = karlan_df[karlan_df['group'] == \"control\"]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave, control_gave, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 3.101, p-value: 0.002\n\n\n\nfrom statsmodels.discrete.discrete_model import Probit\n\nX = sm.add_constant(karlan_df[\"treatment\"])\nprobit_model = Probit(karlan_df[\"gave\"], X).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        18:01:52   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\n\nratio_gave = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].dropna()\nratio2_gave = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].dropna()\nratio3_gave = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].dropna()\nratio_control_gave = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].dropna()\n\nt_stat, p_val = stats.ttest_ind(ratio_gave, ratio2_gave, equal_var=True)\nprint(f\"ratio1 & ratio2: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt_stat, p_val = stats.ttest_ind(ratio_gave, ratio3_gave, equal_var=True)\nprint(f\"ratio1 & ratio3: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt_stat, p_val = stats.ttest_ind(ratio_gave, ratio_control_gave, equal_var=True)\nprint(f\"ratio1 & control: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt_stat, p_val = stats.ttest_ind(ratio2_gave, ratio3_gave, equal_var=True)\nprint(f\"ratio2 & ratio3: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt_stat, p_val = stats.ttest_ind(ratio2_gave, ratio_control_gave, equal_var=True)\nprint(f\"ratio2 & control: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt_stat, p_val = stats.ttest_ind(ratio3_gave, ratio_control_gave, equal_var=True)\nprint(f\"ratio3 & control: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nratio1 & ratio2: t-statistic: -0.965, p-value: 0.335\nratio1 & ratio3: t-statistic: -1.015, p-value: 0.310\nratio1 & control: t-statistic: 1.730, p-value: 0.084\nratio2 & ratio3: t-statistic: -0.050, p-value: 0.960\nratio2 & control: t-statistic: 2.804, p-value: 0.005\nratio3 & control: t-statistic: 2.859, p-value: 0.004\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"gave\", evar=\"ratio\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : gave\nExplanatory variables: ratio\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\nratio[1]         0.003      0.002    1.661   0.097    .\nratio[2]         0.005      0.002    2.744   0.006   **\nratio[3]         0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.665 df(3, 50079), p.value 0.012\nNr obs: 50,083\n\n\n\nresponse_rate_ratio1 = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].mean().round(4)\nresponse_rate_ratio2 = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].mean().round(4)\nresponse_rate_ratio3 = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].mean().round(4)\nresponse_rate_control = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].mean().round(4)\nresponse_rate = pd.Series({\n    \"ratio1\": response_rate_ratio1,\n    \"ratio2\": response_rate_ratio2,\n    \"ratio3\": response_rate_ratio3,\n    \"control\": response_rate_control\n})\nresponse_rate\nresponse_rate.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Response Rate by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Response Rate\")\nplt.xticks(rotation=0)\n\nfor i, value in enumerate(response_rate):\n    plt.text(i, value, f\"{value*100:.2f}%\", ha=\"center\", va=\"bottom\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\n\ntreated_amount = karlan_df[karlan_df['group'] == \"treatment\"]['amount'].dropna()\ncontrol_amount = karlan_df[karlan_df['group'] == \"control\"]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_amount, control_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 1.861, p-value: 0.063\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"amount\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.666      0.002  314.669  &lt; .001  ***\namount           0.000      0.000    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.461 df(1, 50081), p.value 0.063\nNr obs: 50,083\n\n\n\ntreated_gave_amount = karlan_df[(karlan_df['group'] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\ncontrol_gave_amount = karlan_df[(karlan_df['group'] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave_amount, control_gave_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.581, p-value: 0.561\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df[karlan_df[\"gave\"] == 1]}, rvar=\"treatment\", evar=\"amount\")\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept         0.72      0.021   35.055  &lt; .001  ***\namount           -0.00      0.000   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.001\nF-statistic: 0.337 df(1, 1032), p.value 0.561\nNr obs: 1,034\n\n\n\ntreated_gave_amount = karlan_df[(karlan_df[\"group\"] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_treated_gave_amount = treated_gave_amount.mean()\n\ntreated_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7)\nplt.axvline(avg_treated_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_treated_gave_amount:.2f}\")\nplt.legend()\nplt.title(\"Distribution of Gave Amount for Treatment Group\")\nplt.xlabel(\"Amount\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\n\ncontrol_gave_amount = karlan_df[(karlan_df[\"group\"] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_control_gave_amount = control_gave_amount.mean()\ncontrol_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7)\nplt.axvline(avg_control_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_control_gave_amount:.2f}\")\nplt.legend()\nplt.title(\"Distribution of Gave Amount for Control Group\")\nplt.xlabel(\"Amount\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(0)\np_control = 0.018\np_treatment = 0.022\nn_control = 100_000\nn_treatment = 10_000\n\n# Simulate donatioin outcomes (Bernoulli distribution)\ncontrol = np.random.binomial(1, p_control, size=n_control)\ntreatment = np.random.binomial(1, p_treatment, size=n_treatment)\n\n# Sample the first 10,000 control observations to match treatment\ncontrol_sample = control[:n_treatment]\n\n# Difference = treatment - control\ndiffs = treatment - control_sample\n\n# Calculate the cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_treatment + 1)\n\n# Plot the cumulative average and the true difference line\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative average of difference\", color=\"lightblue\")\nplt.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True difference (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Law of Large Numbers Simulation\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(42)\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n\nfig, axes = plt.subplots(2, 2, figsize=(8, 8))\naxes = axes.flatten()\n\nfor idx, n in enumerate(sample_sizes):\n    diffs = []\n\n    # Simulate n_simulations times\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        diff = np.mean(treatment) - np.mean(control)\n        diffs.append(diff)\n\n    # Plot the histogram of differences\n    ax = axes[idx]\n    ax.hist(diffs, bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.75)\n    ax.axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Zero\")\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Mean Difference (Treatment - Control)\")\n    ax.set_ylabel(\"Frequency\")\n    ax.legend()\n\n# Add a title for the entire figure\nplt.suptitle(\"Central Limit Theorem Simulation\\nEffect of Sample Size on Distribution of Mean Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html",
    "href": "projects/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this large-scale natural field experiment, Karlan and List collaborated with a liberal nonprofit organization in the United States to examine how different price framing and incentives affect individual charitable giving behavior. The sample consisted of 50,083 individuals who had donated to the organization at least once since 1991. Participants were randomly assigned to either a control group or one of several treatment groups. The control group received a standard direct mail fundraising letter, while the treatment groups received letters that included an announcement of a matching grant or challenge grant offer.\nThe matching grant treatments varied systematically along three key dimensions: (1) the match ratio ($1:$1, $2:$1, and $3:$1), (2) the maximum size of the matching gift ($25,000, $50,000, $100,000, or unstated), and (3) the suggested donation amount (based on the recipient’s past donation, set at 1x, 1.25x, or 1.5x of their highest previous gift). This randomized design enabled the researchers to isolate the effect of each element on donation behavior.\nThe goal was to assess whether and how the “price” of giving, as framed by these match offers, influences both the likelihood of giving and the amount donated. The experiment provides a rare opportunity to observe actual behavior—rather than stated intentions—in a real-world charitable context, thereby generating high external validity. It also allows for an investigation of heterogeneous effects, such as differences in responsiveness across political geographies (“red” vs. “blue” states) and donor history.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#introduction",
    "href": "projects/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this large-scale natural field experiment, Karlan and List collaborated with a liberal nonprofit organization in the United States to examine how different price framing and incentives affect individual charitable giving behavior. The sample consisted of 50,083 individuals who had donated to the organization at least once since 1991. Participants were randomly assigned to either a control group or one of several treatment groups. The control group received a standard direct mail fundraising letter, while the treatment groups received letters that included an announcement of a matching grant or challenge grant offer.\nThe matching grant treatments varied systematically along three key dimensions: (1) the match ratio ($1:$1, $2:$1, and $3:$1), (2) the maximum size of the matching gift ($25,000, $50,000, $100,000, or unstated), and (3) the suggested donation amount (based on the recipient’s past donation, set at 1x, 1.25x, or 1.5x of their highest previous gift). This randomized design enabled the researchers to isolate the effect of each element on donation behavior.\nThe goal was to assess whether and how the “price” of giving, as framed by these match offers, influences both the likelihood of giving and the amount donated. The experiment provides a rare opportunity to observe actual behavior—rather than stated intentions—in a real-world charitable context, thereby generating high external validity. It also allows for an investigation of heterogeneous effects, such as differences in responsiveness across political geographies (“red” vs. “blue” states) and donor history.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#data",
    "href": "projects/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe bar chart indicates that approximately 66.7% of individuals belong to the “treatment” group, while 33.3% are in the “control” group.\n\n\n\n\n\n\n\n\n\nThe bar chart indicates that approximately 33.32% of individuals belonged to the “control” group, while the 1:1, 2:1, and 3:1 match ratios each accounted for about 22.23% of the sample.\n\n\n\n\n\n\n\n\n\nThe bar chart shows that approximately 33.32% of individuals belonged to the “control” group as well, while the unstated, $25,000, $50,000, and $100,00 match thresholds each accounted for about 16.66% of the sample.\n\n\n\n\n\n\n\n\n\nThe bar chart illustrates that roughly 33.32% of individuals were assigned to the control group, whereas each of the groups receiving suggested donation amounts of 1x, 1.25x, and 1.50x their previous highest contribution represented approximately 22.23% of the sample.\n\n\n\n\n\n\n\n\n\nThe pie chart shows that 2.1% of individuals made a donation of any amount.\n\n\n\n\n\n\n\n\n\nThe average donation amounts for the control and treatment groups are similar, at $46 and $44 respectively.\n\n\n\n\n\n\n\n\n\nBased on the match ratios, we can see that the control group has the highest average donation amount at $46. The 1:1 and 2:1 match groups follow closely, both averaging $45, while the 3:1 group has the lowest average, at only $41.\n\n\n\n\n\n\n\n\n\nThe bar chart illustrates the average donation amount across different match threshold conditions. Among all groups, the $25,000 match threshold yielded the highest average donation at $49. Both the control group and the group with an unstated match threshold followed, with an average donation of $46. In contrast, the $50,000 and $100,000 thresholds resulted in lower average donations, at $40 and $41 respectively. These findings suggest that a lower or unspecified match cap may be more effective at encouraging larger individual donations compared to higher threshold amounts.\n\n\n\n\n\n\n\n\n\nThe charts show the average donation amount and response rate across counties categorized by political affiliation (blue vs. red) and treatment type (control vs. matching grant).\nIn terms of average donation amount, the blue-control group gave the most ($46), while the treatment groups in both counties had slightly lower averages—$45 in blue counties and $43 in red counties. Notably, the red-treatment group had the lowest average donation.\nAs for the response rate, matching treatments increased participation in both regions. In blue counties, the response rose from 1.76% to 2.06%, while in red counties it increased more significantly from 1.82% to 2.33%.\nOverall, while matching grants improved the likelihood of donating, they did not necessarily increase the amount donated per person. The effect on response rate was particularly strong in red counties.\n\n\n\n\n\n\n\n\n\nThe charts provide insights into donation behavior across political states (blue vs. red) and treatment conditions (control vs. matching grant).\nIn terms of average donation amount, the highest contribution was observed in the red-control group at $47, followed by both the blue-control and red-treatment groups at $45. The blue-treatment group recorded the lowest average at $42, suggesting that matching treatments may slightly reduce the average donation amount in blue states.\nLooking at the response rate, matching grants had a positive effect in both political contexts, but the effect was particularly strong in red states. The red-treatment group showed the highest response rate at 2.34%, a significant increase from 1.46% in the red-control group. In blue states, the increase was more modest—from 2.0% to 2.11%.\nThese findings reinforce a key insight from Karlan and List (2007): matching grants boost participation (response rate), especially in red states, but do not necessarily lead to higher donation amounts per individual.\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nnon-outcome variable: mrm2\n\n\nfrom scipy import stats\n\n# group by treatment and control\ntreated_mrm2 = karlan_df[karlan_df['group'] == \"treatment\"]['mrm2'].dropna()\ncontrol_mrm2 = karlan_df[karlan_df['group'] == \"control\"]['mrm2'].dropna()\n\n# t-test\nt_stat, p_val = stats.ttest_ind(treated_mrm2, control_mrm2, equal_var=True)\n\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 0.119, p-value: 0.905\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"mrm2\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: mrm2\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  215.360  &lt; .001  ***\nmrm2             0.000      0.000    0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nnon-outcome variable: median_hhincome\n\n\ntreated_mh = karlan_df[karlan_df['group'] == \"treatment\"]['median_hhincome'].dropna()\ncontrol_mh = karlan_df[karlan_df['group'] == \"control\"]['median_hhincome'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_mh, control_mh, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.742, p-value: 0.458\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"median_hhincome\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: median_hhincome\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n                 coefficient  std.error  t.value p.value     \nIntercept              0.671      0.006  116.647  &lt; .001  ***\nmedian_hhincome       -0.000      0.000   -0.742   0.458     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nnon-outcome variable: freq\n\n\ntreated_freq = karlan_df[karlan_df['group'] == \"treatment\"]['freq'].dropna()\ncontrol_freq = karlan_df[karlan_df['group'] == \"control\"]['freq'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_freq, control_freq, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.111, p-value: 0.912\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"freq\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: freq\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  258.746  &lt; .001  ***\nfreq            -0.000      0.000   -0.111   0.912     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nnon-outcome variable: female\n\n\ntreated_female = karlan_df[karlan_df[\"group\"] == \"treatment\"][\"female\"].dropna()\ncontrol_female = karlan_df[karlan_df[\"group\"] == \"control\"][\"female\"].dropna()\n\nt_test, p_val = stats.ttest_ind(treated_female, control_female, equal_var=True)\nprint(f\"t-statistic: {t_test:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -1.758, p-value: 0.079\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"female\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: female\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.669      0.003  266.731  &lt; .001  ***\nfemale          -0.008      0.005   -1.758   0.079    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTo assess the validity of the random assignment, we tested several non-outcome variables—mrm2, median_hhincome, freq, and female—for balance between the treatment and control groups. Each variable was analyzed using both an independent-samples t-test and a linear regression, with the treatment assignment as the dependent variable. Across all tests, there were no statistically significant differences at the 95% confidence level (all p-values &gt; 0.05), suggesting that the two groups were comparable in terms of their baseline characteristics.\nOne exception worth noting is the variable female, which showed a p-value of 0.079—non-significant at the conventional 5% threshold but approaching marginal significance at the 10% level. This variable may be considered in further robustness checks as a potential confounder.\nThese findings mirror the results presented in Table 1 of Karlan and List (2007), which serves to confirm the success of the randomization. By establishing that the treatment and control groups are balanced on observable covariates, we strengthen the internal validity of the experimental design and provide a solid foundation for interpreting causal treatment effects in subsequent analyses."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#experimental-results",
    "href": "projects/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\ngave_by_group = karlan_df.groupby(\"group\")[\"gave\"].value_counts(normalize=True).unstack()\ngave_by_group.plot(kind=\"bar\", stacked=True, color=(\"lightblue\", \"lightpink\"))\nplt.title(\"Proportation of people who denoted by Group\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nplt.legend(title=\"Gave\", loc=\"upper right\")\n\nfor i, (gave_by_group, row) in enumerate(gave_by_group.iterrows()):\n    for j, value in enumerate(row):\n        if j == 1:\n            plt.text(i, value+1, f\"{value*100:.1f}%\", ha=\"center\", va=\"top\", fontsize=10)\n        else:\n            plt.text(i, value/2, f\"{value*100:.1f}%\", ha=\"center\", va=\"center\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\nThis bar chart shows the proportion of people who donated, broken down by group. We can see that 1.8% of individuals in the control group made a donation, compared to 2.2% in the treatment group.\n\ntreated_gave = karlan_df[karlan_df['group'] == \"treatment\"]['gave'].dropna()\ncontrol_gave = karlan_df[karlan_df['group'] == \"control\"]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave, control_gave, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 3.101, p-value: 0.002\n\n\n\nStatistical Results & Interpretation\nThe t-test comparing donation rates between the treatment and control groups produced a statistically significant result (p-value = 0.002), indicating a meaningful difference in the likelihood of making a donation. Specifically, individuals who received the matching grant treatment were significantly more likely to donate than those who received the standard fundraising letter.\nTogether, these results align with Table 2A, Panel A in Karlan and List (2007), which shows that the matching grant treatment increases the donation response rate from approximately 1.8% in the control group to 2.2% in the treatment group. Although this change may appear small in absolute terms, it is statistically reliable and meaningful in large-scale fundraising.\n\n\nWhat We Learn About Human Behavior\nThese findings suggest that even simple changes in how charitable giving opportunities are framed—such as the use of a matching grant—can significantly influence behavior. People appear to be more willing to give when they perceive that their contribution will be amplified or matched by another donor. This reflects the importance of social cues and perceived impact in motivating altruistic behavior, and highlights how thoughtfully designed messages can boost participation in public good provision.\n\n\nProbit Regression Summary\n\nimport statsmodels.api as sm\nfrom statsmodels.discrete.discrete_model import Probit\n\nX = sm.add_constant(karlan_df[\"treatment\"])\nprobit_model = Probit(karlan_df[\"gave\"], X).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Thu, 24 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        11:08:39   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nTo replicate the results presented in Table 3, Column 1 of Karlan and List (2007), I conducted a probit regression where the outcome variable was whether an individual made any charitable donation, and the explanatory variable was assignment to the treatment or control group. The regression results indicate that assignment to the treatment group significantly increased the likelihood of donating.\nThe estimated coefficient on the treatment variable was 0.0868, with a p-value of 0.002, indicating strong statistical significance at the 1% level. This positive and significant result aligns closely with the original paper’s findings, where the authors report a similar treatment effect of approximately 0.087.\nThese findings confirm that the treatment intervention—providing a matching grant—has a statistically meaningful impact on charitable behavior, increasing the probability that individuals choose to give. The successful replication supports the robustness of the original study’s conclusion: that subtle framing strategies in fundraising can effectively encourage higher participation in charitable giving.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nratio_gave = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].dropna()\nratio2_gave = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].dropna()\nratio3_gave = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].dropna()\nratio_control_gave = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].dropna()\n\npairs = [\n    (\"ratio1 & ratio2\", ratio_gave, ratio2_gave),\n    (\"ratio1 & ratio3\", ratio_gave, ratio3_gave),\n    (\"ratio1 & control\", ratio_gave, ratio_control_gave),\n    (\"ratio2 & ratio3\", ratio2_gave, ratio3_gave),\n    (\"ratio2 & control\", ratio2_gave, ratio_control_gave),\n    (\"ratio3 & control\", ratio3_gave, ratio_control_gave),\n]\n\nfor label, group1, group2 in pairs:\n    t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=True)\n    print(f\"{label}: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nratio1 & ratio2: t-statistic: -0.965, p-value: 0.335\nratio1 & ratio3: t-statistic: -1.015, p-value: 0.310\nratio1 & control: t-statistic: 1.730, p-value: 0.084\nratio2 & ratio3: t-statistic: -0.050, p-value: 0.960\nratio2 & control: t-statistic: 2.804, p-value: 0.005\nratio3 & control: t-statistic: 2.859, p-value: 0.004\n\n\n\nMatch Ratio T-Test Summary\nTo evaluate whether the size of the match ratio influences charitable behavior, a series of t-tests were conducted comparing donation rates across different match treatments (1:1, 2:1, 3:1) and a control group. This analysis was designed to test the authors’ suggestion in the paper that larger match ratios do not necessarily lead to higher donation rates.\nThe results show no statistically significant differences in donation likelihood between the 1:1, 2:1, and 3:1 match groups (all p-values &gt; 0.3). This suggests that increasing the match ratio does not significantly increase the probability that someone will donate, relative to the baseline 1:1 offer.\nHowever, when comparing each match ratio group to the control group, both the 2:1 and 3:1 ratios led to statistically significant increases in donation rates (p = 0.005 and p = 0.004, respectively), whereas the 1:1 vs. control difference was not significant (p = 0.084).\nThese findings support the authors’ claim on page 8 of the paper that, although offering a match increases the probability of donation, increasing the match ratio beyond 1:1 does not further enhance donation behavior. In other words, it is the presence of a match, rather than its generosity, that seems to matter most.\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"gave\", evar=\"ratio\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : gave\nExplanatory variables: ratio\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\nratio[1]         0.003      0.002    1.661   0.097    .\nratio[2]         0.005      0.002    2.744   0.006   **\nratio[3]         0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nRegression Summary: Match Ratio and Donation Behavior\nTo further assess whether the size of the match ratio affects donation behavior, I ran a linear regression using indicator variables for each match ratio group (ratio1, ratio2, and ratio3) to predict the probability of making a donation (gave). The regression results reveal that the match ratio does have a measurable impact on donation rates.\nThe intercept of 0.018 represents the baseline donation rate for the control group (1.8%). Compared to this baseline: • The 1:1 match (ratio1) increased donation rates by 0.3 percentage points, but this effect is not statistically significant (p = 0.097). • The 2:1 and 3:1 match groups (ratio2 and ratio3) both show statistically significant increases of 0.5 percentage points (p = 0.006 and p = 0.005, respectively).\nThese findings align with the earlier t-test results, reinforcing the conclusion that larger match ratios (2:1 and 3:1) lead to significantly higher response rates compared to the control group, whereas the 1:1 match has a smaller and statistically weaker effect.\nTaken together, the regression analysis supports the interpretation in the original paper that while offering a match increases donations, increasing the generosity of the match beyond 1:1 may yield modest but statistically significant gains. However, the differences between match ratios themselves remain relatively small.\n\nresponse_rate_ratio1 = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].mean().round(4)\nresponse_rate_ratio2 = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].mean().round(4)\nresponse_rate_ratio3 = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].mean().round(4)\nresponse_rate_control = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].mean().round(4)\nresponse_rate = pd.Series({\n    \"ratio1\": response_rate_ratio1,\n    \"ratio2\": response_rate_ratio2,\n    \"ratio3\": response_rate_ratio3,\n    \"control\": response_rate_control\n})\nresponse_rate\nresponse_rate.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Response Rate by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Response Rate\")\nplt.xticks(rotation=0)\n\nfor i, value in enumerate(response_rate):\n    plt.text(i, value, f\"{value*100:.2f}%\", ha=\"center\", va=\"bottom\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSummary of Response Rate by Match Ratio:\nTo evaluate the effectiveness of different match ratios on donation behavior, I calculated the donation response rates for the control group and each treatment group (1:1, 2:1, and 3:1 match ratios). The results reveal a clear pattern: any match treatment increases the likelihood of donation compared to no match, but increasing the match ratio does not substantially improve the response rate beyond the baseline 1:1 match. • Control group response rate: 1.79% • 1:1 match (ratio1): 2.07% • 2:1 match (ratio2): 2.26% • 3:1 match (ratio3): 2.27%\nThe increase from the control group to any treatment group is notable—about 0.3% to 0.5 percentage points—confirming that offering a matching grant increases participation. However, the differences among the 1:1, 2:1, and 3:1 ratios themselves are minimal, with a maximum difference of just 0.2 percentage points, suggesting diminishing returns to increasing the generosity of the match.\nThese findings align with the authors’ conclusion in the paper that the presence of a match matters more than the size of the match. From a practical perspective, this implies that organizations may not need to offer high match ratios to achieve significant gains in donor participation.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\ntreated_amount = karlan_df[karlan_df['group'] == \"treatment\"]['amount'].dropna()\ncontrol_amount = karlan_df[karlan_df['group'] == \"control\"]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_amount, control_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 1.861, p-value: 0.063\n\n\n\nDoes treatment affect the average donation amount?\nIn the first part of the analysis, a t-test was used to compare the donation amounts between the treatment and control groups. The results show that the treatment group donated slightly more on average than the control group, with a t-statistic of 1.861 and a p-value of 0.063. This value is close to, but does not reach, the conventional 5% threshold for statistical significance.\nThis suggests that the matching grant treatment may have some effect on the amount donated, but the evidence is not strong enough to confirm a clear impact. In other words, we find weak evidence that the treatment could increase the average donation amount, but it does not support a strong causal conclusion.\n\nreg = rsm.model.regress({\"karlan\": karlan_df[karlan_df[\"gave\"] == 1]}, rvar=\"treatment\", evar=\"amount\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept         0.72      0.021   35.055  &lt; .001  ***\namount           -0.00      0.000   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nAmong donors only, does treatment affect the donation amount?\nIn the second part of the analysis, a linear regression was conducted using only those individuals who made a donation, in order to assess whether the treatment influenced the amount donated among actual donors. The result shows that the coefficient on treatment is essentially zero (p = 0.561), indicating no significant relationship between treatment status and donation amount among those who gave.\nThis implies that while the matching grant treatment may encourage more people to donate, it does not significantly affect how much they donate once they’ve decided to give. The primary effect of the treatment appears to lie in influencing the decision to donate, not the size of the donation.\nAdditionally, because this analysis is limited to donors only and treatment is not randomly assigned within this subset (it’s conditioned on gave = 1), the result cannot be interpreted causally, and should be treated as descriptive.\n\ntreated_gave_amount = karlan_df[(karlan_df[\"group\"] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_treated_gave_amount = treated_gave_amount.mean()\n\ncontrol_gave_amount = karlan_df[(karlan_df[\"group\"] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_control_gave_amount = control_gave_amount.mean()\nfig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n\n# Plot for Control Group\ncontrol_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7, ax=axes[0])\naxes[0].axvline(avg_control_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_control_gave_amount:.2f}\")\naxes[0].legend()\naxes[0].set_title(\"Distribution of Gave Amount for Control Group\", fontsize=10)\naxes[0].set_xlabel(\"Amount\")\naxes[0].set_ylabel(\"Frequency\")\n\n# Plot for Treatment Group\ntreated_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7, ax=axes[1])\naxes[1].axvline(avg_treated_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_treated_gave_amount:.2f}\")\naxes[1].legend()\naxes[1].set_title(\"Distribution of Gave Amount for Treatment Group\", fontsize=10)\naxes[1].set_xlabel(\"Amount\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#simulation-experiment",
    "href": "projects/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers Simulation\nThe plot below visualizes the Law of Large Numbers using a simulation of donation behavior. Specifically, I simulated 100,000 random draws from the control group distribution and 10,000 random draws from the treatment group distribution, then calculated a vector of 10,000 differences between a randomly drawn treatment value and a randomly drawn control value. The chart plots the cumulative average of those differences as the number of simulations increases.\nThe red dashed line represents the true average difference in means, which is 0.004. As shown in the graph, the cumulative average fluctuates more heavily at the beginning when the number of simulations is small, but gradually stabilizes and converges toward the true value as the number of simulations increases. This behavior is a direct demonstration of the Law of Large Numbers, which states that the average of a large number of independent observations will converge to the expected value.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(0)\np_control = 0.018\np_treatment = 0.022\nn_control = 100_000\nn_treatment = 10_000\n\n# Simulate donatioin outcomes (Bernoulli distribution)\ncontrol = np.random.binomial(1, p_control, size=n_control)\ntreatment = np.random.binomial(1, p_treatment, size=n_treatment)\n\n# Sample the first 10,000 control observations to match treatment\ncontrol_sample = control[:n_treatment]\n\n# Difference = treatment - control\ndiffs = treatment - control_sample\n\n# Calculate the cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_treatment + 1)\n\n# Plot the cumulative average and the true difference line\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative average of difference\", color=\"lightblue\")\nplt.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True difference (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Law of Large Numbers Simulation\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nConclusion\nThis simulation confirms that the cumulative average difference between treatment and control groups indeed approaches the true difference in means as the number of samples grows. It visually reinforces a key statistical principle: with enough data, we can reliably estimate underlying population parameters, even when working with noisy or variable outcomes.\n\n\nCentral Limit Theorem Simulation\nThe set of histograms above illustrates the Central Limit Theorem (CLT) in action by showing how the distribution of sample mean differences (treatment minus control) changes with increasing sample sizes. For each sample size (50, 200, 500, and 1000), I repeatedly drew random samples from the treatment and control distributions, computed their mean difference, and repeated this process 1000 times to generate a distribution of average differences.\n\nSample size = 50: The distribution is wide and irregular, showing high variability. The zero line lies close to the center but not perfectly symmetric, and the distribution appears somewhat dispersed.\nSample size = 200: The histogram begins to resemble a normal distribution. The peak becomes more centered around zero, and the variance shrinks.\nSample size = 500: The distribution is tighter and more symmetric. Zero is clearly in the center, showing reduced sampling variability.\nSample size = 1000: The distribution becomes even more narrow and bell-shaped, strongly centered around zero. The noise has largely averaged out.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(42)\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n\nfig, axes = plt.subplots(2, 2, figsize=(8, 8))\naxes = axes.flatten()\n\nfor idx, n in enumerate(sample_sizes):\n    diffs = []\n\n    # Simulate n_simulations times\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        diff = np.mean(treatment) - np.mean(control)\n        diffs.append(diff)\n\n    # Plot the histogram of differences\n    ax = axes[idx]\n    ax.hist(diffs, bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.75)\n    ax.axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Zero\")\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Mean Difference (Treatment - Control)\")\n    ax.set_ylabel(\"Frequency\")\n    ax.legend()\n\n# Add a title for the entire figure\nplt.suptitle(\"Central Limit Theorem Simulation\\nEffect of Sample Size on Distribution of Mean Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\n\nConclusion\nThese plots clearly demonstrate the Central Limit Theorem: as the sample size increases, the distribution of the sample mean differences becomes more normal and converges toward the true mean (which is close to zero in this case). Importantly, zero is consistently near the center of the distribution, indicating that under random sampling, there is no systematic difference between the treatment and control means—exactly what we expect under the null hypothesis.\nThis reinforces a key statistical principle: larger sample sizes lead to more stable and reliable estimates, and support valid inference based on the sampling distribution of the mean."
  },
  {
    "objectID": "projects/HW1/index.html",
    "href": "projects/HW1/index.html",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects/HW1/HW1.html",
    "href": "projects/HW1/HW1.html",
    "title": "Data Description",
    "section": "",
    "text": "# pip install pandas pyreadstat\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pyrsm as rsm\n\n\nkarlan_df = pd.read_stata('karlan_list_2007.dta')\nkarlan_df.to_csv('karlan_list_2007.csv', index=False)\n\n\nkarlan_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\nkarlan_df.isnull().sum()\n\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n\n\n\ngroup_cols = [\"treatment\", \"control\"]\nratio_cols = [\"ratio\", \"ratio2\", \"ratio3\"]\nsize_cols = [\"size25\", \"size50\", \"size100\", \"sizeno\"]\naskd_cols = [\"ask\", \"askd1\", \"askd2\", \"askd3\"]\nask_cols = [\"ask1\", \"ask2\", \"ask3\"]\nstate_cols = [\"red0\", \"blue0\"]\ncounty_cols = [\"redcty\", \"bluecty\"]\n\n\nkarlan_df[\"group\"] = karlan_df[group_cols].idxmax(axis=1)\nkarlan_df[\"county\"] = karlan_df[county_cols].idxmax(axis=1).map({\"redcty\": \"red\", \"bluecty\": \"blue\"})\nkarlan_df[\"state\"] = karlan_df[state_cols].idxmax(axis=1).map({\"red0\": \"red\", \"blue0\": \"blue\"})\nkarlan_df\n\n/tmp/ipykernel_38392/2551348540.py:2: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n  karlan_df[\"county\"] = karlan_df[county_cols].idxmax(axis=1).map({\"redcty\": \"red\", \"bluecty\": \"blue\"})\n/tmp/ipykernel_38392/2551348540.py:3: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n  karlan_df[\"state\"] = karlan_df[state_cols].idxmax(axis=1).map({\"red0\": \"red\", \"blue0\": \"blue\"})\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\ngroup\ncounty\nstate\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\ncontrol\nblue\nblue\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\ncontrol\nred\nblue\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\ntreatment\nblue\nblue\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\ntreatment\nred\nblue\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\ntreatment\nblue\nred\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\ntreatment\nblue\nred\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\ncontrol\nblue\nblue\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\ncontrol\nred\nblue\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\ntreatment\nred\nblue\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\ntreatment\nblue\nblue\n\n\n\n\n50083 rows × 54 columns\n\n\n\n\ngroup = karlan_df[\"group\"].value_counts(normalize=True)\ngroup.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Group Distribution\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nfor i in range(len(group)):\n    plt.text(i, group[i], f\"{round(group[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n\ngroup = karlan_df[\"group\"].value_counts(normalize=True)\ngroup.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Group Distribution\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nfor i in range(len(group)):\n    plt.text(i, group[i], f\"{round(group[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/2886523009.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, group[i], f\"{round(group[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nratios = karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}).value_counts(normalize=True)\nratios.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Match Ratios\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nfor i in range(len(ratios)):\n    plt.text(i, ratios[i], f\"{round(ratios[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/3747464993.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ratios[i], f\"{round(ratios[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nsizes = karlan_df[\"size\"].value_counts(normalize=True)\nsizes.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Match thresholds\")\nplt.xlabel(\"Size\")\nplt.ylabel(\"Proportion\")\nfor i in range(len(sizes)):\n    plt.text(i, sizes[i], f\"{round(sizes[i]*100, 2)}%\", ha='center', va='bottom')\nplt.xticks(rotation=0)\nplt.show()\n\n/tmp/ipykernel_38392/248569292.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, sizes[i], f\"{round(sizes[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nasks = karlan_df[\"ask\"].value_counts(normalize=True)\nasks.plot(kind=\"bar\", color=\"orange\")\nplt.title(\"Distribution of Highest previous contribution (for suggestion)\")\nplt.xlabel(\"Ask\")\nplt.ylabel(\"Proportion\")\nfor i in range(len(asks)):\n    plt.text(i, asks[i], f\"{round(asks[i]*100, 2)}%\", ha='center', va='bottom')\nplt.xticks(rotation=0)\nplt.show()\n\n/tmp/ipykernel_38392/182013770.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, asks[i], f\"{round(asks[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngave = karlan_df[\"gave\"].value_counts(normalize=True)\nax = gave.plot(kind=\"pie\", autopct='%1.1f%%', startangle=90, colors=[\"lightblue\",\"lightpink\"])\nplt.title(\"Response rate of Donations\")\nplt.legend(title=\"Gave\", loc=\"upper right\")\nplt.show()\n\n\n\n\n\n\n\n\n\nax = karlan_df[karlan_df['gave'] == 1].groupby(\"group\")[\"amount\"].mean()\nax.plot(kind='bar', color='lightblue')\n\nplt.title(\"Average Dollar Given Amount by group\")\nplt.xlabel(\"group\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(ax)):\n    plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/1169144851.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngave1_ratio = karlan_df[karlan_df['gave'] == 1].groupby(karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}))['amount'].mean()\ngave1_ratio.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Average Amount Given by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Average Amount Given\")\nplt.xticks(rotation=0)\nfor i in range(len(gave1_ratio)):\n    plt.text(i, gave1_ratio[i], f\"{round(gave1_ratio[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/1509173456.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  gave1_ratio = karlan_df[karlan_df['gave'] == 1].groupby(karlan_df[\"ratio\"].map({1: \"1:1\", 2: \"2:1\", 3: \"3:1\", \"Control\": \"Control\"}))['amount'].mean()\n/tmp/ipykernel_38392/1509173456.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, gave1_ratio[i], f\"{round(gave1_ratio[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nax = karlan_df[karlan_df[\"gave\"] == 1].groupby(\"size\")[\"amount\"].mean()\nax.plot(kind='bar', color='lightblue')\nplt.title(\"Average Dollar Given Amount by Match threshold\")\nplt.xlabel(\"size\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(ax)):\n    plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/1746374688.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  ax = karlan_df[karlan_df[\"gave\"] == 1].groupby(\"size\")[\"amount\"].mean()\n/tmp/ipykernel_38392/1746374688.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, ax[i], f\"{round(ax[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=False)\n\n# Plot 1: Average Dollar Given Amount by county\ngrouped_county = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"county\", \"group\"])[\"amount\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county, _ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors, ax=axes[0])\naxes[0].set_title(\"Average Dollar Given Amount by county\")\naxes[0].set_xlabel(\"County\")\naxes[0].set_ylabel(\"Average Amount\")\naxes[0].tick_params(axis='x', rotation=0, labelsize=9)  # Adjust the fontsize here\nfor i in range(len(grouped_county)):\n    axes[0].text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\n\n# Plot 2: Response rate of Donation by county\ngrouped_county = karlan_df.groupby([\"county\", \"group\"])[\"gave\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county, _ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors, ax=axes[1])\naxes[1].set_title(\"Response rate of Donation by county\")\naxes[1].set_xlabel(\"County\")\naxes[1].set_ylabel(\"Response rate\")\naxes[1].tick_params(axis='x', rotation=0, labelsize=9)  # Adjust the fontsize here\nfor i in range(len(grouped_county)):\n    axes[1].text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_38392/2640907076.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  axes[0].text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\n/tmp/ipykernel_38392/2640907076.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  axes[1].text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped_county = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"county\", \"group\"])[\"amount\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county,_ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors)\nplt.title(\"Average Dollar Given Amount by county\")\nplt.xlabel(\"county\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped_county)):\n    plt.text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/3334000609.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped_county[i], f\"{round(grouped_county[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped_county = karlan_df.groupby([\"county\", \"group\"])[\"gave\"].mean()\ncolors = [\"pink\" if county == \"red\" else \"lightblue\" for county,_ in grouped_county.index]\n\ngrouped_county.plot(kind='bar', color=colors)\nplt.title(\"Response rate of Donation by county\")\nplt.xlabel(\"county\")\nplt.ylabel(\"Response rate\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped_county)):\n    plt.text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/683103117.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped_county[i], f\"{round(grouped_county[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=False)\n\n# Plot 1: Average Dollar Given Amount by State\ngrouped = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"state\", \"group\"])[\"amount\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors, ax=axes[0])\naxes[0].set_title(\"Average Dollar Given Amount by State\")\naxes[0].set_xlabel(\"State and Group\")\naxes[0].set_ylabel(\"Average Amount\")\naxes[0].tick_params(axis='x', rotation=0)\nfor i in range(len(grouped)):\n    axes[0].text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\n\n# Plot 2: Response Rate of Donation by State\ngrouped = karlan_df.groupby([\"state\", \"group\"])[\"gave\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors, ax=axes[1])\naxes[1].set_title(\"Response Rate of Donation by State\")\naxes[1].set_xlabel(\"State and Group\")\naxes[1].set_ylabel(\"Response Rate\")\naxes[1].tick_params(axis='x', rotation=0)\nfor i in range(len(grouped)):\n    axes[1].text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_38392/3635852891.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  axes[0].text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\n/tmp/ipykernel_38392/3635852891.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  axes[1].text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped = karlan_df[karlan_df[\"gave\"] == 1].groupby([\"state\", \"group\"])[\"amount\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors)\n\nplt.title(\"Average Dollar Given Amount by State\")\nplt.xlabel(\"State and Group\")\nplt.ylabel(\"Average Amount\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped)):\n    plt.text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/4144588813.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped[i], f\"{round(grouped[i])}\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\ngrouped = karlan_df.groupby([\"state\", \"group\"])[\"gave\"].mean()\ncolors = [\"lightblue\" if state == \"blue\" else \"pink\" for state, _ in grouped.index]\n\ngrouped.plot(kind=\"bar\", color=colors)\n\nplt.title(\"Response rate of Donation by State\")\nplt.xlabel(\"State and Group\")\nplt.ylabel(\"Response rate\")\nplt.xticks(rotation=0)\nfor i in range(len(grouped)):\n    plt.text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\nplt.show()\n\n/tmp/ipykernel_38392/154559919.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  plt.text(i, grouped[i], f\"{round(grouped[i]*100, 2)}%\", ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\n\nkarlan_df[['gave', 'median_hhincome', 'pwhite', 'page18_39']].describe()\n\n\n\n\n\n\n\n\ngave\nmedian_hhincome\npwhite\npage18_39\n\n\n\n\ncount\n50083.000000\n48209.000000\n48217.000000\n48217.000000\n\n\nmean\n0.020646\n54815.700533\n0.819599\n0.321694\n\n\nstd\n0.142197\n22027.316665\n0.168560\n0.103039\n\n\nmin\n0.000000\n5000.000000\n0.009418\n0.000000\n\n\n25%\n0.000000\n39181.000000\n0.755845\n0.258311\n\n\n50%\n0.000000\n50673.000000\n0.872797\n0.305534\n\n\n75%\n0.000000\n66005.000000\n0.938827\n0.369132\n\n\nmax\n1.000000\n200001.000000\n1.000000\n0.997544\n\n\n\n\n\n\n\n\nBalance Test\n\nnon-outcome variable: mrm2\n\nfrom scipy import stats\n\n# group by treatment and control\ntreated_mrm2 = karlan_df[karlan_df['group'] == \"treatment\"]['mrm2'].dropna()\ncontrol_mrm2 = karlan_df[karlan_df['group'] == \"control\"]['mrm2'].dropna()\n\n# t-test\nt_stat, p_val = stats.ttest_ind(treated_mrm2, control_mrm2, equal_var=True)\n\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 0.119, p-value: 0.905\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"mrm2\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: mrm2\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  215.360  &lt; .001  ***\nmrm2             0.000      0.000    0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nimport statsmodels.api as sm\n\n# regression analysis\nX = sm.add_constant(karlan_df['treatment'])\ny = karlan_df['mrm2']\nmodel = sm.OLS(y, X, missing='drop').fit()\n\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.905\nTime:                        20:34:15   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nnon-outcome variable: median_hhincome\n\ntreated_mh = karlan_df[karlan_df['group'] == \"treatment\"]['median_hhincome'].dropna()\ncontrol_mh = karlan_df[karlan_df['group'] == \"control\"]['median_hhincome'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_mh, control_mh, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.742, p-value: 0.458\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"median_hhincome\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: median_hhincome\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n                 coefficient  std.error  t.value p.value     \nIntercept              0.671      0.006  116.647  &lt; .001  ***\nmedian_hhincome       -0.000      0.000   -0.742   0.458     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nnon-outcome variable: freq\n\ntreated_freq = karlan_df[karlan_df['group'] == \"treatment\"]['freq'].dropna()\ncontrol_freq = karlan_df[karlan_df['group'] == \"control\"]['freq'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_freq, control_freq, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.111, p-value: 0.912\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"freq\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: freq\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  258.746  &lt; .001  ***\nfreq            -0.000      0.000   -0.111   0.912     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nnon-outcome variable: female\n\ntreated_female = karlan_df[karlan_df[\"group\"] == \"treatment\"][\"female\"].dropna()\ncontrol_female = karlan_df[karlan_df[\"group\"] == \"control\"][\"female\"].dropna()\n\nt_test, p_val = stats.ttest_ind(treated_female, control_female, equal_var=True)\nprint(f\"t-statistic: {t_test:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -1.758, p-value: 0.079\n\n\n\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"female\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: female\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.669      0.003  266.731  &lt; .001  ***\nfemale          -0.008      0.005   -1.758   0.079    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nExperimental Results\n\nCharitable Contribution Made\n\ngave_by_group = karlan_df.groupby(\"group\")[\"gave\"].value_counts(normalize=True).unstack()\ngave_by_group.plot(kind=\"bar\", stacked=True, color=(\"lightblue\", \"lightpink\"))\nplt.title(\"Proportation of people who denoted by Group\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nplt.legend(title=\"Gave\", loc=\"upper right\")\n\nfor i, (gave_by_group, row) in enumerate(gave_by_group.iterrows()):\n    for j, value in enumerate(row):\n        if j == 1:\n            plt.text(i, value+1, f\"{value*100:.1f}%\", ha=\"center\", va=\"top\", fontsize=10)\n        else:\n            plt.text(i, value/2, f\"{value*100:.1f}%\", ha=\"center\", va=\"center\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\n\ntreated_gave = karlan_df[karlan_df['group'] == \"treatment\"]['gave'].dropna()\ncontrol_gave = karlan_df[karlan_df['group'] == \"control\"]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave, control_gave, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 3.101, p-value: 0.002\n\n\n\nfrom statsmodels.discrete.discrete_model import Probit\n\nX = sm.add_constant(karlan_df[\"treatment\"])\nprobit_model = Probit(karlan_df[\"gave\"], X).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        20:16:14   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\n\nratio_gave = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].dropna()\nratio2_gave = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].dropna()\nratio3_gave = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].dropna()\nratio_control_gave = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].dropna()\n\npairs = [\n    (\"ratio1 & ratio2\", ratio_gave, ratio2_gave),\n    (\"ratio1 & ratio3\", ratio_gave, ratio3_gave),\n    (\"ratio1 & control\", ratio_gave, ratio_control_gave),\n    (\"ratio2 & ratio3\", ratio2_gave, ratio3_gave),\n    (\"ratio2 & control\", ratio2_gave, ratio_control_gave),\n    (\"ratio3 & control\", ratio3_gave, ratio_control_gave),\n]\n\nfor label, group1, group2 in pairs:\n    t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=True)\n    print(f\"{label}: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nratio1 & ratio2: t-statistic: -0.965, p-value: 0.335\nratio1 & ratio3: t-statistic: -1.015, p-value: 0.310\nratio1 & control: t-statistic: 1.730, p-value: 0.084\nratio2 & ratio3: t-statistic: -0.050, p-value: 0.960\nratio2 & control: t-statistic: 2.804, p-value: 0.005\nratio3 & control: t-statistic: 2.859, p-value: 0.004\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"gave\", evar=\"ratio\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : gave\nExplanatory variables: ratio\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\nratio[1]         0.003      0.002    1.661   0.097    .\nratio[2]         0.005      0.002    2.744   0.006   **\nratio[3]         0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nresponse_rate_ratio1 = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].mean().round(4)\nresponse_rate_ratio2 = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].mean().round(4)\nresponse_rate_ratio3 = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].mean().round(4)\nresponse_rate_control = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].mean().round(4)\nresponse_rate = pd.Series({\n    \"ratio1\": response_rate_ratio1,\n    \"ratio2\": response_rate_ratio2,\n    \"ratio3\": response_rate_ratio3,\n    \"control\": response_rate_control\n})\nresponse_rate\nresponse_rate.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Response Rate by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Response Rate\")\nplt.xticks(rotation=0)\n\nfor i, value in enumerate(response_rate):\n    plt.text(i, value, f\"{value*100:.2f}%\", ha=\"center\", va=\"bottom\", fontsize=10)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\n\ntreated_amount = karlan_df[karlan_df['group'] == \"treatment\"]['amount'].dropna()\ncontrol_amount = karlan_df[karlan_df['group'] == \"control\"]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_amount, control_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: 1.861, p-value: 0.063\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"amount\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.666      0.002  314.669  &lt; .001  ***\namount           0.000      0.000    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ntreated_gave_amount = karlan_df[(karlan_df['group'] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\ncontrol_gave_amount = karlan_df[(karlan_df['group'] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave_amount, control_gave_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nt-statistic: -0.581, p-value: 0.561\n\n\n\nreg = rsm.model.regress({\"karlan\": karlan_df[karlan_df[\"gave\"] == 1]}, rvar=\"treatment\", evar=\"amount\")\nreg.summary(fit=False)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept         0.72      0.021   35.055  &lt; .001  ***\namount           -0.00      0.000   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ntreated_gave_amount = karlan_df[(karlan_df[\"group\"] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_treated_gave_amount = treated_gave_amount.mean()\n\ncontrol_gave_amount = karlan_df[(karlan_df[\"group\"] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_control_gave_amount = control_gave_amount.mean()\nfig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n\n# Plot for Control Group\ncontrol_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7, ax=axes[0])\naxes[0].axvline(avg_control_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_control_gave_amount:.2f}\")\naxes[0].legend()\naxes[0].set_title(\"Distribution of Gave Amount for Control Group\", fontsize=10)\naxes[0].set_xlabel(\"Amount\")\naxes[0].set_ylabel(\"Frequency\")\n\n# Plot for Treatment Group\ntreated_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7, ax=axes[1])\naxes[1].axvline(avg_treated_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_treated_gave_amount:.2f}\")\naxes[1].legend()\naxes[1].set_title(\"Distribution of Gave Amount for Treatment Group\", fontsize=10)\naxes[1].set_xlabel(\"Amount\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ntreated_gave_amount = karlan_df[(karlan_df[\"group\"] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_treated_gave_amount = treated_gave_amount.mean()\n\ntreated_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7)\nplt.axvline(avg_treated_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_treated_gave_amount:.2f}\")\nplt.legend()\nplt.title(\"Distribution of Gave Amount for Treatment Group\")\nplt.xlabel(\"Amount\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\n\ncontrol_gave_amount = karlan_df[(karlan_df[\"group\"] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_control_gave_amount = control_gave_amount.mean()\n\ncontrol_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7)\nplt.axvline(avg_control_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_control_gave_amount:.2f}\")\nplt.legend()\nplt.title(\"Distribution of Gave Amount for Control Group\")\nplt.xlabel(\"Amount\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(0)\np_control = 0.018\np_treatment = 0.022\nn_control = 100_000\nn_treatment = 10_000\n\n# Simulate donatioin outcomes (Bernoulli distribution)\ncontrol = np.random.binomial(1, p_control, size=n_control)\ntreatment = np.random.binomial(1, p_treatment, size=n_treatment)\n\n# Sample the first 10,000 control observations to match treatment\ncontrol_sample = control[:n_treatment]\n\n# Difference = treatment - control\ndiffs = treatment - control_sample\n\n# Calculate the cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_treatment + 1)\n\n# Plot the cumulative average and the true difference line\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative average of difference\", color=\"lightblue\")\nplt.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True difference (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Law of Large Numbers Simulation\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(42)\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n\nfig, axes = plt.subplots(2, 2, figsize=(8, 8))\naxes = axes.flatten()\n\nfor idx, n in enumerate(sample_sizes):\n    diffs = []\n\n    # Simulate n_simulations times\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        diff = np.mean(treatment) - np.mean(control)\n        diffs.append(diff)\n\n    # Plot the histogram of differences\n    ax = axes[idx]\n    ax.hist(diffs, bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.75)\n    ax.axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Zero\")\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Mean Difference (Treatment - Control)\")\n    ax.set_ylabel(\"Frequency\")\n    ax.legend()\n\n# Add a title for the entire figure\nplt.suptitle(\"Central Limit Theorem Simulation\\nEffect of Sample Size on Distribution of Mean Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()"
  }
]