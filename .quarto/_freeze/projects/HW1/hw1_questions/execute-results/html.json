{
  "hash": "dac45308d5da2fb57c5ab396580a2527",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A Replication of Karlan and List (2007)\"\nauthor: \"Chih-Ling Chang\"\ndate: today\ncallout-appearance: minimal # this hides the blue \"i\" icon on .callout-notes\n---\n\n\n\n\n\n## Introduction\n\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\nIn this large-scale natural field experiment, Karlan and List collaborated with a liberal nonprofit organization in the United States to examine how different price framing and incentives affect individual charitable giving behavior. The sample consisted of 50,083 individuals who had donated to the organization at least once since 1991. Participants were randomly assigned to either a control group or one of several treatment groups. The control group received a standard direct mail fundraising letter, while the treatment groups received letters that included an announcement of a matching grant or challenge grant offer.\n\nThe matching grant treatments varied systematically along three key dimensions: (1) the match ratio ($1:$1, $2:$1, and $3:$1), (2) the maximum size of the matching gift ($25,000, $50,000, $100,000, or unstated), and (3) the suggested donation amount (based on the recipient’s past donation, set at 1x, 1.25x, or 1.5x of their highest previous gift). This randomized design enabled the researchers to isolate the effect of each element on donation behavior.\n\nThe goal was to assess whether and how the “price” of giving, as framed by these match offers, influences both the likelihood of giving and the amount donated. The experiment provides a rare opportunity to observe actual behavior—rather than stated intentions—in a real-world charitable context, thereby generating high external validity. It also allows for an investigation of heterogeneous effects, such as differences in responsiveness across political geographies (“red” vs. “blue” states) and donor history.\n\nThis project seeks to replicate their results.\n\n\n## Data\n\n### Description\n\n:::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|----------------------|---------------------------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n\n::::\n\n\n\n::: {#c8388573 .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-3-output-1.png){width=589 height=449}\n:::\n:::\n\n\nThe bar chart indicates that approximately 66.7% of individuals belong to the \"treatment\" group, while 33.3% are in the \"control\" group.\n\n::: {#06488f6a .cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-4-output-1.png){width=597 height=449}\n:::\n:::\n\n\nThe bar chart indicates that approximately 33.32% of individuals belonged to the “control” group, while the 1:1, 2:1, and 3:1 match ratios each accounted for about 22.23% of the sample.\n\n::: {#8dd02806 .cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-5-output-1.png){width=597 height=449}\n:::\n:::\n\n\nThe bar chart shows that approximately 33.32% of individuals belonged to the “control” group as well, while the unstated, $25,000, $50,000, and $100,00 match thresholds each accounted for about 16.66% of the sample.\n\n::: {#a7cd0c1d .cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-6-output-1.png){width=597 height=449}\n:::\n:::\n\n\nThe bar chart illustrates that roughly 33.32% of individuals were assigned to the control group, whereas each of the groups receiving suggested donation amounts of 1x, 1.25x, and 1.50x their previous highest contribution represented approximately 22.23% of the sample.\n\n::: {#2d0122f7 .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-7-output-1.png){width=407 height=409}\n:::\n:::\n\n\nThe pie chart shows that 2.1% of individuals made a donation of any amount.\n\n::: {#74cdae7b .cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-8-output-1.png){width=585 height=449}\n:::\n:::\n\n\nThe average donation amounts for the control and treatment groups are similar, at $46 and $44 respectively.\n\n::: {#a5b73915 .cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-9-output-1.png){width=585 height=449}\n:::\n:::\n\n\nBased on the match ratios, we can see that the control group has the highest average donation amount at $46. The 1:1 and 2:1 match groups follow closely, both averaging $45, while the 3:1 group has the lowest average, at only $41.\n\n::: {#4cd42cfe .cell execution_count=9}\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-10-output-1.png){width=585 height=449}\n:::\n:::\n\n\nThe bar chart illustrates the average donation amount across different match threshold conditions. Among all groups, the $25,000 match threshold yielded the highest average donation at $49. Both the control group and the group with an unstated match threshold followed, with an average donation of $46. In contrast, the $50,000 and $100,000 thresholds resulted in lower average donations, at $40 and $41 respectively. These findings suggest that a lower or unspecified match cap may be more effective at encouraging larger individual donations compared to higher threshold amounts.\n\n::: {#7fe79f3a .cell execution_count=10}\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-11-output-1.png){width=1141 height=468}\n:::\n:::\n\n\nThe charts show the average donation amount and response rate across counties categorized by political affiliation (blue vs. red) and treatment type (control vs. matching grant).\n\nIn terms of average donation amount, the blue-control group gave the most ($46), while the treatment groups in both counties had slightly lower averages—$45 in blue counties and $43 in red counties. Notably, the red-treatment group had the lowest average donation.\n\nAs for the response rate, matching treatments increased participation in both regions. In blue counties, the response rose from 1.76% to 2.06%, while in red counties it increased more significantly from 1.82% to 2.33%.\n\nOverall, while matching grants improved the likelihood of donating, they did not necessarily increase the amount donated per person. The effect on response rate was particularly strong in red counties.\n\n::: {#44ed5349 .cell execution_count=11}\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-12-output-1.png){width=1141 height=468}\n:::\n:::\n\n\nThe charts provide insights into donation behavior across political states (blue vs. red) and treatment conditions (control vs. matching grant).\n\nIn terms of average donation amount, the highest contribution was observed in the red-control group at $47, followed by both the blue-control and red-treatment groups at $45. The blue-treatment group recorded the lowest average at $42, suggesting that matching treatments may slightly reduce the average donation amount in blue states.\n\nLooking at the response rate, matching grants had a positive effect in both political contexts, but the effect was particularly strong in red states. The red-treatment group showed the highest response rate at 2.34%, a significant increase from 1.46% in the red-control group. In blue states, the increase was more modest—from 2.0% to 2.11%.\n\nThese findings reinforce a key insight from Karlan and List (2007): matching grants boost participation (response rate), especially in red states, but do not necessarily lead to higher donation amounts per individual.\n\n\n### Balance Test \n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n1. non-outcome variable: `mrm2`\n\n::: {#087af9a9 .cell execution_count=12}\n``` {.python .cell-code}\nfrom scipy import stats\n\n# group by treatment and control\ntreated_mrm2 = karlan_df[karlan_df['group'] == \"treatment\"]['mrm2'].dropna()\ncontrol_mrm2 = karlan_df[karlan_df['group'] == \"control\"]['mrm2'].dropna()\n\n# t-test\nt_stat, p_val = stats.ttest_ind(treated_mrm2, control_mrm2, equal_var=True)\n\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nt-statistic: 0.119, p-value: 0.905\n```\n:::\n:::\n\n\n::: {#575b8034 .cell execution_count=13}\n``` {.python .cell-code}\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"mrm2\")\nreg.summary(fit=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: mrm2\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  215.360  < .001  ***\nmrm2             0.000      0.000    0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n2. non-outcome variable: `median_hhincome`\n\n::: {#cac6a144 .cell execution_count=14}\n``` {.python .cell-code}\ntreated_mh = karlan_df[karlan_df['group'] == \"treatment\"]['median_hhincome'].dropna()\ncontrol_mh = karlan_df[karlan_df['group'] == \"control\"]['median_hhincome'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_mh, control_mh, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nt-statistic: -0.742, p-value: 0.458\n```\n:::\n:::\n\n\n::: {#f122341e .cell execution_count=15}\n``` {.python .cell-code}\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"median_hhincome\")\nreg.summary(fit=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: median_hhincome\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n                 coefficient  std.error  t.value p.value     \nIntercept              0.671      0.006  116.647  < .001  ***\nmedian_hhincome       -0.000      0.000   -0.742   0.458     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n3. non-outcome variable: `freq`\n\n::: {#3b203703 .cell execution_count=16}\n``` {.python .cell-code}\ntreated_freq = karlan_df[karlan_df['group'] == \"treatment\"]['freq'].dropna()\ncontrol_freq = karlan_df[karlan_df['group'] == \"control\"]['freq'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_freq, control_freq, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nt-statistic: -0.111, p-value: 0.912\n```\n:::\n:::\n\n\n::: {#bcc57fe8 .cell execution_count=17}\n``` {.python .cell-code}\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"treatment\", evar=\"freq\")\nreg.summary(fit=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: freq\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.667      0.003  258.746  < .001  ***\nfreq            -0.000      0.000   -0.111   0.912     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n4. non-outcome variable: `female`\n\n::: {#13eab792 .cell execution_count=18}\n``` {.python .cell-code}\ntreated_female = karlan_df[karlan_df[\"group\"] == \"treatment\"][\"female\"].dropna()\ncontrol_female = karlan_df[karlan_df[\"group\"] == \"control\"][\"female\"].dropna()\n\nt_test, p_val = stats.ttest_ind(treated_female, control_female, equal_var=True)\nprint(f\"t-statistic: {t_test:.3f}, p-value: {p_val:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nt-statistic: -1.758, p-value: 0.079\n```\n:::\n:::\n\n\n::: {#a3d640d6 .cell execution_count=19}\n``` {.python .cell-code}\nreg = rsm.model.regress({\"dakarlan\": karlan_df}, rvar=\"treatment\", evar=\"female\")\nreg.summary(fit=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear regression (OLS)\nData                 : dakarlan\nResponse variable    : treatment\nExplanatory variables: female\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.669      0.003  266.731  < .001  ***\nfemale          -0.008      0.005   -1.758   0.079    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nTo assess the validity of the random assignment, we tested several non-outcome variables—mrm2, median_hhincome, freq, and female—for balance between the treatment and control groups. Each variable was analyzed using both an independent-samples t-test and a linear regression, with the treatment assignment as the dependent variable. Across all tests, there were no statistically significant differences at the 95% confidence level (all p-values > 0.05), suggesting that the two groups were comparable in terms of their baseline characteristics.\n\nOne exception worth noting is the variable female, which showed a p-value of 0.079—non-significant at the conventional 5% threshold but approaching marginal significance at the 10% level. This variable may be considered in further robustness checks as a potential confounder.\n\nThese findings mirror the results presented in Table 1 of Karlan and List (2007), which serves to confirm the success of the randomization. By establishing that the treatment and control groups are balanced on observable covariates, we strengthen the internal validity of the experimental design and provide a solid foundation for interpreting causal treatment effects in subsequent analyses.\n\n\n## Experimental Results\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. \n\n::: {#89e776c5 .cell execution_count=20}\n``` {.python .cell-code}\ngave_by_group = karlan_df.groupby(\"group\")[\"gave\"].value_counts(normalize=True).unstack()\ngave_by_group.plot(kind=\"bar\", stacked=True, color=(\"lightblue\", \"lightpink\"))\nplt.title(\"Proportation of people who denoted by Group\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nplt.legend(title=\"Gave\", loc=\"upper right\")\n\nfor i, (gave_by_group, row) in enumerate(gave_by_group.iterrows()):\n    for j, value in enumerate(row):\n        if j == 1:\n            plt.text(i, value+1, f\"{value*100:.1f}%\", ha=\"center\", va=\"top\", fontsize=10)\n        else:\n            plt.text(i, value/2, f\"{value*100:.1f}%\", ha=\"center\", va=\"center\", fontsize=10)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-21-output-1.png){width=589 height=449}\n:::\n:::\n\n\nThis bar chart shows the proportion of people who donated, broken down by group. We can see that 1.8% of individuals in the control group made a donation, compared to 2.2% in the treatment group.\n\n::: {#b06bd58b .cell execution_count=21}\n``` {.python .cell-code}\ntreated_gave = karlan_df[karlan_df['group'] == \"treatment\"]['gave'].dropna()\ncontrol_gave = karlan_df[karlan_df['group'] == \"control\"]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_gave, control_gave, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nt-statistic: 3.101, p-value: 0.002\n```\n:::\n:::\n\n\n#### Statistical Results & Interpretation\n\nThe t-test comparing donation rates between the treatment and control groups produced a statistically significant result (p-value = 0.002), indicating a meaningful difference in the likelihood of making a donation. Specifically, individuals who received the matching grant treatment were significantly more likely to donate than those who received the standard fundraising letter.\n\nTogether, these results align with Table 2A, Panel A in Karlan and List (2007), which shows that the matching grant treatment increases the donation response rate from approximately 1.8% in the control group to 2.2% in the treatment group. Although this change may appear small in absolute terms, it is statistically reliable and meaningful in large-scale fundraising.\n\n#### What We Learn About Human Behavior\nThese findings suggest that even simple changes in how charitable giving opportunities are framed—such as the use of a matching grant—can significantly influence behavior. People appear to be more willing to give when they perceive that their contribution will be amplified or matched by another donor. This reflects the importance of social cues and perceived impact in motivating altruistic behavior, and highlights how thoughtfully designed messages can boost participation in public good provision.\n\n#### Probit Regression Summary\n\n::: {#23f3ab47 .cell execution_count=22}\n``` {.python .cell-code}\nimport statsmodels.api as sm\nfrom statsmodels.discrete.discrete_model import Probit\n\nX = sm.add_constant(karlan_df[\"treatment\"])\nprobit_model = Probit(karlan_df[\"gave\"], X).fit()\nprint(probit_model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 28 May 2025   Pseudo R-squ.:               0.0009783\nTime:                        15:51:03   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n```\n:::\n:::\n\n\nTo replicate the results presented in Table 3, Column 1 of Karlan and List (2007), I conducted a probit regression where the outcome variable was whether an individual made any charitable donation, and the explanatory variable was assignment to the treatment or control group. The regression results indicate that assignment to the treatment group significantly increased the likelihood of donating.\n\nThe estimated coefficient on the treatment variable was 0.0868, with a p-value of 0.002, indicating strong statistical significance at the 1% level. This positive and significant result aligns closely with the original paper’s findings, where the authors report a similar treatment effect of approximately 0.087.\n\nThese findings confirm that the treatment intervention—providing a matching grant—has a statistically meaningful impact on charitable behavior, increasing the probability that individuals choose to give. The successful replication supports the robustness of the original study’s conclusion: that subtle framing strategies in fundraising can effectively encourage higher participation in charitable giving.\n\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n::: {#cafd5f34 .cell execution_count=23}\n``` {.python .cell-code}\nratio_gave = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].dropna()\nratio2_gave = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].dropna()\nratio3_gave = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].dropna()\nratio_control_gave = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].dropna()\n\npairs = [\n    (\"ratio1 & ratio2\", ratio_gave, ratio2_gave),\n    (\"ratio1 & ratio3\", ratio_gave, ratio3_gave),\n    (\"ratio1 & control\", ratio_gave, ratio_control_gave),\n    (\"ratio2 & ratio3\", ratio2_gave, ratio3_gave),\n    (\"ratio2 & control\", ratio2_gave, ratio_control_gave),\n    (\"ratio3 & control\", ratio3_gave, ratio_control_gave),\n]\n\nfor label, group1, group2 in pairs:\n    t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=True)\n    print(f\"{label}: t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nratio1 & ratio2: t-statistic: -0.965, p-value: 0.335\nratio1 & ratio3: t-statistic: -1.015, p-value: 0.310\nratio1 & control: t-statistic: 1.730, p-value: 0.084\nratio2 & ratio3: t-statistic: -0.050, p-value: 0.960\nratio2 & control: t-statistic: 2.804, p-value: 0.005\nratio3 & control: t-statistic: 2.859, p-value: 0.004\n```\n:::\n:::\n\n\n#### Match Ratio T-Test Summary\n\nTo evaluate whether the size of the match ratio influences charitable behavior, a series of t-tests were conducted comparing donation rates across different match treatments (1:1, 2:1, 3:1) and a control group. This analysis was designed to test the authors’ suggestion in the paper that larger match ratios do not necessarily lead to higher donation rates.\n\nThe results show no statistically significant differences in donation likelihood between the 1:1, 2:1, and 3:1 match groups (all p-values > 0.3). This suggests that increasing the match ratio does not significantly increase the probability that someone will donate, relative to the baseline 1:1 offer.\n\nHowever, when comparing each match ratio group to the control group, both the 2:1 and 3:1 ratios led to statistically significant increases in donation rates (p = 0.005 and p = 0.004, respectively), whereas the 1:1 vs. control difference was not significant (p = 0.084).\n\nThese findings support the authors’ claim on page 8 of the paper that, although offering a match increases the probability of donation, increasing the match ratio beyond 1:1 does not further enhance donation behavior. In other words, it is the presence of a match, rather than its generosity, that seems to matter most.\n\n::: {#eeb4c4df .cell execution_count=24}\n``` {.python .cell-code}\nreg = rsm.model.regress({\"karlan\": karlan_df}, rvar=\"gave\", evar=\"ratio\")\nreg.summary(fit=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : gave\nExplanatory variables: ratio\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  < .001  ***\nratio[1]         0.003      0.002    1.661   0.097    .\nratio[2]         0.005      0.002    2.744   0.006   **\nratio[3]         0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n#### Regression Summary: Match Ratio and Donation Behavior\nTo further assess whether the size of the match ratio affects donation behavior, I ran a linear regression using indicator variables for each match ratio group (ratio1, ratio2, and ratio3) to predict the probability of making a donation (gave). The regression results reveal that the match ratio does have a measurable impact on donation rates.\n\nThe intercept of 0.018 represents the baseline donation rate for the control group (1.8%). Compared to this baseline:\n\t•\tThe 1:1 match (ratio1) increased donation rates by 0.3 percentage points, but this effect is not statistically significant (p = 0.097).\n\t•\tThe 2:1 and 3:1 match groups (ratio2 and ratio3) both show statistically significant increases of 0.5 percentage points (p = 0.006 and p = 0.005, respectively).\n\nThese findings align with the earlier t-test results, reinforcing the conclusion that larger match ratios (2:1 and 3:1) lead to significantly higher response rates compared to the control group, whereas the 1:1 match has a smaller and statistically weaker effect.\n\nTaken together, the regression analysis supports the interpretation in the original paper that while offering a match increases donations, increasing the generosity of the match beyond 1:1 may yield modest but statistically significant gains. However, the differences between match ratios themselves remain relatively small.\n\n::: {#5205de37 .cell execution_count=25}\n``` {.python .cell-code}\nresponse_rate_ratio1 = karlan_df[karlan_df[\"ratio\"] == 1][\"gave\"].mean().round(4)\nresponse_rate_ratio2 = karlan_df[karlan_df[\"ratio\"] == 2][\"gave\"].mean().round(4)\nresponse_rate_ratio3 = karlan_df[karlan_df[\"ratio\"] == 3][\"gave\"].mean().round(4)\nresponse_rate_control = karlan_df[karlan_df[\"ratio\"] == \"Control\"][\"gave\"].mean().round(4)\nresponse_rate = pd.Series({\n    \"ratio1\": response_rate_ratio1,\n    \"ratio2\": response_rate_ratio2,\n    \"ratio3\": response_rate_ratio3,\n    \"control\": response_rate_control\n})\nresponse_rate\nresponse_rate.plot(kind=\"bar\", color=\"lightblue\")\nplt.title(\"Response Rate by Ratio\")\nplt.xlabel(\"Ratio\")\nplt.ylabel(\"Response Rate\")\nplt.xticks(rotation=0)\n\nfor i, value in enumerate(response_rate):\n    plt.text(i, value, f\"{value*100:.2f}%\", ha=\"center\", va=\"bottom\", fontsize=10)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-26-output-1.png){width=606 height=449}\n:::\n:::\n\n\n#### Summary of Response Rate by Match Ratio: \nTo evaluate the effectiveness of different match ratios on donation behavior, I calculated the donation response rates for the control group and each treatment group (1:1, 2:1, and 3:1 match ratios). The results reveal a clear pattern: any match treatment increases the likelihood of donation compared to no match, but increasing the match ratio does not substantially improve the response rate beyond the baseline 1:1 match.\n\t•\tControl group response rate: 1.79%\n\t•\t1:1 match (ratio1): 2.07%\n\t•\t2:1 match (ratio2): 2.26%\n\t•\t3:1 match (ratio3): 2.27%\n\nThe increase from the control group to any treatment group is notable—about 0.3% to 0.5 percentage points—confirming that offering a matching grant increases participation. However, the differences among the 1:1, 2:1, and 3:1 ratios themselves are minimal, with a maximum difference of just 0.2 percentage points, suggesting diminishing returns to increasing the generosity of the match.\n\nThese findings align with the authors’ conclusion in the paper that the presence of a match matters more than the size of the match. From a practical perspective, this implies that organizations may not need to offer high match ratios to achieve significant gains in donor participation.\n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n::: {#12a37574 .cell execution_count=26}\n``` {.python .cell-code}\ntreated_amount = karlan_df[karlan_df['group'] == \"treatment\"]['amount'].dropna()\ncontrol_amount = karlan_df[karlan_df['group'] == \"control\"]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated_amount, control_amount, equal_var=True)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nt-statistic: 1.861, p-value: 0.063\n```\n:::\n:::\n\n\n#### Does treatment affect the average donation amount?\n\nIn the first part of the analysis, a t-test was used to compare the donation amounts between the treatment and control groups. The results show that the treatment group donated slightly more on average than the control group, with a t-statistic of 1.861 and a p-value of 0.063. This value is close to, but does not reach, the conventional 5% threshold for statistical significance.\n\nThis suggests that the matching grant treatment may have some effect on the amount donated, but the evidence is not strong enough to confirm a clear impact. In other words, we find weak evidence that the treatment could increase the average donation amount, but it does not support a strong causal conclusion.\n\n::: {#15b59ca5 .cell execution_count=27}\n``` {.python .cell-code}\nreg = rsm.model.regress({\"karlan\": karlan_df[karlan_df[\"gave\"] == 1]}, rvar=\"treatment\", evar=\"amount\")\nreg.summary(fit=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : treatment\nExplanatory variables: amount\nNull hyp.: the effect of x on treatment is zero\nAlt. hyp.: the effect of x on treatment is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept         0.72      0.021   35.055  < .001  ***\namount           -0.00      0.000   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n#### Among donors only, does treatment affect the donation amount?\n\nIn the second part of the analysis, a linear regression was conducted using only those individuals who made a donation, in order to assess whether the treatment influenced the amount donated among actual donors. The result shows that the coefficient on treatment is essentially zero (p = 0.561), indicating no significant relationship between treatment status and donation amount among those who gave.\n\nThis implies that while the matching grant treatment may encourage more people to donate, it does not significantly affect how much they donate once they’ve decided to give. The primary effect of the treatment appears to lie in influencing the decision to donate, not the size of the donation.\n\nAdditionally, because this analysis is limited to donors only and treatment is not randomly assigned within this subset (it’s conditioned on gave = 1), the result cannot be interpreted causally, and should be treated as descriptive.\n\n::: {#52ee01c4 .cell execution_count=28}\n``` {.python .cell-code}\ntreated_gave_amount = karlan_df[(karlan_df[\"group\"] == \"treatment\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_treated_gave_amount = treated_gave_amount.mean()\n\ncontrol_gave_amount = karlan_df[(karlan_df[\"group\"] == \"control\") & (karlan_df['gave'] == 1)]['amount'].dropna()\navg_control_gave_amount = control_gave_amount.mean()\nfig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n\n# Plot for Control Group\ncontrol_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7, ax=axes[0])\naxes[0].axvline(avg_control_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_control_gave_amount:.2f}\")\naxes[0].legend()\naxes[0].set_title(\"Distribution of Gave Amount for Control Group\", fontsize=10)\naxes[0].set_xlabel(\"Amount\")\naxes[0].set_ylabel(\"Frequency\")\n\n# Plot for Treatment Group\ntreated_gave_amount.plot(kind=\"hist\", bins=20, color=\"lightblue\", alpha=0.7, ax=axes[1])\naxes[1].axvline(avg_treated_gave_amount, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {avg_treated_gave_amount:.2f}\")\naxes[1].legend()\naxes[1].set_title(\"Distribution of Gave Amount for Treatment Group\", fontsize=10)\naxes[1].set_xlabel(\"Amount\")\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-29-output-1.png){width=757 height=371}\n:::\n:::\n\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic \"works,\" in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\n\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. \n\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n#### Law of Large Numbers Simulation\n\nThe plot below visualizes the Law of Large Numbers using a simulation of donation behavior. Specifically, I simulated 100,000 random draws from the control group distribution and 10,000 random draws from the treatment group distribution, then calculated a vector of 10,000 differences between a randomly drawn treatment value and a randomly drawn control value. The chart plots the cumulative average of those differences as the number of simulations increases.\n\nThe red dashed line represents the true average difference in means, which is 0.004. As shown in the graph, the cumulative average fluctuates more heavily at the beginning when the number of simulations is small, but gradually stabilizes and converges toward the true value as the number of simulations increases. This behavior is a direct demonstration of the Law of Large Numbers, which states that the average of a large number of independent observations will converge to the expected value.\n\n::: {#3e646609 .cell execution_count=29}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(0)\np_control = 0.018\np_treatment = 0.022\nn_control = 100_000\nn_treatment = 10_000\n\n# Simulate donatioin outcomes (Bernoulli distribution)\ncontrol = np.random.binomial(1, p_control, size=n_control)\ntreatment = np.random.binomial(1, p_treatment, size=n_treatment)\n\n# Sample the first 10,000 control observations to match treatment\ncontrol_sample = control[:n_treatment]\n\n# Difference = treatment - control\ndiffs = treatment - control_sample\n\n# Calculate the cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_treatment + 1)\n\n# Plot the cumulative average and the true difference line\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative average of difference\", color=\"lightblue\")\nplt.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True difference (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Law of Large Numbers Simulation\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-30-output-1.png){width=757 height=372}\n:::\n:::\n\n\n#### Conclusion\nThis simulation confirms that the cumulative average difference between treatment and control groups indeed approaches the true difference in means as the number of samples grows. It visually reinforces a key statistical principle: with enough data, we can reliably estimate underlying population parameters, even when working with noisy or variable outcomes.\n\n\n### Central Limit Theorem Simulation\nThe set of histograms above illustrates the Central Limit Theorem (CLT) in action by showing how the distribution of sample mean differences (treatment minus control) changes with increasing sample sizes. For each sample size (50, 200, 500, and 1000), I repeatedly drew random samples from the treatment and control distributions, computed their mean difference, and repeated this process 1000 times to generate a distribution of average differences.\n\n- **Sample size = 50**: The distribution is wide and irregular, showing high variability. The zero line lies close to the center but not perfectly symmetric, and the distribution appears somewhat dispersed.\n- **Sample size = 200**: The histogram begins to resemble a normal distribution. The peak becomes more centered around zero, and the variance shrinks.\n- **Sample size = 500**: The distribution is tighter and more symmetric. Zero is clearly in the center, showing reduced sampling variability.\n- **Sample size = 1000**: The distribution becomes even more narrow and bell-shaped, strongly centered around zero. The noise has largely averaged out.\n\n::: {#08560388 .cell execution_count=30}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters Setting\nnp.random.seed(42)\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n\nfig, axes = plt.subplots(2, 2, figsize=(8, 8))\naxes = axes.flatten()\n\nfor idx, n in enumerate(sample_sizes):\n    diffs = []\n\n    # Simulate n_simulations times\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        diff = np.mean(treatment) - np.mean(control)\n        diffs.append(diff)\n\n    # Plot the histogram of differences\n    ax = axes[idx]\n    ax.hist(diffs, bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.75)\n    ax.axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Zero\")\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Mean Difference (Treatment - Control)\")\n    ax.set_ylabel(\"Frequency\")\n    ax.legend()\n\n# Add a title for the entire figure\nplt.suptitle(\"Central Limit Theorem Simulation\\nEffect of Sample Size on Distribution of Mean Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-31-output-1.png){width=757 height=755}\n:::\n:::\n\n\n#### Conclusion\n\nThese plots clearly demonstrate the Central Limit Theorem: as the sample size increases, the distribution of the sample mean differences becomes more normal and converges toward the true mean (which is close to zero in this case). Importantly, zero is consistently near the center of the distribution, indicating that under random sampling, there is no systematic difference between the treatment and control means—exactly what we expect under the null hypothesis.\n\nThis reinforces a key statistical principle: larger sample sizes lead to more stable and reliable estimates, and support valid inference based on the sampling distribution of the mean.\n\n",
    "supporting": [
      "hw1_questions_files"
    ],
    "filters": [],
    "includes": {}
  }
}